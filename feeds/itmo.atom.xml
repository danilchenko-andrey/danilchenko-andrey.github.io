<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>4ducks</title><link href="/" rel="alternate"></link><link href="/feeds/itmo.atom.xml" rel="self"></link><id>/</id><updated>2014-10-15T18:50:00+04:00</updated><entry><title>Предыстория лекций в ИТМО</title><link href="/predystoriia-lektsii-v-itmo.html" rel="alternate"></link><updated>2014-10-15T18:50:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:,2014-10-15:predystoriia-lektsii-v-itmo.html</id><summary type="html">&lt;p&gt;В осеннем семестре 2014 года я провожу факультативный курс лекций по рекомендательным системам в &lt;a href="http://www.ifmo.ru/"&gt;СПб НИУ ИТМО&lt;/a&gt; на кафедре КТ ФИТиП.&lt;/p&gt;
&lt;h1&gt;Предыстория&lt;/h1&gt;
&lt;p&gt;В далеком 2012 году Антон Банных предложил мне рассказать его студентам что-нибудь про анализ данных и применение машинного обучения в Яндексе. В тот момент я начал заниматься рекомендательными системами и уже имел некоторые знания области. Я согласился и рассказал студентам четвертого курса основы рекомендаций. Но это были действительно основы — я сделал упор на &lt;a href="http://en.wikipedia.org/wiki/Association_rule_learning"&gt;ассоциативные правила&lt;/a&gt; и &lt;a href="http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"&gt;метод ближайших соседей&lt;/a&gt;. Немного рассказал про SVD, еще меньше - про оценку рекомендаций. Так сказать, первый блин вышел комом.&lt;/p&gt;
&lt;p&gt;На следующий год мои познания в области существенно выросли, как и умение рассказывать эти самые азы. Я снова углубился в создание рекомендаций для Яндекс.Музыки, на этот раз в компании московских коллег. И для "быстрого старта" сделал парочку семинаров для коллег по основам коллаборативной фильтрации. И ребятам польза, и у меня в голове знания еще раз уложились.&lt;br /&gt;
В результате я уже сам предложил Антону свою помощь. На мой взгляд, лекция удалась — я за короткое время сделал обзор простых, но в то же время хорошо работающих методов коллаборативной фильтрации (SVD и kNN — да! как показывает RecSys его до сих много кто использует), немного пробежался по контентным методам и уделил время более подробному (относительно прошлого раза) рассказу про оценку.
Кроме того, в этот год к обычным лабораториям по машинному обучению добавилась лабораторная по рекомендациям, где я предлагал на данных movielens обучить SVD-алгоритм различными способами. Справились, к сожалению, не все, но были ребята, которые сделали даже ALS1!&lt;/p&gt;
&lt;p&gt;В этом году на машинном обучении у студентов четвертого курса КТ тоже будет моя лекция — даже две (хотя это примерно то же самое, в прошлый раз я читал чуть меньше двух пар, зато подряд без перерыва). Но я решил, что можно не останавливаться на достигнутом. Поэтому (та-да-да-дам-та-дам!) предложил студентам четвертого, пятого и шестого курсов серию факультативных лекций.&lt;/p&gt;</summary></entry></feed>