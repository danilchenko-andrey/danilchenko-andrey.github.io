<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>4ducks</title><link href="http://www.4ducks.ru/" rel="alternate"></link><link href="http://www.4ducks.ru/feeds/itmo.atom.xml" rel="self"></link><id>http://www.4ducks.ru/</id><updated>2014-10-18T11:05:00+04:00</updated><entry><title>ITMO RS 2014 ~ Lecture 1</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-1.html" rel="alternate"></link><updated>2014-10-18T11:05:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-18:itmo-rs-2014-lecture-1.html</id><summary type="html">&lt;h2&gt;Введение в рекомендательные системы&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Лекция-введение. Рассказывал про рекомендательные системы в целом, о том, какие они бываю и какие данные используют.
Разобрали kNN-модели и SVD, рассказал как применять SGD и ALS для обучения SVD. Поговорили про evaluation (общая схема и чуть более предметно про online-тестирование).&lt;/p&gt;
&lt;h3&gt;Ссылки&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/AndreyDanilchenko/itmo-recsys-course-autumn-2014-lecture1-introduction-knn-svd"&gt;Слайды к лекции&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.netflixprize.com/"&gt;Netflix Prize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sifter.org/~simon/journal/20061211.html"&gt;Netflix Update: Try this at home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Книги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ricci F. et al. &lt;a href="http://yadi.sk/d/pq3fcJgT9voSt"&gt;Recommender systems handbook.&lt;/a&gt; – Springer US, 2011.&lt;/li&gt;
&lt;li&gt;Celma O. &lt;a href="http://yadi.sk/d/l0ZSsEY69STGT"&gt;Music Recommendation and Discovery: The Long Tail, Long Fail, and Long Play in the Digital Music Space.&lt;/a&gt; – Springer, 2010.&lt;/li&gt;
&lt;li&gt;Jannach D. et al. &lt;a href="http://www.amazon.com/Recommender-Systems-Introduction-Dietmar-Jannach/dp/0521493366"&gt;Recommender systems: an introduction.&lt;/a&gt; – Cambridge University Press, 2010.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Статьи&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Koren Y., Bell R., Volinsky C. &lt;a href="https://yadi.sk/i/CGSXNzr4c89ZY"&gt;Matrix factorization techniques for recommender systems&lt;/a&gt; //Computer. – 2009. – Т. 42. – №. 8. – С. 30-37.&lt;/li&gt;
&lt;li&gt;Koren Y. &lt;a href="http://yadi.sk/d/pTVIQqFP6TjWm"&gt;Factorization meets the neighborhood: a multifaceted collaborative filtering model&lt;/a&gt; //Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. – ACM, 2008. – С. 426-434.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Предыстория лекций в ИТМО</title><link href="http://www.4ducks.ru/predystoriia-lektsii-v-itmo.html" rel="alternate"></link><updated>2014-10-15T18:50:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-15:predystoriia-lektsii-v-itmo.html</id><summary type="html">&lt;p&gt;В осеннем семестре 2014 года я провожу факультативный курс лекций по рекомендательным системам в &lt;a href="http://www.ifmo.ru/"&gt;СПб НИУ ИТМО&lt;/a&gt; на кафедре КТ ФИТиП.&lt;/p&gt;
&lt;h1&gt;Предыстория&lt;/h1&gt;
&lt;p&gt;В далеком 2012 году Антон Банных предложил мне рассказать его студентам что-нибудь про анализ данных и применение машинного обучения в Яндексе. В тот момент я начал заниматься рекомендательными системами и уже имел некоторые знания области. Я согласился и рассказал студентам четвертого курса основы рекомендаций. Но это были действительно основы — я сделал упор на &lt;a href="http://en.wikipedia.org/wiki/Association_rule_learning"&gt;ассоциативные правила&lt;/a&gt; и &lt;a href="http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"&gt;метод ближайших соседей&lt;/a&gt;. Немного рассказал про SVD, еще меньше - про оценку рекомендаций. Так сказать, первый блин вышел комом.&lt;/p&gt;
&lt;p&gt;На следующий год мои познания в области существенно выросли, как и умение рассказывать эти самые азы. Я снова углубился в создание рекомендаций для Яндекс.Музыки, на этот раз в компании московских коллег. И для "быстрого старта" сделал парочку семинаров для коллег по основам коллаборативной фильтрации. И ребятам польза, и у меня в голове знания еще раз уложились.&lt;br /&gt;
В результате я уже сам предложил Антону свою помощь. На мой взгляд, лекция удалась — я за короткое время сделал обзор простых, но в то же время хорошо работающих методов коллаборативной фильтрации (SVD и kNN — да! как показывает RecSys его до сих много кто использует), немного пробежался по контентным методам и уделил время более подробному (относительно прошлого раза) рассказу про оценку.
Кроме того, в этот год к обычным лабораториям по машинному обучению добавилась лабораторная по рекомендациям, где я предлагал на данных movielens обучить SVD-алгоритм различными способами. Справились, к сожалению, не все, но были ребята, которые сделали даже ALS1!&lt;/p&gt;
&lt;p&gt;В этом году на машинном обучении у студентов четвертого курса КТ тоже будет моя лекция — даже две (хотя это примерно то же самое, в прошлый раз я читал чуть меньше двух пар, зато подряд без перерыва). Но я решил, что можно не останавливаться на достигнутом. Поэтому (та-да-да-дам-та-дам!) предложил студентам четвертого, пятого и шестого курсов серию факультативных лекций.&lt;/p&gt;</summary></entry></feed>