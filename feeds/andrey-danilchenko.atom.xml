<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>4ducks</title><link href="http://www.4ducks.ru/" rel="alternate"></link><link href="http://www.4ducks.ru/feeds/andrey-danilchenko.atom.xml" rel="self"></link><id>http://www.4ducks.ru/</id><updated>2015-11-16T14:00:00+03:00</updated><entry><title>ITMO ML course 2015 — RecSys lecture</title><link href="http://www.4ducks.ru/itmo-ml-course-2015-recsys-lecture.html" rel="alternate"></link><updated>2015-11-16T14:00:00+03:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2015-11-16:itmo-ml-course-2015-recsys-lecture.html</id><summary type="html">&lt;h2&gt;Рекомендательные системы&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Рассказ про рекомендательные системы в целом, о том, какие они бываю и какие данные используют.
Краткий разбор kNN-модели и SVD, рассказ о том, как применять SGD и ALS для обучения SVD. Обучение implicit SVD через iALS.
Методы построения объяснений к рекомендациям.
Обзор основных метрик качества
Модель Personalized Bayesian Ranking в качестве примера learning to rank framework.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/key/ozgNS4i2IgJ7ug" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Ссылки&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.netflixprize.com/"&gt;Netflix Prize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sifter.org/~simon/journal/20061211.html"&gt;Netflix Update: Try this at home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Книги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ricci F. et al. &lt;a href="http://yadi.sk/d/pq3fcJgT9voSt"&gt;Recommender systems handbook.&lt;/a&gt; – Springer US, 2011.&lt;/li&gt;
&lt;li&gt;Celma O. &lt;a href="http://yadi.sk/d/l0ZSsEY69STGT"&gt;Music Recommendation and Discovery: The Long Tail, Long Fail, and Long Play in the Digital Music Space.&lt;/a&gt; – Springer, 2010.&lt;/li&gt;
&lt;li&gt;Jannach D. et al. &lt;a href="http://www.amazon.com/Recommender-Systems-Introduction-Dietmar-Jannach/dp/0521493366"&gt;Recommender systems: an introduction.&lt;/a&gt; – Cambridge University Press, 2010.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Статьи&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Koren Y., Bell R., Volinsky C. &lt;a href="https://yadi.sk/i/CGSXNzr4c89ZY"&gt;Matrix factorization techniques for recommender systems&lt;/a&gt; //Computer. – 2009. – Т. 42. – №. 8. – С. 30-37.&lt;/li&gt;
&lt;li&gt;Koren Y. &lt;a href="http://yadi.sk/d/pTVIQqFP6TjWm"&gt;Factorization meets the neighborhood: a multifaceted collaborative filtering model&lt;/a&gt; //Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. – ACM, 2008. – С. 426-434.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;li&gt;Hu Y., Koren Y., Volinsky C. &lt;a href="http://yadi.sk/d/b4BEAs5t6NUOp"&gt;Collaborative filtering for implicit feedback datasets&lt;/a&gt; //Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on. – IEEE, 2008. – С. 263-272.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;li&gt;Takács G., Tikk D. &lt;a href="http://yadi.sk/d/lg6F-o6j6y9qq"&gt;Alternating least squares for personalized ranking&lt;/a&gt; //Proceedings of the sixth ACM conference on Recommender systems. – ACM, 2012. – С. 83-90.&lt;/li&gt;
&lt;li&gt;Herlocker J. L., Konstan J. A., Riedl J. &lt;a href="https://yadi.sk/i/ebMoIaU0cGHHy"&gt;Explaining collaborative filtering recommendations&lt;/a&gt; //Proceedings of the 2000 ACM conference on Computer supported cooperative work. – ACM, 2000. – С. 241-250.&lt;/li&gt;
&lt;li&gt;Rendle S. et al. &lt;a href="http://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf"&gt;BPR: Bayesian personalized ranking from implicit feedback&lt;/a&gt; //Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. – AUAI Press, 2009. – С. 452-461.&lt;/li&gt;
&lt;li&gt;Rendle S., Freudenthaler C., Schmidt-Thieme L. &lt;a href="http://yadi.sk/d/ZF5CzaWq7V3kE"&gt;Factorizing personalized markov chains for next-basket recommendation&lt;/a&gt; //Proceedings of the 19th international conference on World wide web. – ACM, 2010. – С. 811-820.&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Заметки с RecSys 2015</title><link href="http://www.4ducks.ru/zametki-s-recsys-2015.html" rel="alternate"></link><updated>2015-11-14T18:00:00+03:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2015-11-14:zametki-s-recsys-2015.html</id><summary type="html">&lt;p&gt;Содержимое флэшки: &lt;a href="https://yadi.sk/d/ryRQA8iGjDo8r"&gt;https://yadi.sk/d/ryRQA8iGjDo8r&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Среда&lt;/h2&gt;
&lt;h3&gt;Tutorials&lt;/h3&gt;
&lt;h4&gt;Replicable Evaluation of Recommender Systems&lt;/h4&gt;
&lt;p&gt;Рассказывали Said и Bellogin.&lt;/p&gt;
&lt;p&gt;Главная идея, которую они хотят донести уже несколько лет — reproducibility исследований. Очень много статей, которые на одном датасете одним алгоритмом репортят разные результаты. Даже фреймворки этим грешат, у MyMediaLite и Mahout, например, расходится evaluation.&lt;/p&gt;
&lt;p&gt;Обычно рекоммендер считается черным ящиком, а все остальное известно.
Предложенный подход: считать все компоненты черным ящиком (split, recommender, evaluation, candidates, metrics etc)
Если рекоммендер черный ящик и не может предсказать скор, то это влияет на item coverage. Поэтому нужно coverage (user|item) тоже репортить.&lt;/p&gt;
&lt;p&gt;Дальше рассказывали про метрики и их особенности на разных фреймворках.&lt;/p&gt;
&lt;p&gt;Важное понимание: replicability vs reproducibility.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/recommenders/tutorial"&gt;https://github.com/recommenders/tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Сначала replicate: это просто копируем все (данные, алгоритм, метрики, сплиты и тд). Результаты должны совпасть.
Потом reproduce: замеряем experimental setup на свой.
Ну и еще можно reuse, это если мы оставляем только базовый подход (например, как метрику мерить), а все остальное меняем.&lt;/p&gt;
&lt;p&gt;Короче, вывод: логгировать все и начинать с replicate.&lt;/p&gt;
&lt;h4&gt;Scalable RS, where ML meets search&lt;/h4&gt;
&lt;p&gt;Рассказывали Joachin Delgado и Diana Hu&lt;/p&gt;
&lt;p&gt;Общая идея заключается в том, что можно переформулировать различные подходы к рекомендациям (CF, CB, Knowledge based) как запросы к поиску.
Эту идею они развивают в плагин к elasticsearch, который умеет поверх стандартного поиска (в который можно легко вкручивать ранжирование на основе бизнес-правил) добавлять ранжирование по коллаборативке (конкретно, matrix factorization). Собственно, сначала они обучают модель на спарке, потом сериализуют ее в файл и раскидывают по машинкам ES. Все это интересная идея, насколько я понимаю, это получается фактически ранжирование на базовых.
Плюс, такое легко собрать, ES очень удобно и просто конфигурируется. Можно делать цепочки из переранжирований, засовывая туда разные бизнес-правила. ES сам все масштабирует.
Плагинчик доступен как proof of concept. Но в go90 (стартап Verison) они это уже используют: &lt;a href="https://github.com/sdhu/elasticsearch-prediction"&gt;https://github.com/sdhu/elasticsearch-prediction&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Keynote: A (Persuasive?) Speech on Automated Persuasion&lt;/h3&gt;
&lt;p&gt;Очень странный кейноут, никто кажется не понял, какое это ввобще имеет отношение к рекомендациям.
Чуваки построили систему, которая автоматически перестраивает фразы, добавляя более выраженную эмоциональную окраску. Например, good dish =&amp;gt; delicious dish. И тому подобные системы, о которых и шла речь.&lt;/p&gt;
&lt;h3&gt;Social RS&lt;/h3&gt;
&lt;h4&gt;Overlapping Community Regularization for Rating Prediction in Social Recommender Systems&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/2AOreTfPjDQGh"&gt;https://yadi.sk/i/2AOreTfPjDQGh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Строится комбинация MF (обычная и обусловленная влиянием друзей), это STE (метод 2009 года). К этому прибавили способ сделать граф друзей более плотным: использование communities. Но кроме всего прочего эти communities (которые не естественные группы соцсети, а автоопределяемые) могут перекрываться. И статья как раз о том, что в этом случае делать.&lt;/p&gt;
&lt;p&gt;MFC: использовать всех членов community в разложении
MFC+: использовать только профиль community (который средний профиль всех пользователь)&lt;/p&gt;
&lt;p&gt;Замеряют RMSE и говорят о том, что стало лучше на cold start :/
MFC+ оказывается лучше на больших RMSD (где мнение community не согласовано)&lt;/p&gt;
&lt;h4&gt;Preference-oriented Social Networks: Group Recommendation and Inference&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/lGNdWeIOjDQJM"&gt;https://yadi.sk/i/lGNdWeIOjDQJM&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Рекомендации группе пользователей. Хочется принять решение для группы, но ее предпочтения неизвестны. Метод использует социальный граф, похожесть предпочтений определяется вероятностью иметь ребро в графе. Это приводит к чуть более сложной модели, потому что известные рейтинги теперь зависимые переменные.&lt;/p&gt;
&lt;p&gt;Алгоритм: по известным предпочтениям строим inferred preferences, затем уже их используем, чтобы делать group recommendations.&lt;/p&gt;
&lt;p&gt;Evaluation на синтетических данных.&lt;/p&gt;
&lt;h4&gt;A Probabilistic Model for Using Social Networks in Personalized Item Recommendation&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/27nrdvfIjDQNo"&gt;https://yadi.sk/i/27nrdvfIjDQNo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Слайды: &lt;a href="http://ajbc.io/projects/presentations/recsys2015.pdf"&gt;http://ajbc.io/projects/presentations/recsys2015.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Какие-то предпочтения пользователей обусловлены социальным влиянием. 
Используюю графическую модель: social poisson factorization: &lt;a href="https://yadi.sk/i/Px_UsNJ4jDQYB"&gt;https://yadi.sk/i/Px_UsNJ4jDQYB&lt;/a&gt;, там все очень похоже на графическую модель для обычного MF, но еще добавляется влияние профилей связанных пользователей.&lt;/p&gt;
&lt;p&gt;Замеряли nCRR (как nDCG, только без логарифмического затухания).&lt;/p&gt;
&lt;h4&gt;PushTrust: An Efficient Recommendation Algorithm by Leveraging Trust and Distrust Relations&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/RAumxUZdjDQmr"&gt;https://yadi.sk/i/RAumxUZdjDQmr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Вводятся понятия trust и distrust. Trust транзитивен (вот это еще под вопросом), а distrust нет.&lt;/p&gt;
&lt;p&gt;Дальше добавляем оба в регуляризацию: прижимаемся к доверенным пользователям и стремимся уйти от недоверенных. Оптимизация SGD, по RMSE хорошо на cold users (cold в смысле рейтинга, но не в смысле trust)&lt;/p&gt;
&lt;h3&gt;The User in the Loop&lt;/h3&gt;
&lt;h4&gt;Letting Users Choose Recommender Algorithms: An  Experimental Study&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/fpryDPCPjNQPb"&gt;https://yadi.sk/i/fpryDPCPjNQPb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Что будет, если дать пользователю возможность выбирать алгоритм рекомендаций? Сравнивали четыре алгоритма: user-item, group-based, item-item, FunkSVD. Сравнивали на MovieLens на пользователях с историей. Первый алгоритм назначался случайно. 25% переключились хотя бы раз, 72% в итоге стали использовать алгоритм, отличный от начального.&lt;/p&gt;
&lt;h4&gt;"I like to explore sometimes": Adapting to Dynamic User Novelty Preferences&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/_syihnfBjNQXZ"&gt;https://yadi.sk/i/_syihnfBjNQXZ&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Пользователям иногда нравится, чтобы им рекомендовали что-то новое/неожиданное. Это желание меняется во времени. Модели вроде user-item или item-item ломаются, если у пользователя внезапно поменяются предпочтения.&lt;/p&gt;
&lt;p&gt;Familiar items определяются как множество всех айтемов, который пользователь потребил за недавнее время. Желание увидеть новое определяется как доля новых айтемов среди familiar items. На данных видно, что это желание отличается у разных юзеров в один и тот же момент времени, а у одного юзера может меняться во времени. Предлагается строить логистическую регрессию, которая будет предсказывать желание пользователя увидеть что-то новое в ближайшем будущем. Признака два: разнообразие familiar item set и negative preference for items in familiar set (насколько ему наскучили текущие айтемы; измеряется какой-то марковской моделью из другой статьи). Экспериментировали на lastfm и NDA-датасете.&lt;/p&gt;
&lt;h2&gt;Четверг&lt;/h2&gt;
&lt;h3&gt;Cold Start&lt;/h3&gt;
&lt;h4&gt;ExcUseMe: Asking Users to Help in Item Cold-Start Recommendations&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/tPb25TgLjDR3K"&gt;https://yadi.sk/i/tPb25TgLjDR3K&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yahoo labs&lt;/p&gt;
&lt;p&gt;Ad recommendations, очень сильный item cold start. Стандартный подход: давать пользователям на explore с фиксированным по item бюджетом (если грубо, то какое-то определенное количество раз). Здесь предлагается идея оптимизировать вероятность получения implicit feedback. Алгоритм: оптимизируется специальный вектор V_useme, ищем пользователя, отличного от тех, кто не дает фидбек, затем ищем пользователей, близких к тем, кто дал фидбек.&lt;/p&gt;
&lt;p&gt;На маленьких бюджетах дает хорошее отличие по RMSE, вероятность получить хотя бы один feedback примерно такая же, а по среднему числу implicit feedback метод дает лучший результат.&lt;/p&gt;
&lt;h4&gt;Cold-Start Item and User Recommendation with Decoupled Completion and Transduction&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/URexaSJ8jDRZh"&gt;https://yadi.sk/i/URexaSJ8jDRZh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Решают matrix completion problem, разбивая на низкоранговые подматрицы и уже на них по очереди запускают matrix completion с учетом уже заполненных частей. Подматрицу, где запустить определяют по максимальным собственным векторам.&lt;/p&gt;
&lt;h4&gt;HyPER: A Flexible and Extensible Probabilistic Framework for Hybrid Recommender Systems&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/TJQurbVWjDRo9"&gt;https://yadi.sk/i/TJQurbVWjDRo9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Строится двудольный граф рейтингов, в которых добавляются дополнительные ребра, чтобы закодировать новую информацию. Дальше через probabilistic soft logic строятся правила, которые они умеют превращать в loss function, чтобы оптимизировать.&lt;/p&gt;
&lt;h3&gt;Distinguished papers&lt;/h3&gt;
&lt;h4&gt;Applying Differential Privacy to Matrix Factorization&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/ne5g71uNjDTKE"&gt;https://yadi.sk/i/ne5g71uNjDTKE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;По рекомендациям, которые система дает пользователю, часто можно восстановить, что он смотрел/лайкал и тд.. Таким образом данные пользователя могут оказаться доступны злоумышленникам.&lt;/p&gt;
&lt;p&gt;Вводится шум в алгоритмы, который не сильно ухудшает качество, но делает трудным восстановление исходных рейтингов.&lt;/p&gt;
&lt;p&gt;Куда добавлять:
1. на входы
2. в SGD
3. в ALS
4. в выходы (но тогда проблема станет невыпуклой)&lt;/p&gt;
&lt;p&gt;Private global effects: добавляем шум к bias-ам. В SGD добавляем шум к error-у. В ALS шум добавляется к результатам P и Q шагов.
Показывают, что RMSE получается несколько хуже, чем у исходных алгоритмов, но все же лучше, чем у просто bias-ов. Забавно, что private kNN сильно лучше. Это объясняется тем, что он вероятно, более устойчив к шуму в данных.&lt;/p&gt;
&lt;h4&gt;Gaussian Ranking by Matrix Factorization&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/0cA-6A6VjDTP6"&gt;https://yadi.sk/i/0cA-6A6VjDTP6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Netflix&lt;/p&gt;
&lt;p&gt;MF представляется в виде трехслойной нейросети. Дальше к этой сети добавляют еще два слоя поверх output (первый превращает score в ранк, второй применяет activation function, например logit). Все это оптимизируется SGD.
Таким образом удается оптимизировать всякие разные функции ранжирования. По AUC их метод близок к SVD, по Recall@N сильно лучше.&lt;/p&gt;
&lt;h4&gt;Context-Aware Event Recommendation in Event-based Social Networks&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/UK3DnJOQjDTeG"&gt;https://yadi.sk/i/UK3DnJOQjDTeG&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best paper&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Мне выбор этой статьи в качестве best paper не понравился, хотя может быть, я не проникся.
Речь идет о соцсети meetup.com, в которой пользователи создают события (например, прогулка на велосипедах вдоль озера завтра утром) и могут приглашать участников. Ну и соответственно, есть рекомендации этих самых событий.
Проблемы следующие: 
&lt;em&gt; события всегда в будущем, то есть про них мало что известно, кроме тех, кто принял. Отношение их к событиям неизвестно.
&lt;/em&gt; про большинство пользователей почти ничего не известно&lt;/p&gt;
&lt;p&gt;Group frequency: чем чаще пользователь принимает события группы, в которой состоит, тем больше вероятность, что примет следующее.
Используют BPR и еще кучу хаков про контент (например, context через TF-IDF, модель для location и времени и тд). Все это засовывается в learning to rank.
Все это очень хорошо работает на cold start, результаты по nDCG@10 жгут.&lt;/p&gt;
&lt;h3&gt;Industry 1&lt;/h3&gt;
&lt;h4&gt;Complicated TV made easy, again&lt;/h4&gt;
&lt;p&gt;Contentwise&lt;/p&gt;
&lt;p&gt;Рассуждения о том, что в рекомендациях нужно использовать контекст.&lt;/p&gt;
&lt;h4&gt;The Application of Recommender Systems in a Multi Site, Multi Domain Environment&lt;/h4&gt;
&lt;p&gt;Schibsted, как авито только в разы больше&lt;/p&gt;
&lt;p&gt;Стремились избавиться от popularity effect (слишком много покупателей получают отказ, а продавцу приходит много сообщений)
Качество объявления вообще очень странная штука, ее трудно понять по взаимодействию пользователей с карточкой
Сегментировали пользователей на две категории:
&lt;em&gt; transactional users: CF работает плохо, но гибридные методы ок
&lt;/em&gt; buyers: показывают все категории одновременно, и новое и хорошо знакомое&lt;/p&gt;
&lt;h4&gt;We Know Where You Should Work Next Summer: Job Recommendations&lt;/h4&gt;
&lt;p&gt;Xing, европейский аналог linkedin&lt;/p&gt;
&lt;p&gt;Обучают логистическую регрессию на простых факторах, делают ранжирование, поверх запускают фильтры и разнообразие.&lt;/p&gt;
&lt;p&gt;Проблема: пользовательский профиль показывает прошлое, но не будущие шаги (например, если чувак только что закончил PhD, то ему будут рекомедовать позиции в универах, но он-то может хотеть в индустрию!). Решение: граф переходов между позициями (строится через arules). По CTR очень хорошо помогает, acceptance rate не смотрели.&lt;/p&gt;
&lt;h4&gt;Assessing Expertise in the Enterprise: The Recommender Point of View&lt;/h4&gt;
&lt;p&gt;IBM research&lt;/p&gt;
&lt;p&gt;Есть развесистое дерево skill-ов на linkedin, очень трудно формализовать. В IBM каждый skill имеет формализованное описание, но при добавлении скилла очень трудно заполнить все правильно. И они стали использовать ML, чтобы предсказывать скиллы человека&lt;/p&gt;
&lt;p&gt;Есть карточка сотрудника &lt;a href="https://yadi.sk/i/xm0OwHVRjDWFU"&gt;https://yadi.sk/i/xm0OwHVRjDWFU&lt;/a&gt;, но там маловато полезного. Зато можно выделить что-то из текста, который написал сам человек.
&lt;em&gt; сколько-то от HR
&lt;/em&gt; сколько-то из внутренней соцсети и тд&lt;/p&gt;
&lt;p&gt;Tasks:
1. predict fine skills
2. predict job role
3. predict expertise in broad areas&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Matrix completion like usual CF
recommending new skills: используют tfidf на основе тэгов у скилла&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;чтобы понимать, сколько у них экспертов в области, когда запускается проект.
про каждую область собирают тэги&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Пятница&lt;/h2&gt;
&lt;h3&gt;Novel setups&lt;/h3&gt;
&lt;h4&gt;It Takes Two to Tango: an Exploration of Domain Pairs for Cross-Domain Collaborative Filtering&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/LUGr1djyjDWhu"&gt;https://yadi.sk/i/LUGr1djyjDWhu&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Слайды: &lt;a href="http://www.slideshare.net/chagh/it-takes-two-to-tango-an-exploration-of-domain-pairs-for-crossdomain-collaborative-filtering"&gt;http://www.slideshare.net/chagh/it-takes-two-to-tango-an-exploration-of-domain-pairs-for-crossdomain-collaborative-filtering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Делают cross-domain CF. Но как определить, поможет ли данный домен или нет?
Вводят canonical correlation analysis между доменами. Matrix factorization в target домене выражается через проекцию source domain-а и новые коэффициенты.
Смотрели на yelp dataset, 21 категория, рейтинги.&lt;/p&gt;
&lt;p&gt;CCA очень хорошо коррелирует с улучшениями по cross domain CCA рекомендациям. Но объяснить это формально пока не удается. Ну и все это лучше, чем просто SVD по всему датасету.&lt;/p&gt;
&lt;p&gt;В кулуарах пообщались со Шломо Берковским (один из отцов cross-domain рекомендаций), он рассказал, что готовится к изданию вторая редакция хэндбука, даже прислал мне драфт своей главы про cross domain. Но это походу туториал Cremonesi с прошлого рексиса, положенный на бумагу.&lt;/p&gt;
&lt;p&gt;toc: &lt;a href="https://yadi.sk/i/PRGV8PL0jDbax"&gt;https://yadi.sk/i/PRGV8PL0jDbax&lt;/a&gt;
их глава: &lt;a href="https://yadi.sk/i/LgLF029hjDbWg"&gt;https://yadi.sk/i/LgLF029hjDbWg&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Recommending Fair Payments for Large-Scale Social Ridesharing&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/fSj9B1VfjDWtg"&gt;https://yadi.sk/i/fSj9B1VfjDWtg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Соцсеть шаринга поездок на машине. Смотрят на оптимальные "коалиции" среди друзей по соцсети. Проблема: как посчитать стоимость поездки для каждого участника. Ввели мутную идею стабильности платежа, чтобы уравновешивать платежи всех участников (хотя казалось бы, это не обязательно).&lt;/p&gt;
&lt;p&gt;Интересное следствие: чем больше степень вершины к соц-графе (больше друзей-соседей), тем меньше стоимость поездки. Логично, у человека больше шансов пошарить поездку с соседями.&lt;/p&gt;
&lt;h4&gt;Learning Distributed Representations from Reviews for Collaborative Filtering&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/Fy_FmcM2jDXDG"&gt;https://yadi.sk/i/Fy_FmcM2jDXDG&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Multitask learning - это еще один способ сделать регуляризацию. Идея в том, что вместо обычной L2 регуляризации добавляется еще одна оптимизационная задача из другого домена. В данном случае вместе с Matrix factorization учат модель (DBoW из word2vec и RecurrentNN) для описания текстов ревью.
Добавляли такую регуляризацию только по item векторам, пользовательские никак не регуляризуются (у них так получилось лучше). Обычной регуляризации нет. Получается лучше, чем просто регуляризованный SVD.&lt;/p&gt;
&lt;h3&gt;Industry&lt;/h3&gt;
&lt;h4&gt;Large-Scale Real-Time Product Recommendation At Criteo&lt;/h4&gt;
&lt;p&gt;800k rps!!!
&amp;lt;10ms на решение, &amp;lt;100ms на рекомендацию
largest Hadoop in Europe &amp;gt;35Pb&lt;/p&gt;
&lt;p&gt;1M+ catalogue / client
10k clients
~2B events/day behavioural data
20B shows / day&lt;/p&gt;
&lt;p&gt;На оффайне считают best, best of, similarities (250M keys), complementaries (50M keys). В рантайме все хранять в memcache. Для ML используют logistic regression ("scales and fast", хотя кажется, что можно было и поинтереснее что-нибудь), используя hashing trick.
На оффлайне используют машину времени и работают над counterfactual reasoning.
Есть датасет на kaggle&lt;/p&gt;
&lt;h4&gt;Challenges Encountered Scaling Up Recommendation Services&lt;/h4&gt;
&lt;p&gt;Gravity R&amp;amp;D
В основном был рассказ о подводных камнях, которые находили в GravityRD.&lt;/p&gt;
&lt;p&gt;Очень быстро отвечают: 10-30мс, 140M requests/day
200+ серверов, 3500+ сервисов в мониторинге, 4 dc
Как хранить модель и метаданные в памяти? много item-ов, скоро выберут int для размера каталога.
Обнаружили, что CTR падал утром - большая часть видео загружалась утром, стали запускали обучение почаще к этому периоду.
Реализовано больше 100 алгоритмов, но самые простые работают в большинстве задач.&lt;/p&gt;
&lt;p&gt;В кулуарах порасспрашивал поподробнее. У них все в памяти, стараются максимально использовать offline и near realtime (например, kNN обновляется с SLA 5 секунд!). Нарывались на баги в gc. В результате пришли к схеме, где gc планируется. Машинку отключают от траффика, запускают full gc, потом снова включают трафик.
Есть команда исследований 4 человека (Балаш Хидаси руководит), которая занимается новыми разработками. Они имплементят почти все интересные алгоритмы, которые находят в статьях. Есть команда, которая пилит общие компоненты, есть команда, которая подключает клиентов. Само подключение занимает от 48 часов до года в зависимости от сложности области и данных. Хотят давать js-блок, чтобы в пару кликов подключать данные клиента. Каждый месяц у клиента есть один день сотрудника поддержки. Но обычно первые полгода-год ничего не допиливают. Вот уже дальше могут быть улучшения.&lt;/p&gt;
&lt;h4&gt;Recommendations in Travel&lt;/h4&gt;
&lt;p&gt;booking.com&lt;/p&gt;
&lt;p&gt;Стандартные MF методы в их области не работают =( Кроме того, очень высока цена неверной рекомендации. В результате у них очень много чего выделяется из текстов и делается CB. Плюс, они рассказывают про все ML алгоритмы внутри отелям. Это часть правил честного ранжирования.&lt;/p&gt;
&lt;h4&gt;Making Meaningful Restaurant Recommendations At OpenTable&lt;/h4&gt;
&lt;p&gt;32k ресторанов, 17M посетителей seated monthly
Для похожестей ials и CB смешанные как a/r1 + (1-a)/r2&lt;/p&gt;
&lt;p&gt;Активно используют word2vec для поиска зависимостей (например, могут порекомендовать подходящее вино). Кроме того, с помощью word2vec решают задачу рекомендации в незнакомом городе.&lt;/p&gt;
&lt;p&gt;Ранжирование делается через one vs all логистической регрессией с l1 регуляризатором. Но начали делать factorization machines, чтобы засовывать контексты.&lt;/p&gt;
&lt;h4&gt;The Role of User Location in Personalized Search and Recommendation&lt;/h4&gt;
&lt;p&gt;Ido Guy, Yahoo labs&lt;/p&gt;
&lt;p&gt;Рассказывал, как отличается поиск из знакомых и незнакомых мест. Определяют знакомые места по тому, как часто видели там пользователя (тут очень трудно, если пользователь поехал надолго в отпуск).
Вся эта техника отлично помогает делать поисковые подсказки.&lt;/p&gt;
&lt;h3&gt;News and Media&lt;/h3&gt;
&lt;h4&gt;Predicting Online Performance of News Recommender Systems Through Richer Evaluation Metrics&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/DkRWIMWRjDZsV"&gt;https://yadi.sk/i/DkRWIMWRjDZsV&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Хотят изобрести такую метрику, которая будет на offline работать так же, как на online.&lt;/p&gt;
&lt;p&gt;Метрики: accuracy, diversity, coverage, serendipity, novelty, etc. Дальше учат комбинацию метрик, чтобы правильно предсказывать CTR.&lt;/p&gt;
&lt;p&gt;Пошли дальше и подобрали параметры алгоритма на offline и через AB. Результаты сошлись.&lt;/p&gt;
&lt;p&gt;Еще интересно, что accuracy имеет не самую лучшую корреляцию с CTR.&lt;/p&gt;
&lt;h3&gt;Beyond “Hitting the Hits” – Generating Coherent Music Playlist Continuations with the Right Tracks&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://yadi.sk/i/Ytoert3djDa65"&gt;https://yadi.sk/i/Ytoert3djDa65&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Дитмар Яннах и компания в своем универе строят online радио (но чисто для науки, даже прототипа нет).&lt;/p&gt;
&lt;p&gt;Построение радио состоит из двух фаз: сначала ранжируют (kNN + тэги от last.fm) и отбирают top-30 треков. Затем выбирают перестановку, оптимальную с точки зрения разницы в числовых фичах с предыдущей историей пользователя. Так радиопоток становится более когерентным.&lt;/p&gt;
&lt;h2&gt;Суббота&lt;/h2&gt;
&lt;p&gt;день неинтересных воркшопов&lt;/p&gt;
&lt;h3&gt;RecSysTV&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.contentwise.tv/recsystv2015/"&gt;http://www.contentwise.tv/recsystv2015/&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Recommending TV News and Circumventing The Filter Bubble&lt;/h4&gt;
&lt;p&gt;Thomson Reuters&lt;/p&gt;
&lt;p&gt;примерно 2M историй, 200k видео
mobile news broadcast app
startup in 2014
500000 downloads
25k WAU
60 news stories per day&lt;/p&gt;
&lt;p&gt;Рассказывали про рекомендации в своем приложении. Только implicit feedback и сильный cold start. Персонализация по времени суток и геолокации. К каждому ролику добавляют метаданные: настроение, описание, формат, название, автор и тд. Автоматически по описанию определяют темы, есть авторазметка объектов и организаций.&lt;/p&gt;
&lt;p&gt;Модели: hierarchical bayesian networks, beta regression
play распределены по Бернулли? на самом деле нет
true pref ~ Beta(a, b)
play|pref ~ Bernoulli(pref)
Еще проблема в том, что на самом деле мы не знаем много про пользователя, делают explore exploit. Knowledge gradient хорошо работает когда совсем мало данных, потом томсон сэмплинг (как именно непонятно было).
Для сборки эфира используют "dynamic programming optimal solution".&lt;/p&gt;
&lt;h4&gt;Social video recommendations: From the ground up&lt;/h4&gt;
&lt;p&gt;Verison&lt;/p&gt;
&lt;p&gt;Рассказывали про свой стартап go90 (запустится на днях). Суть в том, что они комбинируют обычный видеоконтент с роликами из интернета. Проблемы в основном с метаданными. Делают очень много NLP, включая субтитры! Начали делать computer vision на видеопотоке.&lt;/p&gt;
&lt;p&gt;Как раз тут используют свой плагин к Elasticsearch.&lt;/p&gt;
&lt;h4&gt;Relevance of Social Data in Video Recommendation&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://comcast.app.box.com/recsystv-2015-xu"&gt;https://comcast.app.box.com/recsystv-2015-xu&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Adobe research&lt;/p&gt;
&lt;p&gt;С одной стороны есть рейтинги фильмов, с другой стороны данные твиттера. Сделали приложение movie tweeting app.&lt;/p&gt;
&lt;p&gt;dataset: 27500 users, 161k movies, 239k ratings, 41023 followings
Очень сильно его проредили и устроили линейную комбинацию kNN-ов по рейтингам и соцсети (коэффициент похожести по соцсети может меняться с силой связи). Еще пробовали совместную оптимизацию MF по двум матрицам (от соцсети и рейтингов) и factorization machines. Их подход, конечно же, лучше. Но данных там осталось как кот наплакал, скорее всего, это все не значимо.&lt;/p&gt;
&lt;h4&gt;Using Social Media data for Online Television Recommendation Services at RTÉ Ireland&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://comcast.app.box.com/recsystv-2015-barraza-urbina"&gt;https://comcast.app.box.com/recsystv-2015-barraza-urbina&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Похоже на предыдущую.&lt;/p&gt;
&lt;p&gt;С одной стороны preferences из их сервиса, с другой стороны implicit информация из твиттера. Из твита выделяют конкретную программу и эпизод плюс открытые каталоги IMDB, DBPedia.&lt;/p&gt;
&lt;p&gt;Связывают user x tweet и tweet x program матрицы.&lt;/p&gt;
&lt;h4&gt;Exploiting crowdsourced movie reviews to explain recommendation&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://comcast.app.box.com/recsystv-2015-aouad"&gt;https://comcast.app.box.com/recsystv-2015-aouad&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Можно показывать просто похожие item-ы, но хочется объяснять.&lt;/p&gt;
&lt;p&gt;Идея: разделим похожести на группы по жанру и будем персонализировать эти группы пользователю.&lt;/p&gt;
&lt;p&gt;Разбиение по жанрам, для объяснения выделяют слова из тем от LDA. Внутри группы ранжирование по MF методу.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muse.inria.fr/tagit"&gt;http://muse.inria.fr/tagit&lt;/a&gt;
данные: 2k фильмов c IMDB, 100 пользователей =(&lt;/p&gt;
&lt;h4&gt;How smart is your data? The new differentiator for video operators&lt;/h4&gt;
&lt;p&gt;Spideo&lt;/p&gt;
&lt;p&gt;лучший способ делать рекомендации должен включать общение на натуральном языке!
Делают динамически меняющийся текстовый профиль пользователя.&lt;/p&gt;
&lt;p&gt;Еще у них клевые дашборды: например, в разрезе по настроениям сколько всего фильмов, сколько просмотрено, сколько порекомендовано.&lt;/p&gt;
&lt;h4&gt;Context-aware LDA: Balancing Relevance and Diversity in TV Content Recommenders&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://comcast.app.box.com/recsystv-2015-yuan"&gt;https://comcast.app.box.com/recsystv-2015-yuan&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Есть данные видеоплатформы, выкидывают проигрывания &amp;lt; 15 секунд и &amp;lt; 15% и пользователей &amp;lt; 10 просмотров.&lt;/p&gt;
&lt;p&gt;Контекст: live/vod и время (time of day, day of week)&lt;/p&gt;
&lt;p&gt;Просто LDA работает плохо, а вот context-LDA (добавили контексты в графическую модель) начиная с первых десятков в размерности бьет их бейлайны по nDCG@K, recall@K&lt;/p&gt;
&lt;p&gt;Смотрят в тч в разрезе "просто рекомендации" и "с учетом текущей программы".&lt;/p&gt;
&lt;h4&gt;New Quality Measure of Linear Ads in Online Videos&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://comcast.app.box.com/recsystv-2015-kar"&gt;https://comcast.app.box.com/recsystv-2015-kar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Adobe&lt;/p&gt;
&lt;p&gt;linear ads (реклама встраивается в каком-то месте в ролик, например, в начале).
Оптимизируют continuation rate (средняя вероятность неуйти по всем просмотрам), используя utility рекламного ролика и линейную модель на фичах ролика.
В результате хорошо увеличивает метрики, еще оказывается, про preroll и первые мидроллы дают больше продолжающихся сессий.&lt;/p&gt;
&lt;h3&gt;CrowdRec&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.crowdrecworkshop.org"&gt;http://www.crowdrecworkshop.org&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Changing mobility behavior through recommendations&lt;/h4&gt;
&lt;p&gt;Идея в том, чтобы порекомедовать события куда пойти по дороге домой, чтобы переждать пробки.&lt;/p&gt;
&lt;p&gt;Посылают напоминания или прямо в приложении можно получить рекомендацию, дальше человек едет и участвует в том, что ему предложили, за это начисляются баллы и бейджи.&lt;/p&gt;
&lt;p&gt;Через некоторое время померили поведение людей, примерно половина приняла игру и изменила свое поведение.&lt;/p&gt;
&lt;h4&gt;An Adaptive Implicit Feedback Model for Short Clips Recommendations&lt;/h4&gt;
&lt;p&gt;Мутная статья про рекомендацию роликов. Длину проигрывания превращают в рейтинг (адаптивно подстраивая распределение по рейтингам). Кажется, можно и лучше.&lt;/p&gt;
&lt;h2&gt;Воскресенье&lt;/h2&gt;
&lt;p&gt;Интересный LSLR&lt;/p&gt;
&lt;h3&gt;Large scale RS&lt;/h3&gt;
&lt;h4&gt;Keynote: Scaling RS research&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://dato.com/files/lsrs2015/lsrs15_ekstrand.pdf"&gt;https://dato.com/files/lsrs2015/lsrs15_ekstrand.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Michael Ekstrand рассказывал про large scale evaluation. &lt;/p&gt;
&lt;p&gt;Идеи: 
&lt;em&gt; random search лучше, чем поиск по сетке
&lt;/em&gt; общие части алгоритмов надо переиспользовать (lenskit умеет dependency injection)
&lt;em&gt; некоторые гиперпараметры можно подбирать на очень маленьком подмножестве данных
&lt;/em&gt; из оффлайн тестов стоит выбрать лучшие, но очень разные! результаты для online теста. Оффлайн тесты часто не совпадают с онлайном, но эта история в основном про accuracy (см. статью EPFL).
* бандиты хороши, чтобы быстро найти лучший алгоритм. но будет очень трудно понять, почему он лучше.&lt;/p&gt;
&lt;h4&gt;Large scale music recommendation @ Pandora&lt;/h4&gt;
&lt;p&gt;Много вау-вау и бла-бла. Pandora всегда показывает красивые картинки, но очень чего не рассказывает из внутренней кухни.&lt;/p&gt;
&lt;p&gt;Внутри радио 50 моделей обучаются на разные таргеты, потом все это в ансамбль, который динамически подстраивается. Алгоритмы у них простые, но очень много данных. Параметры ансамбля персонализированы.&lt;/p&gt;
&lt;p&gt;В рекомендациях радиостанций идея оптимизировать не CTR, а конверсию. Это приводит к лучшему росту long-term метрик.&lt;/p&gt;
&lt;p&gt;UI (особенно на мобильниках) решает больше, чем качество алгоритмов.&lt;/p&gt;
&lt;h4&gt;Travoltify - The Dance moment&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://dato.com/files/lsrs2015/lsrs15_spotify.pdf"&gt;https://dato.com/files/lsrs2015/lsrs15_spotify.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Spotify&lt;/p&gt;
&lt;p&gt;Рекомендации музыки для определенного танца. В качестве примера взяли буги.&lt;/p&gt;
&lt;p&gt;Две ступени: 
1. word2vec на данных прослушивания, потом латентные вектора и дополнительные фичи засовывают в логистическую регрессию, чтобы классифицировать принадлежность к танцу
2. дальше выделяют подмножество каталога с высоким скором классификатора
3. запускают factorization machines на подмножестве (используя в тч dance relevance из предыдущего классификатора)&lt;/p&gt;
&lt;p&gt;Для обучения классификатора 76k треков танца (авторазметка?) и 125k рандом по популярности.&lt;/p&gt;
&lt;h4&gt;Large Scale Music Recommendation&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://dato.com/files/lsrs2015/lsrs15_turin.pdf"&gt;https://dato.com/files/lsrs2015/lsrs15_turin.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Contentwise&lt;/p&gt;
&lt;p&gt;Рекомендуют следующий трек на основе истории прослушиваний. Но все в offline тестах.&lt;/p&gt;
&lt;p&gt;Собрали датасет: &lt;a href="http://recsys.deib.polimi.it/?page_id=54"&gt;http://recsys.deib.polimi.it/?page_id=54&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Разбили данные на сессии и разделили на трейновые и тестовые сессии (данные за год, тест за 3 месяца, переобучения модели в ходе теста нет).&lt;/p&gt;
&lt;p&gt;Выиграли у очень странных бейзлайнов.&lt;/p&gt;
&lt;h4&gt;Neighbor methods vs. matrix factorization: case studies of real-life recommendations&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.slideshare.net/domonkostikk/neighbor-methods-vs-matrix-factorization-case-studies-of-reallife-recommendations-gravity-lsrs2015-recsys-2015"&gt;http://www.slideshare.net/domonkostikk/neighbor-methods-vs-matrix-factorization-case-studies-of-reallife-recommendations-gravity-lsrs2015-recsys-2015&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Доклад от Gravity, разрушающий легенды&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;После Netflix Prise они сделали демку для инвесторов. Но качество было плохое, шумела популярность. Убрали user bias, стало получше. Еще пробовали ставить bias-ы в ноль перед построением пользовательских профилей, тоже хорошо работало.&lt;/p&gt;
&lt;p&gt;Много занимаются item2item рекомендациями. В жизни данные устроены не так, как в соревнованиях: 1% explicit, 99% implicit. Много пользователей и item-ов и при этом очень жесткий SLA на рекоммендер. Проверяют i2i на трилогиях (нужно порекомендовать третью часть выше всех остальных фильмов), метрика жжет.
Но! Нужна очень большая размерность SVD, чтобы побить простейший kNN (типа 1500).
Смотрели на метод Корена, но в итоге взяли оттуда только метрику. Кореновские похожести лучше svd, но просто популярность по парам гораздо лучше обоих методов.
Переключились с iALS1 на item kNN и CTR удвоился! Такой простой метод бьет даже BPR (правда не на всех датасетах).&lt;/p&gt;
&lt;p&gt;Короче, вывод: у MF очень много недостатков, MF для item2item очень плохо работает.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;для плотных доменов ок&lt;/li&gt;
&lt;li&gt;для персонализованных рекомендаций ок&lt;/li&gt;
&lt;li&gt;для taste-based feedback ок&lt;/li&gt;
&lt;li&gt;лучше попробовать смешивание и обязательно AB&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Unifying the problem of Search and Recommendations at OpenTable&lt;/h4&gt;
&lt;p&gt;Поиск может использовать CF output как одну из фичей, еще нужно контекст, плюс что-то можно смайнить из NLP анализа запроса.&lt;/p&gt;
&lt;p&gt;Если нет данных, то хороши эвристические правила для выбора продуктов (суши плохо на завтрак), если мало данных - простые статистики.&lt;/p&gt;
&lt;p&gt;Есть metric gap (train error, generalization error, online error). Они используют online learning (бандитов), но надо обязательно валидировать через AB.&lt;/p&gt;
&lt;p&gt;Еще говорили про trust (типа не скрывать доступ к сырым данным). Например, у них новый пользователь читает все ревью, а потом уже начинает верить их рейтингу и рекомендациям.&lt;/p&gt;
&lt;h4&gt;Learning from Lack of Clicks, Learning from Lack of Likes: Two Applications in the Domain of Content Discovery&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://dato.com/files/lsrs2015/lsrs15_outbrain.pdf"&gt;https://dato.com/files/lsrs2015/lsrs15_outbrain.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Outbrain&lt;/p&gt;
&lt;p&gt;Рекомедовать одно и то же — не оптимальная стратегия. Смотрят на падение CTR в зависимости от того, когда и где и сколько раз пользователь уже видел эту рекомендацию.&lt;/p&gt;
&lt;p&gt;Вторая идея: users are likely to share socially acceptable content&lt;/p&gt;
&lt;h4&gt;Building Actionable Recommendations for Sellers to Help Improve their eBay&lt;/h4&gt;
&lt;p&gt;eBay&lt;/p&gt;
&lt;p&gt;Интересный доклад про рекомендацию цены, которую делают тому, кто размещает объявление на eBay.&lt;/p&gt;
&lt;p&gt;Смотрят на похожие продукты (по тексту и метаданным), потом вкручивают ML и бизнес-правила. Делают отдельно сэмплинг для недорогих продуктов, тк там их предсказание заметно хуже.&lt;/p&gt;
&lt;p&gt;Для B2C делают рекомендации вида: если вы повысите цену на 5$, то продажи упадут на столько-то. Но еще не в проде.&lt;/p&gt;
&lt;h3&gt;INRA&lt;/h3&gt;
&lt;p&gt;зачем-то сходил на два доклада из новостного воркшопа. Это все bullshit, очень слабые работы.&lt;/p&gt;
&lt;h4&gt;Survey of User Profiling in News Recommender Systems&lt;/h4&gt;
&lt;p&gt;бла-бла-бла про отличия от обычных рекоммендеров&lt;/p&gt;
&lt;p&gt;модель пользователя: выделение тем и сущностей (проблемы синонимов?)
Требуется учитывать время (например, день недели или время суток) и long-term/short-term preferences.&lt;/p&gt;
&lt;h4&gt;News2Images: Automatically Summarizing News Articles into Image-Based Contents via Deep Learning&lt;/h4&gt;
&lt;p&gt;Корейский NAVER&lt;/p&gt;
&lt;p&gt;Задача: по новости найти related картинки. word2vec на текстах, ищут похожие документы. Есть ConvNN, обученная на мультиклассификацию персон. Дальше по картинкам похожих документов запускают сеть и замеряют точность определения персоны. Мутная задача, кривой evaluation.&lt;/p&gt;
&lt;h3&gt;Content based RS&lt;/h3&gt;
&lt;h4&gt;The continuous cold-start problem in e-commerce recommender systems&lt;/h4&gt;
&lt;p&gt;Booking.com&lt;/p&gt;
&lt;p&gt;Работа моей бывшей коллеги из Яндекса. Перед отпуском в Питере общался с ее профом Яппом.&lt;/p&gt;
&lt;p&gt;идея: пользователь всегда в cold start.
как бороться?
- спросить пользователя (например, он для работы или отдыхать)
- implicit ratings (просто по просмотрам)
- popularity (очень хорошо работает!)
- content (item descriptions, user profiles etc)&lt;/p&gt;
&lt;p&gt;Используют mixed профиль пользователя (OS, browser etc, weekday) и предсказывают направление. На удивление, такого рода персонализация очень хорошо работает (+20% к CTR). Геолокацию пользователя еще не успели вкрутить, там пока только страна.&lt;/p&gt;</summary></entry><entry><title>ITMO RS 2014 ~ Lecture 6</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-6.html" rel="alternate"></link><updated>2014-12-20T12:00:00+03:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-12-20:itmo-rs-2014-lecture-6.html</id><summary type="html">&lt;h2&gt;Sequence recommenders&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Рекомендации последовательностей: постановка задачи, модели station-based и stationless. Похожести item2item. LME и расширения.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/42891684" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Материалы&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://yadi.sk/d/do6Q_y6j6buKY"&gt;Aizenberg N., Koren Y., Somekh O. Build your own music recommender by modeling internet radio streams //Proceedings of the 21st international conference on World Wide Web. – ACM, 2012. – С. 1-10.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.eng.tau.ac.il/~noamk/papers/item_based_recsys_2013.pdf"&gt;Koenigstein N., Koren Y. Towards scalable and accurate item-oriented recommendations //Proceedings of the 7th ACM conference on Recommender systems. – ACM, 2013. – С. 419-422.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yadi.sk/d/qrwWvb8SKPJCk"&gt;Chen S. et al. Playlist prediction via metric embedding //Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. – ACM, 2012. – С. 714-722.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yadi.sk/d/qrwWvb8SKPJCk"&gt;Chen S. et al. Playlist prediction via metric embedding //Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. – ACM, 2012. – С. 714-722.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.cornell.edu/People/tj/publications/chen_etal_13a.pdf"&gt;Chen S., Xu J., Joachims T. Multi-space probabilistic sequence modeling //Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. – ACM, 2013. – С. 865-873.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ismir2013.ismir.net/wp-content/uploads/2013/09/220_Paper.pdf"&gt;Moore J. L. et al. TASTE OVER TIME: THE TEMPORAL DYNAMICS OF USER PREFERENCES.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jimi.ithaca.edu/~dturnbull/research/lme/lmeDemo.html"&gt;LME demo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/pages/itmo-rs-2014.html"&gt;Содержание&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-5.html"&gt; &amp;lt;- Предыдущая лекция&lt;/a&gt;&lt;/p&gt;</summary></entry><entry><title>ITMO RS 2014 ~ Lecture 5</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-5.html" rel="alternate"></link><updated>2014-12-13T10:00:00+03:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-12-13:itmo-rs-2014-lecture-5.html</id><summary type="html">&lt;h2&gt;Deep learning&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Deep learning, полезный в рекомендательных системах. Модели NNLM, word2vec (CBOW и Skip-Gram), doc2vec (через кластеризацию) и Paragraph vector.
Сверточные сети на примере музыкальных рекомендаций.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/42666726" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Материалы&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://yadi.sk/d/j9uLwCDdNAYEk"&gt;Bengio Y. et al. Neural probabilistic language models //Innovations in Machine Learning. – Springer Berlin Heidelberg, 2006. – С. 137-186.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yadi.sk/d/ENgfjaU-ND4fn"&gt;Mikolov T. et al. Recurrent neural network based language model //INTERSPEECH. – 2010. – С. 1045-1048.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1301.3781.pdf"&gt;Mikolov T. et al. Efficient estimation of word representations in vector space //arXiv preprint arXiv:1301.3781. – 2013.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://code.google.com/p/word2vec/"&gt;Word2vec reference implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/2014/02/word2vec-tutorial/"&gt;Word2vec tutorial with Gensim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"&gt;Mikolov T. et al. Distributed representations of words and phrases and their compositionality //Advances in Neural Information Processing Systems. – 2013. – С. 3111-3119.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://yadi.sk/i/uAN34VkedLsG7"&gt;Morin F., Bengio Y. Hierarchical probabilistic neural network language model //AISTATS. – 2005. – Т. 5. – С. 246-252.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://musicweb.ucsd.edu/~sdubnov/Mu270d/SemanticWeb/PlaylistsMcFee.pdf"&gt;McFee B., Lanckriet G. R. G. The Natural Language of Playlists //ISMIR. – 2011. – С. 537-542.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://eng.kifi.com/from-word2vec-to-doc2vec-an-approach-driven-by-chinese-restaurant-process/"&gt;Yingjie Miao. //From word2vec to doc2vec: an approach driven by Chinese restaurant process//&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://yadi.sk/i/d2n7vosmVdHxs"&gt;Le Q. V., Mikolov T. Distributed Representations of Sentences and Documents //arXiv preprint arXiv:1405.4053. – 2014.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://papers.nips.cc/paper/5557-smoothed-gradients-for-stochastic-variational-inference.pdf"&gt;Levy O., Goldberg Y. Neural Word Embedding as Implicit Matrix Factorization //Advances in Neural Information Processing Systems. – 2014. – С. 2177-2185.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf"&gt;Van den Oord A., Dieleman S., Schrauwen B. Deep content-based music recommendation //Advances in Neural Information Processing Systems. – 2013. – С. 2643-2651.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://benanne.github.io/2014/08/05/spotify-cnns.html"&gt;Sander Dieleman. //Recommending music on Spotify with deep learning//&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://yadi.sk/d/PBTTEV2wdLrg2"&gt;Krizhevsky A., Sutskever I., Hinton G. E. Imagenet classification with deep convolutional neural networks //Advances in neural information processing systems. – 2012. – С. 1097-1105.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/pages/itmo-rs-2014.html"&gt;Содержание&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-4.html"&gt; &amp;lt;- Предыдущая лекция&lt;/a&gt; | &lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-6.html"&gt;Следующая лекция -&amp;gt; &lt;/a&gt;&lt;/p&gt;</summary></entry><entry><title>ITMO RS 2014 ~ Lecture 4</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-4.html" rel="alternate"></link><updated>2014-12-06T12:00:00+03:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-12-06:itmo-rs-2014-lecture-4.html</id><summary type="html">&lt;h2&gt;Advanced models&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Более сложные модели: Restricted Boltzmann Machines для регрессии и Bayesian Personalized Ranking для pairwise-подхода к ранжированию. И еще несколько слов о метриках.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/42404700" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Материалы&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Salakhutdinov R., Mnih A., Hinton G. &lt;a href="http://yadi.sk/d/vF_l_BjP6tGdW"&gt;Restricted Boltzmann machines for collaborative filtering&lt;/a&gt; //Proceedings of the 24th international conference on Machine learning. – ACM, 2007. – С. 791-798.&lt;/li&gt;
&lt;li&gt;Hinton G. &lt;a href="http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf"&gt;A practical guide to training restricted Boltzmann machines&lt;/a&gt; //Momentum. – 2010. – Т. 9. – №. 1. – С. 926.&lt;/li&gt;
&lt;li&gt;Rendle S. et al. &lt;a href="http://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf"&gt;BPR: Bayesian personalized ranking from implicit feedback&lt;/a&gt; //Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. – AUAI Press, 2009. – С. 452-461.&lt;/li&gt;
&lt;li&gt;Rendle S., Freudenthaler C., Schmidt-Thieme L. &lt;a href="http://yadi.sk/d/ZF5CzaWq7V3kE"&gt;Factorizing personalized markov chains for next-basket recommendation&lt;/a&gt; //Proceedings of the 19th international conference on World wide web. – ACM, 2010. – С. 811-820.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/pages/itmo-rs-2014.html"&gt;Содержание&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-3.html"&gt; &amp;lt;- Предыдущая лекция&lt;/a&gt; | &lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-5.html"&gt;Следующая лекция -&amp;gt; &lt;/a&gt;&lt;/p&gt;</summary></entry><entry><title>ITMO ML course — RecSys part 2</title><link href="http://www.4ducks.ru/itmo-ml-course-recsys-part-2.html" rel="alternate"></link><updated>2014-11-17T11:02:00+03:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-11-17:itmo-ml-course-recsys-part-2.html</id><summary type="html">&lt;h2&gt;Рекомендательные системы — часть 2&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Вторая лекция о рекомендациях в рамках курса по Machine Learning.
Говорили о том, как строить объяснения к рекомендациям.
Модели Restricted Boltzmann Machines и Personalized Bayesian Ranking.
Еще раз прошлись по метрикам качества.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/41672194" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Книги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ricci F. et al. &lt;a href="http://yadi.sk/d/pq3fcJgT9voSt"&gt;Recommender systems handbook.&lt;/a&gt; – Springer US, 2011.&lt;/li&gt;
&lt;li&gt;Celma O. &lt;a href="http://yadi.sk/d/l0ZSsEY69STGT"&gt;Music Recommendation and Discovery: The Long Tail, Long Fail, and Long Play in the Digital Music Space.&lt;/a&gt; – Springer, 2010.&lt;/li&gt;
&lt;li&gt;Jannach D. et al. &lt;a href="http://www.amazon.com/Recommender-Systems-Introduction-Dietmar-Jannach/dp/0521493366"&gt;Recommender systems: an introduction.&lt;/a&gt; – Cambridge University Press, 2010.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Статьи&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Hu Y., Koren Y., Volinsky C. &lt;a href="http://yadi.sk/d/b4BEAs5t6NUOp"&gt;Collaborative filtering for implicit feedback datasets&lt;/a&gt; //Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on. – IEEE, 2008. – С. 263-272.&lt;/li&gt;
&lt;li&gt;Herlocker J. L., Konstan J. A., Riedl J. &lt;a href="https://yadi.sk/i/ebMoIaU0cGHHy"&gt;Explaining collaborative filtering recommendations&lt;/a&gt; //Proceedings of the 2000 ACM conference on Computer supported cooperative work. – ACM, 2000. – С. 241-250.&lt;/li&gt;
&lt;li&gt;Salakhutdinov R., Mnih A., Hinton G. &lt;a href="http://yadi.sk/d/vF_l_BjP6tGdW"&gt;Restricted Boltzmann machines for collaborative filtering&lt;/a&gt; //Proceedings of the 24th international conference on Machine learning. – ACM, 2007. – С. 791-798.&lt;/li&gt;
&lt;li&gt;Hinton G. &lt;a href="http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf"&gt;A practical guide to training restricted Boltzmann machines&lt;/a&gt; //Momentum. – 2010. – Т. 9. – №. 1. – С. 926.&lt;/li&gt;
&lt;li&gt;Rendle S. et al. &lt;a href="http://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf"&gt;BPR: Bayesian personalized ranking from implicit feedback&lt;/a&gt; //Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. – AUAI Press, 2009. – С. 452-461.&lt;/li&gt;
&lt;li&gt;Rendle S., Freudenthaler C., Schmidt-Thieme L. &lt;a href="http://yadi.sk/d/ZF5CzaWq7V3kE"&gt;Factorizing personalized markov chains for next-basket recommendation&lt;/a&gt; //Proceedings of the 19th international conference on World wide web. – ACM, 2010. – С. 811-820.&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>ITMO ML course — RecSys part 1</title><link href="http://www.4ducks.ru/itmo-ml-course-recsys-part-1.html" rel="alternate"></link><updated>2014-11-09T15:02:00+03:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-11-09:itmo-ml-course-recsys-part-1.html</id><summary type="html">&lt;h2&gt;Рекомендательные системы — часть 1&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Лекция-введение. Рассказ про рекомендательные системы в целом, о том, какие они бываю и какие данные используют.
Краткий разбор kNN-модели и SVD, рассказ о том, как применять SGD и ALS для обучения SVD. Обучение implicit SVD через iALS.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/41313803" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Ссылки&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.netflixprize.com/"&gt;Netflix Prize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sifter.org/~simon/journal/20061211.html"&gt;Netflix Update: Try this at home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Книги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ricci F. et al. &lt;a href="http://yadi.sk/d/pq3fcJgT9voSt"&gt;Recommender systems handbook.&lt;/a&gt; – Springer US, 2011.&lt;/li&gt;
&lt;li&gt;Celma O. &lt;a href="http://yadi.sk/d/l0ZSsEY69STGT"&gt;Music Recommendation and Discovery: The Long Tail, Long Fail, and Long Play in the Digital Music Space.&lt;/a&gt; – Springer, 2010.&lt;/li&gt;
&lt;li&gt;Jannach D. et al. &lt;a href="http://www.amazon.com/Recommender-Systems-Introduction-Dietmar-Jannach/dp/0521493366"&gt;Recommender systems: an introduction.&lt;/a&gt; – Cambridge University Press, 2010.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Статьи&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Koren Y., Bell R., Volinsky C. &lt;a href="https://yadi.sk/i/CGSXNzr4c89ZY"&gt;Matrix factorization techniques for recommender systems&lt;/a&gt; //Computer. – 2009. – Т. 42. – №. 8. – С. 30-37.&lt;/li&gt;
&lt;li&gt;Koren Y. &lt;a href="http://yadi.sk/d/pTVIQqFP6TjWm"&gt;Factorization meets the neighborhood: a multifaceted collaborative filtering model&lt;/a&gt; //Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. – ACM, 2008. – С. 426-434.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;li&gt;Hu Y., Koren Y., Volinsky C. &lt;a href="http://yadi.sk/d/b4BEAs5t6NUOp"&gt;Collaborative filtering for implicit feedback datasets&lt;/a&gt; //Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on. – IEEE, 2008. – С. 263-272.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;li&gt;Takács G., Tikk D. &lt;a href="http://yadi.sk/d/lg6F-o6j6y9qq"&gt;Alternating least squares for personalized ranking&lt;/a&gt; //Proceedings of the sixth ACM conference on Recommender systems. – ACM, 2012. – С. 83-90.&lt;/li&gt;
&lt;li&gt;Herlocker J. L., Konstan J. A., Riedl J. &lt;a href="https://yadi.sk/i/ebMoIaU0cGHHy"&gt;Explaining collaborative filtering recommendations&lt;/a&gt; //Proceedings of the 2000 ACM conference on Computer supported cooperative work. – ACM, 2000. – С. 241-250.&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>ITMO RS 2014 ~ Lecture 3</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-3.html" rel="alternate"></link><updated>2014-11-08T01:27:00+03:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-11-08:itmo-rs-2014-lecture-3.html</id><summary type="html">&lt;h2&gt;SVD environment&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Демо рекомендательной системы Oryx. Различные подходы к таксономии item-ов. Поиск похожих item-ов и кандидатов для ранжирования: kd-деревья, LSH, asymmetric LSH.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/41275761" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Материалы&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/cloudera/oryx"&gt;Cloudera Oryx on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Koenigstein N., Dror G., Koren Y. &lt;a href="http://yadi.sk/d/2Emm2xkQ6HsnS"&gt;Yahoo! music recommendations: modeling music ratings with temporal dynamics and item taxonomy&lt;/a&gt; //Proceedings of the fifth ACM conference on Recommender systems. – ACM, 2011. – С. 165-172.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://en.wikipedia.org/wiki/K-d_tree"&gt;K-d tree on Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bachrach Y. et al. &lt;a href="https://yadi.sk/i/0vnoyLbkc3TdT"&gt;Speeding up the Xbox recommender system using a euclidean transformation for inner-product spaces //Proceedings of the 8th ACM Conference on Recommender systems.&lt;/a&gt; – ACM, 2014. – С. 257-264.&lt;/li&gt;
&lt;li&gt;Shrivastava A., Li P. &lt;a href="http://arxiv.org/pdf/1405.5869.pdf"&gt;Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS)&lt;/a&gt; //arXiv preprint arXiv:1405.5869. – 2014.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/pages/itmo-rs-2014.html"&gt;Содержание&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-2.html"&gt; &amp;lt;- Предыдущая лекция&lt;/a&gt; | &lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-4.html"&gt;Следующая лекция -&amp;gt; &lt;/a&gt;&lt;/p&gt;</summary></entry><entry><title>ITMO RS 2014 ~ Lecture 2</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-2.html" rel="alternate"></link><updated>2014-10-25T10:52:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-25:itmo-rs-2014-lecture-2.html</id><summary type="html">&lt;h2&gt;SVD continued&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Рассказ про iALS, оптимизацию ALS1 и iALS1, rank ALS. Объяснение SVD рекомендаций.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/40706158" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Статьи&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Hu Y., Koren Y., Volinsky C. &lt;a href="http://yadi.sk/d/b4BEAs5t6NUOp"&gt;Collaborative filtering for implicit feedback datasets&lt;/a&gt; //Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on. – IEEE, 2008. – С. 263-272.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;li&gt;Takács G., Tikk D. &lt;a href="http://yadi.sk/d/lg6F-o6j6y9qq"&gt;Alternating least squares for personalized ranking&lt;/a&gt; //Proceedings of the sixth ACM conference on Recommender systems. – ACM, 2012. – С. 83-90.&lt;/li&gt;
&lt;li&gt;Herlocker J. L., Konstan J. A., Riedl J. &lt;a href="https://yadi.sk/i/ebMoIaU0cGHHy"&gt;Explaining collaborative filtering recommendations&lt;/a&gt; //Proceedings of the 2000 ACM conference on Computer supported cooperative work. – ACM, 2000. – С. 241-250.&lt;/li&gt;
&lt;li&gt;Pilászy I., Tikk D. &lt;a href="http://yadi.sk/d/I4p_DeWg8paLQ"&gt;Explaining Recommendations of Factorization-Based Collaborative Filtering Algorithms&lt;/a&gt; //Acta Technica Jaurinensis. – 2009. – Т. 2. – №. 2. – С. pp. 233-248.&lt;/li&gt;
&lt;li&gt;Kluver D., Konstan J. A. &lt;a href="https://yadi.sk/i/uyVbyOsTcKBiZ"&gt;Evaluating recommender behavior for new users&lt;/a&gt; //Proceedings of the 8th ACM Conference on Recommender systems. – ACM, 2014. – С. 121-128.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/pages/itmo-rs-2014.html"&gt;Содержание&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-1.html"&gt; &amp;lt;- Предыдущая лекция&lt;/a&gt; | &lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-3.html"&gt;Следующая лекция -&amp;gt; &lt;/a&gt;&lt;/p&gt;</summary></entry><entry><title>ITMO RS 2014 ~ Lecture 1</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-1.html" rel="alternate"></link><updated>2014-10-18T11:05:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-18:itmo-rs-2014-lecture-1.html</id><summary type="html">&lt;h2&gt;Введение в рекомендательные системы&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Лекция-введение. Рассказывал про рекомендательные системы в целом, о том, какие они бываю и какие данные используют.
Разобрали kNN-модели и SVD, рассказал как применять SGD и ALS для обучения SVD. Поговорили про evaluation (общая схема и чуть более предметно про online-тестирование).&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/40423604" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Ссылки&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.netflixprize.com/"&gt;Netflix Prize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sifter.org/~simon/journal/20061211.html"&gt;Netflix Update: Try this at home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Книги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ricci F. et al. &lt;a href="http://yadi.sk/d/pq3fcJgT9voSt"&gt;Recommender systems handbook.&lt;/a&gt; – Springer US, 2011.&lt;/li&gt;
&lt;li&gt;Celma O. &lt;a href="http://yadi.sk/d/l0ZSsEY69STGT"&gt;Music Recommendation and Discovery: The Long Tail, Long Fail, and Long Play in the Digital Music Space.&lt;/a&gt; – Springer, 2010.&lt;/li&gt;
&lt;li&gt;Jannach D. et al. &lt;a href="http://www.amazon.com/Recommender-Systems-Introduction-Dietmar-Jannach/dp/0521493366"&gt;Recommender systems: an introduction.&lt;/a&gt; – Cambridge University Press, 2010.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Статьи&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Koren Y., Bell R., Volinsky C. &lt;a href="https://yadi.sk/i/CGSXNzr4c89ZY"&gt;Matrix factorization techniques for recommender systems&lt;/a&gt; //Computer. – 2009. – Т. 42. – №. 8. – С. 30-37.&lt;/li&gt;
&lt;li&gt;Koren Y. &lt;a href="http://yadi.sk/d/pTVIQqFP6TjWm"&gt;Factorization meets the neighborhood: a multifaceted collaborative filtering model&lt;/a&gt; //Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. – ACM, 2008. – С. 426-434.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/pages/itmo-rs-2014.html"&gt;Содержание&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-2.html"&gt;Следующая лекция -&amp;gt; &lt;/a&gt;&lt;/p&gt;</summary></entry><entry><title>Предыстория лекций в ИТМО</title><link href="http://www.4ducks.ru/predystoriia-lektsii-v-itmo.html" rel="alternate"></link><updated>2014-10-15T18:50:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-15:predystoriia-lektsii-v-itmo.html</id><summary type="html">&lt;p&gt;В осеннем семестре 2014 года я провожу факультативный курс лекций по рекомендательным системам в &lt;a href="http://www.ifmo.ru/"&gt;СПб НИУ ИТМО&lt;/a&gt; на кафедре КТ ФИТиП.&lt;/p&gt;
&lt;h1&gt;Предыстория&lt;/h1&gt;
&lt;p&gt;В далеком 2012 году Антон Банных предложил мне рассказать его студентам что-нибудь про анализ данных и применение машинного обучения в Яндексе. В тот момент я начал заниматься рекомендательными системами и уже имел некоторые знания области. Я согласился и рассказал студентам четвертого курса основы рекомендаций. Но это были действительно основы — я сделал упор на &lt;a href="http://en.wikipedia.org/wiki/Association_rule_learning"&gt;ассоциативные правила&lt;/a&gt; и &lt;a href="http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"&gt;метод ближайших соседей&lt;/a&gt;. Немного рассказал про SVD, еще меньше - про оценку рекомендаций. Так сказать, первый блин вышел комом.&lt;/p&gt;
&lt;p&gt;На следующий год мои познания в области существенно выросли, как и умение рассказывать эти самые азы. Я снова углубился в создание рекомендаций для Яндекс.Музыки, на этот раз в компании московских коллег. И для "быстрого старта" сделал парочку семинаров для коллег по основам коллаборативной фильтрации. И ребятам польза, и у меня в голове знания еще раз уложились.&lt;br /&gt;
В результате я уже сам предложил Антону свою помощь. На мой взгляд, лекция удалась — я за короткое время сделал обзор простых, но в то же время хорошо работающих методов коллаборативной фильтрации (SVD и kNN — да! как показывает RecSys его до сих много кто использует), немного пробежался по контентным методам и уделил время более подробному (относительно прошлого раза) рассказу про оценку.
Кроме того, в этот год к обычным лабораториям по машинному обучению добавилась лабораторная по рекомендациям, где я предлагал на данных movielens обучить SVD-алгоритм различными способами. Справились, к сожалению, не все, но были ребята, которые сделали даже ALS1!&lt;/p&gt;
&lt;p&gt;В этом году на машинном обучении у студентов четвертого курса КТ тоже будет моя лекция — даже две (хотя это примерно то же самое, в прошлый раз я читал чуть меньше двух пар, зато подряд без перерыва). Но я решил, что можно не останавливаться на достигнутом. Поэтому (та-да-да-дам-та-дам!) предложил студентам четвертого, пятого и шестого курсов серию факультативных лекций.&lt;/p&gt;</summary></entry><entry><title>Заметки с RecSys 2014</title><link href="http://www.4ducks.ru/zametki-s-recsys-2014.html" rel="alternate"></link><updated>2014-10-15T09:23:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-15:zametki-s-recsys-2014.html</id><summary type="html">&lt;p&gt;На прошлой неделе в Foster City, CA прошла конференция RecSys'14.&lt;/p&gt;
&lt;p&gt;Содержимое флешки с оглавлением: &lt;a href="https://yadi.sk/d/-DVv6cBwbqyM8"&gt;https://yadi.sk/d/-DVv6cBwbqyM8&lt;/a&gt;&lt;br /&gt;
Видео всех докладов и постеров: &lt;a href="https://www.youtube.com/playlist?list=PLaZufLfJumb9A95nS5AmY6G5mqYnwIfZX"&gt;https://www.youtube.com/playlist?list=PLaZufLfJumb9A95nS5AmY6G5mqYnwIfZX&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Понедельник (6 октября)&lt;/h1&gt;
&lt;p&gt;День туториалов, поэтому нового мало.&lt;/p&gt;
&lt;h2&gt;T1&lt;/h2&gt;
&lt;p&gt;Вначале рассказывал Аматриан, это была часть его «стандартного» туториала с MLSS, только в два раза короче. Он пробежался по основным методам (memory-based, svd, rbm, arules, clustering, classification, content-based), а во второй части акцентировал внимание на том, чему они научились во время (и после) Netflix Prize. Это «эволюция рекомендательных систем»: rating -&amp;gt; ranking -&amp;gt; page optimization -&amp;gt; context-aware recommender. С первым и вторым более менее понятно (хотя тут он снова много рассказывал про методы, pairwise и pointwise, про то, что хорошо оптимизировать loss-function для ранжирования, но можно, например, делать это не напрямую, а косвенно. Хотя, конечно, работает хуже). Еще отдельно были упомянуты похожести как рекомендации. Их можно строить через графовые методы, например, sim-rank, через «похожести» в метаданных, в поведении пользователей и в рейтингах (это как раз CF-подходы). Все это очень хорошо работает в ансамбле. Но если трудно обучать ансамбль, то можно использовать бандитов.&lt;/p&gt;
&lt;p&gt;Еще говорил про deep learning, но сразу оговорюсь — тут все только зарождается (в основном благодаря тому, что научились эффективно учить сети, см. &lt;a href="http://techblog.netflix.com/2014/02/distributed-neural-networks-with-gpus.html"&gt;http://techblog.netflix.com/2014/02/distributed-neural-networks-with-gpus.html&lt;/a&gt;). Упоминались методы из Spotify (RNN и обучение латентных векторов). Из spotify, кстати, всего один человек, Бернхардсона не было.
Немного упомянул про social RS (но дальше был отдельный туториал по ним). Кстати, мелькнула идея регуляризации близких пользователей.&lt;/p&gt;
&lt;p&gt;Про page optimization (самое интересное) Аматриан говорил мало, не хватало времени. В кратце: основная идея состоит в том, что у нас 10000 item-ов, которые можно показать и дофига блоков. Но показывать это все надо не просто так, а оптимизируя страницу целиком для конкретного пользователя (и конкретного девайса тоже). Работ тут пока мало, упоминалась вот эта: &lt;a href="http://www.cs.cmu.edu/~amahmed/papers/SVCM_WSDM12.pdf"&gt;http://www.cs.cmu.edu/~amahmed/papers/SVCM_WSDM12.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Еще говорил про context-aware RS: тензорные разложения и factorization machines.&lt;/p&gt;
&lt;p&gt;Интересная часть — о многоруких бандитах. Их активно используют для exploration/exploitation. Можно так подбирать параметры в online, можно выбирать алгоритмы (тогда это работает как гибридная RS). &lt;/p&gt;
&lt;p&gt;Про implicit feedback был вопрос о том, как бороться с bias-ом от того, что пользователь смотрит то, что мы ему показываем. Тут решение либо сэмплить, либо исопользовать бандитов.&lt;/p&gt;
&lt;h2&gt;T2&lt;/h2&gt;
&lt;p&gt;Какие-то невнятные китайцы с отвратительным английским пытались рассказывать про location based recommender на основе соцсетей. Но никто ничего не понял, большая часть людей свалила. Мне так сделать не удалось, но туториал был бесполезный.&lt;/p&gt;
&lt;h2&gt;T3&lt;/h2&gt;
&lt;p&gt;Паоло Кремонези рассказывал про Cross-Domain Recommender Systems. Это был неплохой обзор того, кто чего делает в области.
Очень много всякой разной классификации по типу чего-нибудь. В целом выводы примерно такие: 1) есть разные цели: cold-start, cross-selling, improving quality и разные свойства доменов (например, разное пересечение пользователей, item-ов, аттрибутов). Исходя из этого применяются разные методы от самых тупых (аггрегация профилей, моделей, рейтингов) до сложных (тензорные факторизации, три-матричная кофакторизация, codebook transfer). Про последний забавно — они только что показали, что cross-domain тут непричем — это просто хороший matrix factorization метод. Методы оценки также зависят от того, в каком домене и кому мы хотим рекомендовать.&lt;/p&gt;
&lt;h2&gt;T4&lt;/h2&gt;
&lt;p&gt;Social Recommender Systems. Рассказывали чуваки из Yahoo и IBM (Ido Guy). Идея в том, что web2.0 — интернет людей. Отсюда появились соцсетки и социальные медиа. Очень много новой информации вроде тэгов, голосовалок (like) и комментариев. &lt;/p&gt;
&lt;p&gt;Про рекомендации контента: есть два типа связей — знакомство (люди связаны в сети) и похожесть (люди состоят в одних группах и комментируют одни материалы). Первые дают более точные, но более скучные рекомендации (еще они помогают в explanation), вторые сильно увеличивают diversity и serendipity (имхо, это уже CF). Упоминал статью про google reader: &lt;a href="http://dl.acm.org/citation.cfm?id=1719976&amp;amp;dl=ACM&amp;amp;coll=DL&amp;amp;CFID=438180616&amp;amp;CFTOKEN=35684830"&gt;http://dl.acm.org/citation.cfm?id=1719976&amp;amp;dl=ACM&amp;amp;coll=DL&amp;amp;CFID=438180616&amp;amp;CFTOKEN=35684830&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Еще интересный факт: «входящие» данные (то, что про пользователя думает окружение) работает лучше, чем исходящие данные (лайки, тэги) самого пользователя.&lt;/p&gt;
&lt;p&gt;Рекомендации тэгов еще одна тема. Используются CF-методы, гибридные (Rendle’2010, видимо вот это имелось в виду: &lt;a href="http://www.informatik.uni-konstanz.de/rendle/software/tag-recommender/"&gt;http://www.informatik.uni-konstanz.de/rendle/software/tag-recommender/&lt;/a&gt;). Хорошо работают графовые методы: &lt;a href="http://www.kde.cs.uni-kassel.de/stumme/papers/2006/hotho2006folkrank.pdf"&gt;http://www.kde.cs.uni-kassel.de/stumme/papers/2006/hotho2006folkrank.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Про рекомендации сообществ говорил про комбинацию arules и lda на контенте (странно что не упомянул одноклассников).&lt;/p&gt;
&lt;p&gt;Рекомендация людей (друзей, кого фолловить): есть методы на контенте, FoF и SONAR. В опросах побеждают последние, но по факту они быстро исчерпывают себя — человек и так знаком с рекомендуемыми людьми. Тут было довольно спорно все. Кстати, для предсказания кого фолловить внезапно follower-ы человека более информативны, чем те, кого он сам фолловит.&lt;/p&gt;
&lt;p&gt;Много говорили про создание контента. Так как активно генерят контент всего 1% пользователей, то нужно их мотивировать. В частности, рекомендация тэгов — это мотивация. Приводилось две теории генерации контента: самоопределение и теория Foggs behaviour model (для действия нужны мотивация (нужно хотеть), доступность (это не должно быть слишком сложно) и trigger — событие, которое станет «последней каплей», например, это может быть письмо от соцсети).&lt;/p&gt;
&lt;p&gt;Говорили про интересное исследование: пользователи, которым в самом начале порекомендовали «активных» в друзья, с гораздо большей вероятностью сами становятся активными. Еще была долгая история про то, как рекомендовали темы блогов. С одной стороны, не было значимого увеличения в количестве постов. Но зато посты по рекомендациям собирали гораздо больше посещений и лайков.
Тут отдельный момент — как такие рекомендации меняют структуру сети. Например, FoF создает хабы. А Content matching создает связи к странным людям всего с несколькими друзьями…&lt;/p&gt;
&lt;p&gt;Кратко о trust and reputation: есть семейство графовых методов, которые с помощью «trust» и его распространения в сети могут повысить качество коллаборативки. Пример: повышаем рекомендации от доверенных пользователей, понижаем от недоверенных.
Reputation — это общее доверие, которым пользователь обладает в сети. Аналог page rank.&lt;/p&gt;
&lt;p&gt;Немного говорили про рекомендации группе людей, тут работ мало, в основном работает аггрегация профилей. Еще упоминали интересную работу &lt;a href="http://www.research.ibm.com/haifa/dept/imt/papers/sigir191-ronen.pdf"&gt;http://www.research.ibm.com/haifa/dept/imt/papers/sigir191-ronen.pdf&lt;/a&gt; (свою) про рекомендации контента для владельцев групп.
Снова интересно, как это меняет сеть.&lt;/p&gt;
&lt;h1&gt;Вторник (7 октября)&lt;/h1&gt;
&lt;p&gt;Вторник — первый день основной конференции, программа тоже более интересная.&lt;/p&gt;
&lt;h2&gt;Keynote&lt;/h2&gt;
&lt;p&gt;Вначале был &lt;em&gt;keynote&lt;/em&gt; от Нейл Ханта (технический директор Netflix). Он внезапно начал с того, что доверие пользователей с нами не навсегда и (опираясь на кучу историй с гуглом) призвал всех быть предельно аккуратными, чтобы не потерять свою аудиторию.
Дальше он рассказал краткую историю рекомендаций в компании — в основном раньше брали в прокат только новые релизы, а потом они оставались у них на складе навсегда. После внедрения рекомендаций стало сильно лучше, сейчас новые релизы — это примерно 10%
Были интересные параллели с Linear TV и on-demand TV, Netflix видимо мощно двигается в эту сторону (например, через приложения для телеков) и они говорят об изменении классического формата (бродкаст, 21 час в неделю prime-time и больше ничего). Они не продают рекламу, не продают данные пользователей, но могут делать только качественные рекомендации (примерно 150M «решений»(событий?) в день, 50M пользователей). 1% увеличения к количеству просмотров — это более $500M.
Им очень хочется измерять retention, но это невозможно. Хороший прокси — часы просмотра (так же и у нас в радио). Но не все изменения полезны — даже увеличивая эту метрику они могут потерять пользователей с низким числом просмотров, поэтому смотрят на всю кривую.
Еще интересная мысль — они могут технически (и видимо уже собираются это делать) говорить продюссерам, как будет принят фильм. И могут предсказывать хорошие ниши даже для очень маленьких аудиторий. Вообще «there are no bad shows, just shows with small audience».
И да, еще интересный момент. Они пробовали просить пользователей самим поранжировать вручную. Но их алгоритм по метрике лучше =)&lt;/p&gt;
&lt;p&gt;Во время перерыва говорил с чуваками из Pandora (с Оскаром Сельма тоже, кстати, он там теперь большой начальник). Они рассказали, что используют только разметку, но разметка фичей не бинарная, а обычно в пятибальной шкале. Дальше из этого уже майнят эфир. Новые фичи не добавляются, но зато можно добавить новый домен (например, комедии) со своим набором фич.&lt;/p&gt;
&lt;p&gt;У Гугла спрашивал, используют ли они единую систему рекомендаций. Сказали, что нет, обычно продукт пишет что-то свое. Вообще они очен мало рассказывали по делу, девочка даже ноут от меня прикрыла (хотя я не мог видеть что там, да и не пытался даже) =)&lt;/p&gt;
&lt;p&gt;Поговорил с Рикардо Диасом, который делал доклад &lt;a href="http://ceur-ws.org/Vol-1245/cbrecsys2014-paper05.pdf"&gt;http://ceur-ws.org/Vol-1245/cbrecsys2014-paper05.pdf&lt;/a&gt; на вчерашнем воркшопе. Он пересказал мне вкратце свой метод — они просто берут фичи у эхонеста и пытаются играть треки, которые хорошо подходят к активности конкретного пользователя. Но масштабы там маленькие.&lt;/p&gt;
&lt;h2&gt;Novel applications&lt;/h2&gt;
&lt;p&gt;Заговорившись в холле пропустил первый доклад, как и многие другие =(
Доклад &lt;em&gt;Automating Readers’ Advisory to Make Book Recommendations for K-12 Readers&lt;/em&gt; — это рекомендации детских книжек. Они строят рекомендации на темах и анализе контента, выделяя факторы (например, storyline: fun). Выделение с помощью правил-шаблонов из ревью.
По их замерам лучше Novelist, но хуже амазона (что странно при том, что они очень нишевые).&lt;/p&gt;
&lt;p&gt;Еще был доклад про &lt;em&gt;Robust Model for Paper-Reviewer Assignment&lt;/em&gt;, в целом про то, как выделять экспертов. У них графовая модель, случайные блуждания с рестартом. В вершинах все объекты (авторы, статьи, темы), на ребрах отношения (автор-автор, статья-автор, статья-тема). Темы выделяют через LDA. Разнообразия ревьюеров они добиваются используя кластеризацию и l1 нормой убивая лишних.
Судя по их графикам выигрывает RWR, но они не сравнивали с существующими системами — типа другие данные&lt;/p&gt;
&lt;p&gt;Следующий доклад: &lt;em&gt;Exploiting Sentiment Homophily for Link Prediction&lt;/em&gt; — используя окраску твитов опрелеляют друзей. Строят граф связей различным образом (самый жгущий — это @mentions &amp;gt; N). По тэгам твитов определяют темы и смотрят как разные пользователи к ним относятся. Дальше строят скор кандидатам. Вроде неплохо получается по F1.&lt;/p&gt;
&lt;h2&gt;Novel setups&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Factored MDPs for Detecting Topics of User Sessions&lt;/em&gt;. Обычно нужно по предыдущему item-у определить следующий, но почему бы не делать это по сессии? Собственно, чуваки так и делают: строится MDP — состояния — аттрибуты (всего четыре), действия — выбор следующего, вознаграждение — клики, и матрица переходов.
В предположении независимости атрибутов получают существенное ускорение. 
Дальше имея Q-функцию они определяют тему сессии как распределение вероятностей атрибутов (плюс обрезание по общему порогу). Для длинных сессий хорошо работает точный MDP, для коротких — приближенный.
Дальше применяют свою модель тем для построения рекомендаций и оказываются лучше матричного разложения по AvgPos.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Context Adaptation in Interactive Recommender Systems&lt;/em&gt;. Многорукие бандиты с определением смены контекста. Собственно, exploitation — если контекст одинаковый (item выбирается с вероятностью быть лучшим), exploration — если смена. Смену контекста определяют так: берут два окна (рядом, но не пересекая) и считают модели. Дальше смотрят на разницу. 
Сравнивались с user-based kNN на Y!Music, смену контекста симулировали рандомной сменой пользователя в тест сете. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Question Recommendation with Constraints for Massive Open Online Courses&lt;/em&gt;. Рекомендуют темы форума на курсере, стараются увеличить overall community benefit. Сначала строят скор релевантности (через этакий супер-SVD со статистиками внутри как в %%SVD++%%), потом max concave cost flow, используют три фактора для фильтрации тем и юзеров: capability (expertise), capacity (number of question to work on), Hardness (how difficult question).
Данные, 3 курса с coursera, в питоне (самый большой) 3 тыс пользователей и 3 тыс itemов. Меряют MAP@1 @3 @5, сравнились с простым MF по ним.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Attacking Item-Based Recommender Systems with Power Items&lt;/em&gt;. Чувак очень здорово напугал всех тем, как легко и эффективно можно проводить атаки на user-based, item-based и SVD RS. Типы атак: push (поднимаем item), nuke (опускаем item) и disrupt (выводим систему из строя).
Как это делается: назначается target item, остальные рейтинги симулируются (разными способами) так, чтобы было похоже на обычного userа. Они находят «power users» и power items такие, которые больше всего влияют на систему. Дальше они могут быть похожи на такого user-а или оценивать такие item-ы. В случае item-based систем хорошо работает multitarget attack, у одного пользователя несколько target-итемов.
Атаки весьма эффективны по hit rate и по rating shift. Говорит, что есть хорошие защиты (работы 2002 и 2010 года), основная идея — смотреть на большое количество аномальных новых пользователей.&lt;/p&gt;
&lt;h2&gt;Cold start&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Ensemble Contextual Bandits for Personalized Recommendation&lt;/em&gt;. Идея в том, чтобы использовать многоруких бандитов как ансамбль когда мало данных для разделения моделей. Два шага: начала используется вес алгоритма в ансамбле, потом для каждого item-а алгоритмы говорят его вероятность. Все это совмещается и получается не сильно хуже, чем лучший алгоритм. Зато можно жить не выбирая модель.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Cold-start News Recommendation with Domain-dependent Browse Graph&lt;/em&gt;. Очень хорошая работа из Yahoo! Labs. Они исследовали user cold start для новостей. Идея: поведение пользователей отличается в зависимости от referer-а с которого они пришли. Чуваки выделили несколько больших рефереров (соцсети и поисковые системы) и построили для них browse-graph (с вершинами — статьями и ребрами — переходами). Кстати, графы поисковиков и соцсетей очень отличаются, а в группах большое пересечение. Дальше исследуют влияние разных рекомендаций в таких графах. Получается, что можно сделать лучше! Да, графы пересчитывают каждый час. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Item Cold-Start Recommendations: Learning Local Collective Embeddings&lt;/em&gt;. Еще работа из Yahoo! Labs. Идея в том, что они раскладывают две матрицы content matrix и collaborative matrix вместе, одна формирует темы, другая — группы пользователей. Но матрица фичей одна! То есть можно зная темы документа предсказать рейтинг для каждого пользователя. Используют два датасета: новости и предсказание адресата в почте. По почте почти так же как bpr+knn, где-то лучше, где-то хуже по разным метрикам. По новостям становится сильно лучше.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Improving The Discriminative Power Of Inferred Content Information Using Segmented Virtual Profile&lt;/em&gt;. Чувакки из linkedin рассказывают, как они улучшили  свои рекомендации работ. Выделяют из профилей фичи, по которым аппликанты сильно отличаются от остальных, это помогает дополнить профиль вакансии и лучше рекомендовать. Стало сильно лучше и хорошо масштабируется. Больше я ничего не понял=(&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ratings Meet Reviews, a Combined Approach to Recommend&lt;/em&gt;. Какой-то невнятный китаец рассказывал, как соединить lda и mf в одну вероятностную generative model. Модель вроде интересная, но они меряют rmse и упирают на explanation, который весьма сомнителен. Аматриан заметил, что ровно то же самое опубликовали на последнем KDD. &lt;/p&gt;
&lt;h1&gt;Среда (8 октября)&lt;/h1&gt;
&lt;p&gt;Очень интересный день — самые интересные доклады, самые интересные встречи, постеры. Попытаюсь описать как можно больше из того, что я запомнил.&lt;/p&gt;
&lt;h2&gt;Metrics and Evaluation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; Первая статья — &lt;em&gt;Beyond Clicks: Dwell Time for Personalization&lt;/em&gt; — best paper award.
Идея простая, есть yahoo stream, лайков мало, а клики шумные. Давайте же использовать dwell-time!
Собственно, они собирают события (зашли на статью, в фокусе, потеряли фокус, ушли) и строят сессии.
Дальше они делают большой анализ dwell time в разных категориях и контекстах, в итоге пришли к z-score нормализации внутри контекста.
Рекомендации строят через GBDT, время хорошо использовать для взвешивания событий (тут лучше почитать статью), но можно и для собственно формирования событий.&lt;br /&gt;
Супер-пупер результаты, все хорошо работает, всем dwell-time.&lt;/p&gt;
&lt;p&gt;Дальше Даниэль Клувер делал доклад &lt;em&gt;Evaluating Recommender Behavior For New Users&lt;/em&gt;. Идея простая: они взяли movielens и у некоторых пользователей из test set-а оставили в train-е маленькое количество рейтингов (симулировали cold-start). А дальше они изучили как разные методы ведут себя в разных ситуациях. Вывод доклада — если меньше 4-х рейтингов, то baseline model лучше svd почти по всем метрикам.&lt;/p&gt;
&lt;p&gt;Следом выступил Алан Саид &lt;em&gt;Comparative Recommender System Evaluation: Benchmarking Recommendation Frameworks&lt;/em&gt;. Они рассказывали про rival — фреймворк для оценки и проведения исследований. Получилось очень интересно, они построили хороший протокол, где единственным черным ящиком остается алгоритм. Можно использовать модульно, поэтому и тестить что угодно. Его, кстати, использовали в recsys challenge в этом году.&lt;br /&gt;
Смотреть можно и нужно на &lt;a href="http://rival.recommenders.net"&gt;http://rival.recommenders.net&lt;/a&gt;, код у них открытый.&lt;/p&gt;
&lt;p&gt;Дальше был рассказ про &lt;em&gt;Social Influence Bias in Recommender Systems: A Methodology for Learning, Analyzing, and Mitigating Bias in Ratings&lt;/em&gt;. Суть в том, что решения пользователей подвержены влиянию большинства (например, если все в комнате говорят, что черный кубик белый человек склонен тоже сказать, что он белый, хотя и зная, что это не так). Вопрос в том, можно ли измерить social bias и можно ли его устранить из существующего датасета? Используют California Report Card, люди сначала ставят рейтинг, потом им показывают медиану и они могут поменять решение. Так вот оказывается, что изменившие решение и не изменившие его отличаются (по Вилкоксону). Дальше они строят метод предсказания того, что пользователь поменял рейтинг и очищают данные.&lt;br /&gt;
Но к случаю, когда рейтинг встроен в дизайн, это плохо применимо.&lt;/p&gt;
&lt;h2&gt;Novelty and Serendipity&lt;/h2&gt;
&lt;p&gt;Первая статья весьма оригинальна: &lt;em&gt;Improving-Sales-Diversity-by-Recommending-Users-to-Items&lt;/em&gt;. Идея в том, чтобы развернуть проблему и рекомендовать пользователей к item-ам. Чуваки переписывают kNN в такой формулировке и получают более качественный neighbour selection, в итоге выигрывают по качеству.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;On Over-Specialization and Concentration Biases of Recommendations: Probabilistic Neighborhood Selection in Collaborative Filtering Systems&lt;/em&gt;. Чуваки делают probabilistic neighbor selection, это простое взвешенное семплирование с возващение. Больше ничего не понял =(&lt;/p&gt;
&lt;p&gt;В следующей работе &lt;em&gt;User Perception of Differences in Recommender Algorithms&lt;/em&gt; чуваки на user study смотрят как пользователи оценивают выдачи разных алгоритмов. Они строят модель качества алгоритма, которая учитывает сочетания accuracy, diversity и novelty, от которых зависит satisfaction и first impression, которые в свою очередь ведут к выбору того или иного алгоритма как лучшего. Интересно, что:
  * satisfaction affects 1 imp and choice
  * satisfaction mediates diversity
  * novelty has complex largely negative effect
  * diversity and accuracy trade off
Короче, осторожно с novelty, а diversity в меру хорошо. Но это все махания руками, так как народ резонно заметил, что пользователи не пользовались этими рекомендациями и поэтому скорее всего выбрали более очевидные. Но они якобы делали это больше для новых пользователей и бла-бла-бла...&lt;/p&gt;
&lt;p&gt;Дальше рассказывал Флоран Гарсин (проф из EPFL): &lt;em&gt;Offline and Online Evaluation of News Recommender Systems at swissinfo.ch&lt;/em&gt;
они сделали систему рекомендаций новостей, см. предыдущую работу: &lt;a href="http://arxiv.org/pdf/1303.0665.pdf"&gt;http://arxiv.org/pdf/1303.0665.pdf&lt;/a&gt;&lt;br /&gt;
Собирают клики и обучают модель, в offline и online ситуация отличается диаметрально! Этот тот самый extremely good random recommender. Очень странная статья практически без выводов...&lt;/p&gt;
&lt;p&gt;В перерыве подошел к Клуверу, спрашивал не знает ли он про исследования в области таксономии в cold start. Он не знает =(
Потом обсуждали с Флораном почему его метод не работает, обсуждение плавно перетекло в ланч (всех выгнали из зала). И в результете (один я бы так не сделал), мы подсели за столик к каким-то чувакам. Которые при ближайшем рассмотрении оказались цветом Гугла. Так я пообедал с Джеффом Дином =)&lt;br /&gt;
Они мало что рассказывали и вообще были напряженные. Я пытался спрашивать, как они строят рекомендации — единой платформы таки нет. Часто они совпадают по API, но не всегда, им нравится, что рекомендации делают эксперты в конкретной предметной области. Идеального рекоомендера Джефф не видит, скорее это что-то в духе ансамбля (или нейросети, как можно подумать из его доклада?), куда легко можно вставить разные фичи про пользователя, item и т.д.&lt;/p&gt;
&lt;h2&gt;Keynote&lt;/h2&gt;
&lt;p&gt;Дальше был &lt;em&gt;keynote&lt;/em&gt; от Джеффа, про который мнения разошлись. Он говорил про нейросети (что очень внезапно) и очень impressive. Соответственно, половина людей была скептична (например, Аматриан), другая наоборот воодушевилась. 
В целом главная мысль — нам нужно научиться лучше понимать объекты (тексты, изображения, музыку, действия пользователя и т.д.) и очень хочется избавиться от ручного кодирования тысяч фичей. Выход — deep learning. Это реинкарнация нейронных сетей из 80-х, но at scale. Причем, с одной стороны все упростилось (например, просто max(0,x) вместо сигмоиды для активации), но зато появились способы обучать supervised, unsupervised и RL. Очень много работы сделано, чтобы уменьшить время обучения: это удается сделать с помощью двух вещей:
  * параллелизм модели — разные части модели можно обучать параллельно
  * параллелизм данных - можно поднять много копий моделей и parameter server, каждая модель будет считать дельты к параметрам и отправлять/получать обновления параметров&lt;br /&gt;
В результате — asynchronous distributed SGD. &lt;br /&gt;
См. &lt;a href="http://static.googleusercontent.com/media/research.google.com/ru/us/archive/unsupervised_icml2012.pdf"&gt;http://static.googleusercontent.com/media/research.google.com/ru/us/archive/unsupervised_icml2012.pdf&lt;/a&gt; и &lt;a href="http://static.googleusercontent.com/media/research.google.com/ru/us/archive/large_deep_networks_nips2012.pdf."&gt;http://static.googleusercontent.com/media/research.google.com/ru/us/archive/large_deep_networks_nips2012.pdf.&lt;/a&gt;&lt;br /&gt;
Дальше он приводил множество примеров того, что нейронки всемогущие. Ну вы понимаете о чем я.&lt;br /&gt;
Затем внезапно рассказал word2vec-модели (включая перевод текстов и paragraph-model). и о том, что это можно применять для эмбеддинга целых фраз: &lt;a href="http://arxiv.org/pdf/1409.3215.pdf"&gt;http://arxiv.org/pdf/1409.3215.pdf&lt;/a&gt;&lt;br /&gt;
Дальше с такими представлениями можно работать как с обычными плотными данными, например, кормить большой нейронке, вроде тех, что используются в image recognition или acoustic recognition &lt;a href="http://static.googleusercontent.com/media/research.google.com/ru/us/pubs/archive/38131.pdf."&gt;http://static.googleusercontent.com/media/research.google.com/ru/us/pubs/archive/38131.pdf.&lt;/a&gt; Или просто использовать получившееся латентное пространство.&lt;br /&gt;
Архитектуру сетей очень хочется получать автоматически, но пока они не научились.  &lt;/p&gt;
&lt;h2&gt;Mainstream&lt;/h2&gt;
&lt;p&gt;Дальше тетушка из Linkedin рассказывала про &lt;em&gt;A/B Testing: Innovation @ Internet Scale&lt;/em&gt;. В целом говорила достаточно очевидные вещи: тестировать надо. Но не просто надо, а тестировать надо все (буквально каждый рефакторинг). Они построили систему, которая одновременно гоняет 200+ экспериментов и считает 800+ метрик (кроме всего прочего, замеряет значимость). Плюс, разные метрики по разному связаны с p-value (тут мало кто понял о чем она), поэтому они умеют для разных метрик задавать разные пороги значимости. Плюс, они умеют выделять конкретную экспериментальную группу (тоолько те, у кого было 1 или 2 работы). Плюс, они разделяют владельца эксперимента и владельца метрики и можно удобно смотреть, какие эксперименты зааффектит изменение метрики.&lt;/p&gt;
&lt;p&gt;Дальше ребята из facebook делали два доклада:&lt;/p&gt;
&lt;p&gt;первый — &lt;em&gt;Page recommendations at Facebook&lt;/em&gt;. Идея в том, что они максимизируют не лайки, а user engagement. Система сначала выделяет структурированный запрос, потом выбирает кандидатов, потом ранжирует их по p(engagement). Разные события весят по-разному (лайки, клики), но взвешивание подбирается чуть ли не руками. Для выбора кандидатов используют:
1. location based CF
2. social user2user
3. CF (SVD on user-page matrix)
4. session-based CF: predict p(next page eng|current page eng.)
5. topic based ContentFiltering + RBM для сжатия
6. DNN to match page topic topic models to peoples interest models&lt;/p&gt;
&lt;p&gt;второй — &lt;em&gt;News feed ranking&lt;/em&gt;. У большинства пользователей очень большая лента, которую просто нереально читать. Поэтому они ее ранжируют. Глобальные метрики:daily active people, overall time spent. Но они очень не чувствительные, к тому же не на уровне постов. Метрики фида — на кликах, лайках, поделяшках, комментах и т.д. Пытаются предсказать (с разным весом в зависимости от типа события), понравится ли пользовалелю пост (в смысле лайк ли). We predict p(like) with many features… which are statistics on everything grouped in different ways. Счетчики, счетчики и еще раз счетчики. По пользовательским событиям, по постам и т.д. Дальше они извлекают фичи из счетчиков (как?) и обучают простую логистическую регрессию.&lt;br /&gt;
Еще интересно, что фид не фиксирован — каждый update фида они переранжируют все, причем то, что пользователь видел, сильно понижается. Таким образом они значительно увеличивают долю прочитанного.&lt;/p&gt;
&lt;p&gt;Дальше был докад &lt;em&gt;Making Advertising Personal: Large Scale Product Recommendation at Criteo&lt;/em&gt; чувака из Criteo про то, какие они крутые. Но мне так не кажется — мало что рассказал, только общие идеи, про то, что они тестируют ранжирование вместо регрессии и очень хорошо масштабируются. И все.  &lt;/p&gt;
&lt;p&gt;После снова был перерыв, мне попались ребята из Spotify (собственно, тот самый Эрик Бернардсон). Я много спрашивал про алгоритмы:
1. vector_exp — очень простая штука, которая внезапно хороша
2. они только экспериментируют с ее online-версией
3. да, они используют word2vec в ансамбле (но не очень распространяются как обучать их)
4. они пробовали писать статьи, но их отреджектили и пропала мотивация
5. еще много чего, в основном они спрашивали про то, насколько мы большие, так же ли у нас все устроено как у них и т.д.&lt;/p&gt;
&lt;h2&gt;Recommendation methods and theory&lt;/h2&gt;
&lt;p&gt;Первый доклад: &lt;em&gt;Recommending User Generated Item Lists&lt;/em&gt; про то, как рекомендовать не только item-ы, а целые списки item-ов (мне задача очень напомнила next basket recommendation). Чуваки обучают ранжирование списков с помощью семплирования в два шага: на первом семплят пары item-ов, на втором — пары списков (что бы это ни значило). Сравнивают с кучей методов, в т.ч. BPR и LME, они лучше, конечно. Но там очень маленький датасет — 34k списков и всего 3k item-ов, плюс они еще фильтруют это. Так что скорее всего история как с LME, который не работает на данных реальных размеров.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; Второй доклад: &lt;em&gt;Question Recommendation for Collaborative Question Answering Systems with RankSLDA&lt;/em&gt;. Ребята решают задачу collaborative question answering, рекомендуют вопросы на crossvalidated (из stackexchange) тем, кто может ответить (как я понял). Они придумали расширение sLDA (supervised), которое умеет ранжировать — rankSLDA. Основные отличия — multiple outcome per document и learning to rank. Очень интересная работа, рекомендую прочитать статью.&lt;/p&gt;
&lt;p&gt;Дальше какой-то китаец рассказывал про &lt;em&gt;Bayesian Binomial Mixture Model for Collaborative Prediction with Non-Random Missing Data&lt;/em&gt;. Ничего не понял кроме классификации пропущенных данных (уже давно показали, что рейтинги — это missing not at random).&lt;/p&gt;
&lt;h2&gt;Poster session&lt;/h2&gt;
&lt;p&gt;Через некоторое время был poster session.
Посмотрел несколько работ, организовано было плохо (как и вся конференция целиком), поэтому не со всеми удалось поговорить.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Recommending Learning materials to students…&lt;/em&gt;
Работа Кости Баумана, все очень просто — есть студенты, им предлагают quizz-ы посередине курса и по результатам формируют картину пробелов в знаниях. Рекомендации — это просто материалы к этим пробелам. На мой взгляд там есть проблемы с evaluation, Костя вроде согласился с этим. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Recommending Thumblr blogs to follow with inductive matrix completion&lt;/em&gt;
Работа из yahoo, суть в том, что вместо стандартного матричного разложения они используют разложение на четыре матрицы: U x W x H x V, где U и V — фичи пользователей и блогов соответственно, они просто считают их без обучения. А вот W и H матрицы уже обучают.
Интересно, хотя и неизвестно, насколько это сравнимо с чистым implicit и с инициализацией через SimFactor.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Empathize, don’t filter&lt;/em&gt;
Работа про UI, чуваки просто по разному показывают разные по важности твиты и на user study оказывается, что это типа лучше.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hybrid explanations framework for CF RS&lt;/em&gt;
Работа Кенингстайна про объяснение рекомендаций. Суть в том, чтобы построить три матрицы весов item-а в событиях пользователя, матрицу item-tag корелляций (?) и матрицу весов тэгов (мне так и не удалось понять, что это за веса). Потом простым произведением они выводят user-item-tag и дальше делают на этом explanation. Ноам говорит, что это просто эвристики, они сейчас ничего не обучают.
Кстати, спрашивал его про таксономию, он говорит, что у них есть та-самая-статья, но изданная в журнале, они там в частности показывают на примере жанров, что их таксономические вектора интерпретируемы и отлично сравнимы между собой. Cold start они не смотрели.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Switching Hybrid for cold-start CARS&lt;/em&gt;
Чувак почти ничего толком не объяснил. Суть в том, что есть разные контексты и разные модели. Контексты сочетаются, но мы знаем не про все сочетания. И они вроде придумали, что нужно показывать общее предсказание в таких случаях… он не смог нормально объяснить.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Free-lunch Enhancement for Collaborative Filtering with factorization machines&lt;/em&gt;
Интересная работа про libFM. Идея проста — давайте посмотрим на паттерны оценок пользователей (n1 единиц, n2 двоек, n3 трокек и т.д.), дальше построим по этим паттернам кластера. Номер кластера запихиваем в AUX information в libFM и вуаля.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;WrapRec...&lt;/em&gt;
Фреймворк на C# про то, как можно просто и удобно скрывать внешние рекоммендеры от клиентского кода. На стенде никого не было =(&lt;/p&gt;
&lt;p&gt;&lt;em&gt;An extended data model format for composite recommendation&lt;/em&gt;
Очередной протокол от Саида, на этот раз про то, как передавать данные. Сущности — tsv, атрибуты в json-колонке. Ничего примечательного.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Long term recommendation benchmarking … using Markov chains&lt;/em&gt;
Чувак делает приложение- список покупок. И выдвигает идею, что можно обучать вероятность элемента прожить (не быть удаленным, но может быть быть купленным) в списке больше времени t. Ничего кроме идеи.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Task-based user modelling for personalization via PMF&lt;/em&gt;
Интересная работа, суть в том, чтобы научится выделять из пользовательских запросов задачи через кластеризацию (тут очень спорно, что они получатся интерпретируемы), дальше мы можем соотнести пользователя и его новые запросы с определенными тасками. Может быть, будет интересно кому-нибудь в поиске.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Using graded implicit feedback for BPR&lt;/em&gt;
Чувак предложил как обучать BPR не на {0,1} фидбеке, а в случае, если мы знаем степень предпочтения. Правда, он не умеет сильнее учитывать более сильную разницу предпочтений, учитывается только факт разницы.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Inferring user interests in twitter soc. network&lt;/em&gt;
Простое извлечение интересов по связям и ключевым словам в твиттере.&lt;/p&gt;
&lt;p&gt;Фотки постеров, которые мне удалось посмотреть, можно найти в папке posters в диске: &lt;a href="https://yadi.sk/d/ueMsOUE4buSUx"&gt;https://yadi.sk/d/ueMsOUE4buSUx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;После этого поговорил с Яннахом Дитмаром (автор одной из книжек), они много занимаются музыкой. Но ничего конкретного он не рассказал, скорее больше спрашивал кто мы, сколько у нас данных, какие методы используем и т.д.&lt;/p&gt;
&lt;h1&gt;Четверг (9 октября)&lt;/h1&gt;
&lt;p&gt;В четверг был последний день основной программы, тоже было много чего интересного.
Но обо все по порядку:&lt;/p&gt;
&lt;h2&gt;Ranking and Top-N Recommendations&lt;/h2&gt;
&lt;p&gt;Первый доклад — &lt;em&gt;Coverage, Redundancy and Size-Awareness in Genre Diversity for Recommender Systems&lt;/em&gt;. Чуваки из telefonica делают разнообразие киношных рекомендаций через жанры. Они рассматривают несколько существующих подходов к тому, как это делать и в результате предлагают свой. Суть в построениии метрики binomialDiversity(R), где R — список рекомендаций. Строят так:
  * binomialCoverage(R), — штафуем за невыбор жанра
  * nonRedundancy(R) — штафуем за вероятности найти это или большее количество фильмов жанра в рекомендациях
  * binDiv(R) = coverage(R) * NonRed(R)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Towards a Dynamic Top-N Recommendation Framework&lt;/em&gt;. Автора статьи не было, докладывал его коллега. Строят online+offline модель рекомендаций, но кроме того, еще инициализируют некоторые компоненты латентных векторов через topic modelling. Сравнение у них странное, они делают online, но сравниваются с offline-методами. Короче, неясно, насколько topic modelling помогает.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Explore-Exploit in Top-N Recommender Systems via Gaussian Processes&lt;/em&gt;. Обычно в RL очень маленькое количество действий, но тут #action &amp;gt;&amp;gt; #trials. Поэтому можно выиграть в скорости, плюс идея разделять данные между позициями списка, между пользователями и item-ами. Для разделения между позициями считают простую вероятность вознаграждения на этой позиции, а для разделения user2user и item2item используют Гауссовские процессы. Интересно, что чем длиннее список, тем быстрее сходится.&lt;br /&gt;
Их спрашивали про производительность (вроде Гауссовские процессы медленные) — они говорят, что параллелят вычисления, но у них пока нет online.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A Parameter-free Algorithm for an Optimized Tag Recommendation List Size&lt;/em&gt;. Чувак из Сенегала рассказывал про то, как он строит рекомендации тэгов. Он вводит релевантность тэга, а из нее формулирует релевантность списка (которая не монотонна). В результате рекомендует список, оптимальный по релевантности  (но может быть более короткий).&lt;/p&gt;
&lt;h2&gt;Industry session&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Virtual personal shopping assistant&lt;/em&gt; — чувак из Shopkick (крупнейшего приложения для ритейлеров) рассказывал о rocket future для традиционных магазинов (не online!). Основная идея — нужно привести человека в магазин, а дальше высокая конверсия (от  35% до 90% в разных областях) сделают свое (тут я бы поспорил с ним). Они очень активно используют геопозицию — знают (с помощью ультразвуковых датчиков), когда, где и в какой магазин вошел пользователь. Через iBeacon знают, где он внутри магазина (иногда с точностью до манекена, который он смотрит, чаще просто отдел). В результате их идея — формировать персональные скидки для человека. Например, "хей! ты вчера интересовался этой курткой, специально для тебя скидка 30%"&lt;br /&gt;
Еще персонализируют фид в приложении, персонализируют нотификации (как способ так и время). Стараются выдать нотификацию в тот момент, когда человек реально может зайти в магазин, а не посреди хайвея.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Recommendations and Decision Support in Agriculture&lt;/em&gt;. Чуваки занимаются рекомендациями и анализом данных в сельском хозяйстве. Пишут о том, что средний фермер за год принимает примерно 40 бизнес-решений, которые очень сильно влияют на дальнейшую судьбу бизнеса. Хотят это оптимизировать и помогать в принятии решений. Очень много данных (реально много), но проблема — они не собраны вместе и часто в разных форматах. Но они двигаются вперед.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Blending Human Computing and Recommender Systems for Personalized Style Recommendations&lt;/em&gt;. Доклад прямо противоположный вчерашнему keynote Джеффа. Компьютеры хороши в том, чтобы быстро что-нибудь посчитать, человек — в распознавании сложных образов и вообще в прекрасном. Они соединяют компьютеры и людей для того, чтобы рекомендовать одежду. Модель такая: человек заходит на сайт, заполняет много-много данных про себя (в том числе неструктурированных, плюс указывает примеры стиля, который ей нравится — они только для девушек). Дальше алгоритм отбирает "кандадатов", потом эксперт в области делает окончательный выбор. И товары отправляются пользователю. Сразу. То есть пользователь посмотрит их уже дома. Рекомендации — это 100% их бизнеса, плюс очень высокие ставки (хотя мне интересно, на что они потратили бы больше — на доставку false positive или на зарплату экспертам).&lt;br /&gt;
Идея интересная, хотя и очень спорная.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Prototyping Trust: Modeling the Virtuous Cycle&lt;/em&gt;. Тетушка из microsoft рассказывала про то, как они дизайнят новый интерфейс взамодействия рекомендаций и человека. Она привела резонный пример, что в человеческих отношениях существует social protocol — мы не сразу рассказываем первому встречному все про себя, но нам нужно какое-то время, чтобы обрести доверие друг друга. Собственно тут идея та же самая — они хотят научить машины уважать этот social protocol. Она говорит, что не нужно доставлять максимально точные рекомендации в первый день. По этому вопросу много споров, например, Аматриан с ней категорически не согласен. Но это их идея в том, чтобы сделать "вежливого" интеллектуального помощника.&lt;/p&gt;
&lt;h2&gt;Keynote&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Thoughts on the Future of Recommender Systems&lt;/em&gt; by Hector Garcia Molina, Standford University
Impressive профессор из Стэнфорда пытался научить всех делать рекомендательные системы. Несколько основных мыслей:
1. нужно объединить (хотя бы по базе знаний и технологиям) поиск, рекомендации и рекламу
2. нужно дать пользователю возможность настройки и влияния на алгоритм
3. нужно дать возможность людям помочь в рекомендации (очень созвучно с blending human computing...)
Дальше долго рассказывал какую они замечательную систему рекомендаций построили в Стэнфорде. Вобщем, совершенно не по делу.&lt;/p&gt;
&lt;h2&gt;Panel&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Controversial Questions About Personalization&lt;/em&gt;. В дискуссии принимали участие Pankaj Gupta (ex-Twitter), Tim Jones (CTO at Upworthy — ecommerce), Eric Bieschke (Chief Scientist and VP at Pandora), Joaquin A Delgado (Director of Engineering of Advertising and Personalization at OnCue – Verizon).&lt;br /&gt;
Много говорили про мораль, по то, какая ответственность лежит на системах рекомендаций, не будет ли так, что пользователь окажется в пузыре. "Все люди в пузыре. Но наше счастье, что он достаточно большой" — Эрик. Они в Pandora, кстати, оптимизируют diversity рекомендаций, это одна из их основных метрик. Еще говорили про то, хорошо ли аб-тестироваться на пользователях и о том, как сделать так, чтобы они поняли почему их рекомендации хуже.&lt;/p&gt;
&lt;h2&gt;Matrix factorization&lt;/h2&gt;
&lt;p&gt;Последняя сессия была довольно интересной.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;GASGD: Stochastic Gradient Descent for Distributed Asynchronous Matrix Completion via Graph Partitioning&lt;/em&gt;. Чуваки делают раcпределенный SGD за счет разбиения графа рейтингов (?). Основные улучшения — метод партиционирования, уменьшение количества разделяемых данных между нодами и введение синхро-параметра (отвечает за то, как часто ноды синхронизируются, конролирует tradeoff между качеством и скоростью). Реально на распределенной системе они еще не тестили, только в симуляторе.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A Framework for Matrix Factorization based on General Distributions&lt;/em&gt;. О том, как обобщить probabilistic matrix factorization на любые распределения. GD (или SGD), для вычисления производной делают численное дифференцирование.
&lt;a href="https://github.com/josefbauer/DMF"&gt;https://github.com/josefbauer/DMF&lt;/a&gt; (will be soon available?)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Speeding Up the Xbox Recommender System Using a Euclidean Transformation for Inner-Product Spaces&lt;/em&gt;. Отличная работа Кенингстайна про то, как ускорить выбор кандидатов. Суть в том, что они перевели пространство, где оптимизируется скалярное произведение в пространство, где нужно оптимизировать евклидово расстояние. Дальше применяют PCA-деревья (как kd, только раскладывают по главным компонентам всего множества). Для ускорения поиска они применяют эвристику — пронумеровав все листья они ищут соседей по листам с расстоянием Хэмминга 1 до данного.&lt;br /&gt;
Результаты очень классные.&lt;br /&gt;
P.S. прочитал их статью — там очень простые преобразования, правда. Это должно очень хорошо работать. Но эвристика с расстоянием Хэмминга — все же эвристика, то есть стоит понимать, что результат будет не точный.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно&lt;/strong&gt;: &lt;em&gt;Gradient Boosting Factorization Machines&lt;/em&gt;. Очень простая идея — метод Context Aware FM считает все попарные сочетания факторов. Но не все из них реально полезны! Собственно, чуваки придумали, каким образом ввести коэффициенты для фичей и жадно оптимизировать слой за слоем (у них только слой 2). Плюс еще превзошли сами себя и придумали, как оптимизировать все это используя shared latent vectors. Рекомендую статью к прочтению.&lt;br /&gt;
На эксперименте рвут всех (само собой).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Exploiting Temporal Influence in Online Recommendation&lt;/em&gt;. Парень исследует влияние совместных скробблингов исполнителей в last.fm. Вводит красивую вероятностную модель, сводит это к нескольким матричным разложениям и много махает руками. Тут основная проблема в том, как он измеряет, у него DCG@1. То есть фактически, это не ранжирование, а предсказание.&lt;/p&gt;
&lt;p&gt;В перерывах несколько раз разговаривал с Эриком. Он рассказал, что у них почти все в проде написано java, а исследования на scala. Они пользуются хадупом, пробовали spark, но он очень нестабилен, да и прирост в производительности маленький. Параметры (Миша, тебе лучше присесть) они подбирают на глазок! То есть выбирают то, что описано в статье и неплохо работает и все. Никаких оптимизаций у них нет! Очень внезапно.&lt;br /&gt;
Рассказывал, что они используют word2vec (своя реализация в проде и gensim для исследований), но в основном для похожестей. Я так понял, что у них даже в этом блоке работает ансамбль. Про контент-майнинг — они предсказывают латентные вектора item-ов, но это тоже только для похожестей и не в проде пока. vector_exp действительно у них хорошо работает, там очень простая идея, пока даже онлайна нет.&lt;br /&gt;
Примерно так.  &lt;/p&gt;
&lt;p&gt;Следующий RecSys будет в Вене 16-20 сентября 2015. Огласили программу RecSys Challenge — нужно будет по данным eCommerce системы научиться предсказывать а) была ли в сессии покупка б) и что купили. Данные и условия скоро выложат.&lt;/p&gt;
&lt;h1&gt;Пятница (10 октября)&lt;/h1&gt;
&lt;p&gt;Сегодня был последний день конференции — только воркшопы. Первоначально я планировал идти только на large scale recommender systems, но потом скипнул несколько докладов и послушал вместо них recsysTV. Так что если вдруг статья будет про тв — не удивляйтесь.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Recommendation Architecture: Going Beyond the Collaborative Filter&lt;/em&gt;.  Доклад чуваков из OpenTable — рекомендательная система ресторанов. У них 32k ресторанов,  $25B (в год?) тратят их клиенты в offline-ресторанах. Говорили достаточно много очевидных вещей. В целом идея — real goal: minimize engineering time to improve metric that matters. Такой подход легче измерить, итерации короче и проще. Дальше говорили, что стоит смотреть на то, как люди используют продукт, смотреть и на AB-тесты и «глазами аналитика». Дальше говорили про то, как стартовать рекомендательную систему, что хорошо начинать с простых эвристик и простых метрик типа RMSE. А уже потом переходить на learning2rank. Еще хорошо бы смотреть на variability of predictions, чтобы быть уверенным в своих рекомендациях и не порекомендовать что-то потенциально плохое.&lt;br /&gt;
Еще немного рассказывали о том, что они майнят темы из ревью через non-negative MF + TF-IDF (такой вариант топик-моделлинга). Кстати, у них темы визуализируются клевыми облаками тэгов.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Latent Feature Based FM Model For Rating Prediction&lt;/em&gt;. Задача: добавить контент в Factorization Machines. Один способ — сделать topic modelling и добавить тему как aux information. Второй — выделить вектора слов через word2vec и добавить как aux info в FMs. Результатов не дождался — сбежал на доклад Netflix.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Personalized Page Generation for Browsing Recommendations&lt;/em&gt;. Парень из Netflix рассказывал, как они строят персональную страницу пользователя.&lt;br /&gt;
Начало пересекалось с туториалом Аматриана, скип. Идея персонализации — смотреть как люди скроллят и взаимодействуют со страницей. Простой подход — просто строки на фиксированных местах (со своим ранкингом внутри). Выбирать можно rule-based, жадно и жадно с разнообразием. Второй подход — намайнить кучу фичей про блок (например, его размеры, CTR, quality, evidence, recency, how big, etc.), дальше строить page-level метрики: easy to discovery, diversity, novelty, recall@box (recall по области из нескольких блоков). Дальше добавляются блоки (разных размеров!).&lt;br /&gt;
Все это происходит в три этапа (offline, near RT, RT). То есть что-то они делают прямо налету, да. Но сильно не все.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Large-scale Recommendation in E-commerce&lt;/em&gt;. Чуваки из taobao.com (alibaba group) рассказывали, какие классные рекомендации они делают. Рекомендации разделены на retrieval и ranking + reranking. Плюс они в своем рекоммендере используют asynchronous distributed OnlineGD для обучения MF (?) на implicit-данных (например, dwell-time, click vs long click etc.). Поверх всего этого работает простая логистическая регрессия. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Personalized Content Recommendation in Practice: The StumbleUpon model&lt;/em&gt;. Тетушка рассказывала про StumbleUpon. Это фактически рекомендации страниц как у surfingbird: 180M indexed pages, +75k per day, примерно 500 интересов. 35 страниц пользователь смотрит в сессию, 3,5 часа на пользователя в месяц.&lt;br /&gt;
Основной упор на diversity (когда показать лучшую рекомендацию? сейчас или когда пользователь уже «почти» будет готов уйти?). Из интересного — они майнят экспертов, чтобы а) уменьшить шум данных б) увеличить точность и интересность материала.&lt;br /&gt;
Исползуют все модели – и CB и CF, но diversity is most important factor. Рекомендации генерятся налету. Еще по их опыту рейтинги не помогают почти никак — очень шумные (вы залайкаете котика, но он вам не интересен. А интересный мателиал про какую-нибудь проблему вы не будете лайкать — это слишком серьезная вещь). Ну и да, большинство лайков происходит еще до того, как пользователь прочитал материал. А вот негативные отзывы требуют больше времени, чтобы сформировать эмоции. Этот эффект можно использовать — они предсказывают, где пересекутся кривые ожидания времени лайка и дислайка для предсказания рейтинга. Да, ранжированием они начали заниматься, но там все трудно, так как выигрыш в MF не значит лучший продукт. Они много занимаются сегментацией рейтингов и пользователей и очень много майнят из контента. 
Full stack:
  * ingestion — feature analysis of content
  * sampling — how well this content will do?
  * rec pipelines — compute user-url metches, refresh data sources
  * rec engine — runtime (depends on device)
  * online computation — collecting events and online features and updating models
а еще реклама, дубликаты, классификаторы страниц, и т.д.&lt;br /&gt;
Короче, крутые чуваки. Я делал много фотографий ее слайдов. Если слайды не выложат, то обработаю эти фотки — интересный доклад.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Graphlab tutorial&lt;/em&gt;. Основатель(?) graphlab сел и за двадцать минут показал, как просто это использовать.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Building Large-Scale Recommender Systems for TV&lt;/em&gt;. Скучный доклад тетушки из Samsung о том, как они строят рекомендации. hadoop, yarn, spark, обзор, бла-бла-бла… Интересно следующее: они используют automatic content recognition, то есть телек сам понимает, какое шоу показывают. Они что-то сделали в направлении объединения контентного пространства и коллаборативного пространства. Но что конкретно?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Large Scale Purchase Prediction with Historical User Actions on B2C Online Retail Platform&lt;/em&gt;. Доклад победителей (?) Tmall price (китайское соревнование по ecommerce). Суть в том, что выдали 500M ratings, 10M users, 30k brands и нужно было предсказать по сессии купит ли пользователь данный бренд. Интересный момент — всем дали кластер!&lt;br /&gt;
Чуваки делают много-много-много фичей, некоторые как у нас, некоторые нам надо бы попробовать. Подробности в статье. Feature selection у них наивный, просто по significance в модели.&lt;br /&gt;
Рекомендательная система двухслойная: на первом слое куча сложных моделей (MF, Random forest, GBDT etc), на втором — логистическая регрессия (чтобы не переобучаться, как они говорят).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Distributed framework for ALS&lt;/em&gt;. Очень простая идея — если считать ALS распределенно, то нужно передавать по сети матрицу (P^T * P + lambdaI)^-1. Так вот если ноды объединить в блоки и передавать один раз на блок (а еще мультикастом), то будет хорошо. Но это лишь идея, проработки почти никакой.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Machine Listening at Pandora&lt;/em&gt;. Чуваки из Пандоры намекнули, почему в совсем недалеком будущем останутся только они. Общеизвестно, что у них есть разметка экспертами полутора млн треков. Так вот, inside: они активно майнят свои фичи из контента для неразмеченных треков используя эту гигантскую базу. Дальше он приводил пример того, как выделять сильные доли по контенту (это вроде стандартно и очевидно, Женя, можем поговорить, если надо). Они много чего научились майнить автоматически подобным образом, им очень просто настраивать алгоритмы. На датасетах MIREX-а показывают 0.999, в то время как текущие лучшие результаты в районе 0,6 — 0,9 в разных задачах. Это просто power of data.&lt;br /&gt;
Но предсказание жанра и фичей еще не все — важный момент — это построение плейлиста. У них используется metric learning. Но не только — они очень много чего делают и пробуют.&lt;br /&gt;
q1: deep learning? representation learning?&lt;br /&gt;
пробовали, но не скажут.&lt;br /&gt;
q2: popularity?&lt;br /&gt;
вроде не учитывают ее совсем&lt;br /&gt;
q3: discogs will improve?&lt;br /&gt;
в основном свои данные&lt;br /&gt;
q4: how compares with itunes?&lt;br /&gt;
никак, у них нет данных для объективного сравнения&lt;br /&gt;
q5: а тексты?&lt;br /&gt;
нет, это wide open problem. А вот эмоции майнят.&lt;br /&gt;
q6: do users use cultural vs musicological reason for declaring songs? cultural и musical не так далеки — на самом деле некий tradeoff.  &lt;/p&gt;
&lt;p&gt;С таким размеченным датасетом они могут почти все, что угодно…  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно&lt;/strong&gt;: &lt;em&gt;Introducing the Metric Optimization Engine (MOE)&lt;/em&gt;. Optimal learning — most effective way to collect information. Ребята в Yelp сделали фреймворк, который позволяет это делать. Оптимально обучаться, оптимально тюнить параметры, оптимально тестировать. Все это на explore-exploit.&lt;br /&gt;
Как это работает:
  * builds Gaussian Process from sampled points
  * optimize covariance hyperparams of Gp
  * choose point with hight expected improvement
  * return next optimal point
Быстро сходится, отлично параллелится (можно делать мультисемплинг), можно исопльзовать GPU, можно как угодно задавать objective function… И все это уже работает в их production. И open source.&lt;br /&gt;
Короче, надо брать: &lt;a href="https://github.com/Yelp/MOE"&gt;https://github.com/Yelp/MOE&lt;/a&gt;&lt;/p&gt;</summary></entry></feed>