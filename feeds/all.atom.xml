<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>4ducks</title><link href="http://www.4ducks.ru/" rel="alternate"></link><link href="http://www.4ducks.ru/feeds/all.atom.xml" rel="self"></link><id>http://www.4ducks.ru/</id><updated>2014-10-25T10:52:00+04:00</updated><entry><title>ITMO RS 2014 ~ Lecture 2</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-2.html" rel="alternate"></link><updated>2014-10-25T10:52:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-25:itmo-rs-2014-lecture-2.html</id><summary type="html">&lt;h2&gt;SVD continued&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Рассказ про iALS, оптимизацию ALS1 и iALS1, rank ALS. Объяснение SVD рекомендаций.&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/40706158" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Статьи&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Hu Y., Koren Y., Volinsky C. &lt;a href="http://yadi.sk/d/b4BEAs5t6NUOp"&gt;Collaborative filtering for implicit feedback datasets&lt;/a&gt; //Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on. – IEEE, 2008. – С. 263-272.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;li&gt;Takács G., Tikk D. &lt;a href="http://yadi.sk/d/lg6F-o6j6y9qq"&gt;Alternating least squares for personalized ranking&lt;/a&gt; //Proceedings of the sixth ACM conference on Recommender systems. – ACM, 2012. – С. 83-90.&lt;/li&gt;
&lt;li&gt;Herlocker J. L., Konstan J. A., Riedl J. &lt;a href="https://yadi.sk/i/ebMoIaU0cGHHy"&gt;Explaining collaborative filtering recommendations&lt;/a&gt; //Proceedings of the 2000 ACM conference on Computer supported cooperative work. – ACM, 2000. – С. 241-250.&lt;/li&gt;
&lt;li&gt;Pilászy I., Tikk D. &lt;a href="http://yadi.sk/d/I4p_DeWg8paLQ"&gt;Explaining Recommendations of Factorization-Based Collaborative Filtering Algorithms&lt;/a&gt; //Acta Technica Jaurinensis. – 2009. – Т. 2. – №. 2. – С. pp. 233-248.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-1.html"&gt; &amp;lt;- Предыдущая лекция&lt;/a&gt;&lt;/p&gt;</summary></entry><entry><title>ITMO RS 2014 ~ Lecture 1</title><link href="http://www.4ducks.ru/itmo-rs-2014-lecture-1.html" rel="alternate"></link><updated>2014-10-18T11:05:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-18:itmo-rs-2014-lecture-1.html</id><summary type="html">&lt;h2&gt;Введение в рекомендательные системы&lt;/h2&gt;
&lt;h3&gt;Краткое содержание&lt;/h3&gt;
&lt;p&gt;Лекция-введение. Рассказывал про рекомендательные системы в целом, о том, какие они бываю и какие данные используют.
Разобрали kNN-модели и SVD, рассказал как применять SGD и ALS для обучения SVD. Поговорили про evaluation (общая схема и чуть более предметно про online-тестирование).&lt;/p&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/40706158" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"&gt;&lt;/iframe&gt;

&lt;h3&gt;Ссылки&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.netflixprize.com/"&gt;Netflix Prize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sifter.org/~simon/journal/20061211.html"&gt;Netflix Update: Try this at home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Книги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ricci F. et al. &lt;a href="http://yadi.sk/d/pq3fcJgT9voSt"&gt;Recommender systems handbook.&lt;/a&gt; – Springer US, 2011.&lt;/li&gt;
&lt;li&gt;Celma O. &lt;a href="http://yadi.sk/d/l0ZSsEY69STGT"&gt;Music Recommendation and Discovery: The Long Tail, Long Fail, and Long Play in the Digital Music Space.&lt;/a&gt; – Springer, 2010.&lt;/li&gt;
&lt;li&gt;Jannach D. et al. &lt;a href="http://www.amazon.com/Recommender-Systems-Introduction-Dietmar-Jannach/dp/0521493366"&gt;Recommender systems: an introduction.&lt;/a&gt; – Cambridge University Press, 2010.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Статьи&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Koren Y., Bell R., Volinsky C. &lt;a href="https://yadi.sk/i/CGSXNzr4c89ZY"&gt;Matrix factorization techniques for recommender systems&lt;/a&gt; //Computer. – 2009. – Т. 42. – №. 8. – С. 30-37.&lt;/li&gt;
&lt;li&gt;Koren Y. &lt;a href="http://yadi.sk/d/pTVIQqFP6TjWm"&gt;Factorization meets the neighborhood: a multifaceted collaborative filtering model&lt;/a&gt; //Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. – ACM, 2008. – С. 426-434.&lt;/li&gt;
&lt;li&gt;Pilászy I., Zibriczky D., Tikk D. &lt;a href="http://yadi.sk/d/ye_l0Z0u6vUvO"&gt;Fast als-based matrix factorization for explicit and implicit feedback datasets&lt;/a&gt; //Proceedings of the fourth ACM conference on Recommender systems. – ACM, 2010. – С. 71-78.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://www.4ducks.ru/itmo-rs-2014-lecture-2.html"&gt;Следующая лекция -&amp;gt; &lt;/a&gt;&lt;/p&gt;</summary></entry><entry><title>Предыстория лекций в ИТМО</title><link href="http://www.4ducks.ru/predystoriia-lektsii-v-itmo.html" rel="alternate"></link><updated>2014-10-15T18:50:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-15:predystoriia-lektsii-v-itmo.html</id><summary type="html">&lt;p&gt;В осеннем семестре 2014 года я провожу факультативный курс лекций по рекомендательным системам в &lt;a href="http://www.ifmo.ru/"&gt;СПб НИУ ИТМО&lt;/a&gt; на кафедре КТ ФИТиП.&lt;/p&gt;
&lt;h1&gt;Предыстория&lt;/h1&gt;
&lt;p&gt;В далеком 2012 году Антон Банных предложил мне рассказать его студентам что-нибудь про анализ данных и применение машинного обучения в Яндексе. В тот момент я начал заниматься рекомендательными системами и уже имел некоторые знания области. Я согласился и рассказал студентам четвертого курса основы рекомендаций. Но это были действительно основы — я сделал упор на &lt;a href="http://en.wikipedia.org/wiki/Association_rule_learning"&gt;ассоциативные правила&lt;/a&gt; и &lt;a href="http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"&gt;метод ближайших соседей&lt;/a&gt;. Немного рассказал про SVD, еще меньше - про оценку рекомендаций. Так сказать, первый блин вышел комом.&lt;/p&gt;
&lt;p&gt;На следующий год мои познания в области существенно выросли, как и умение рассказывать эти самые азы. Я снова углубился в создание рекомендаций для Яндекс.Музыки, на этот раз в компании московских коллег. И для "быстрого старта" сделал парочку семинаров для коллег по основам коллаборативной фильтрации. И ребятам польза, и у меня в голове знания еще раз уложились.&lt;br /&gt;
В результате я уже сам предложил Антону свою помощь. На мой взгляд, лекция удалась — я за короткое время сделал обзор простых, но в то же время хорошо работающих методов коллаборативной фильтрации (SVD и kNN — да! как показывает RecSys его до сих много кто использует), немного пробежался по контентным методам и уделил время более подробному (относительно прошлого раза) рассказу про оценку.
Кроме того, в этот год к обычным лабораториям по машинному обучению добавилась лабораторная по рекомендациям, где я предлагал на данных movielens обучить SVD-алгоритм различными способами. Справились, к сожалению, не все, но были ребята, которые сделали даже ALS1!&lt;/p&gt;
&lt;p&gt;В этом году на машинном обучении у студентов четвертого курса КТ тоже будет моя лекция — даже две (хотя это примерно то же самое, в прошлый раз я читал чуть меньше двух пар, зато подряд без перерыва). Но я решил, что можно не останавливаться на достигнутом. Поэтому (та-да-да-дам-та-дам!) предложил студентам четвертого, пятого и шестого курсов серию факультативных лекций.&lt;/p&gt;</summary></entry><entry><title>Заметки с RecSys 2014</title><link href="http://www.4ducks.ru/zametki-s-recsys-2014.html" rel="alternate"></link><updated>2014-10-15T09:23:00+04:00</updated><author><name>Andrey Danilchenko</name></author><id>tag:www.4ducks.ru,2014-10-15:zametki-s-recsys-2014.html</id><summary type="html">&lt;p&gt;На прошлой неделе в Foster City, CA прошла конференция RecSys'14.&lt;/p&gt;
&lt;p&gt;Содержимое флешки с оглавлением: &lt;a href="https://yadi.sk/d/-DVv6cBwbqyM8"&gt;https://yadi.sk/d/-DVv6cBwbqyM8&lt;/a&gt;&lt;br /&gt;
Видео всех докладов и постеров: &lt;a href="https://www.youtube.com/playlist?list=PLaZufLfJumb9A95nS5AmY6G5mqYnwIfZX"&gt;https://www.youtube.com/playlist?list=PLaZufLfJumb9A95nS5AmY6G5mqYnwIfZX&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Понедельник (6 октября)&lt;/h1&gt;
&lt;p&gt;День туториалов, поэтому нового мало.&lt;/p&gt;
&lt;h2&gt;T1&lt;/h2&gt;
&lt;p&gt;Вначале рассказывал Аматриан, это была часть его «стандартного» туториала с MLSS, только в два раза короче. Он пробежался по основным методам (memory-based, svd, rbm, arules, clustering, classification, content-based), а во второй части акцентировал внимание на том, чему они научились во время (и после) Netflix Prize. Это «эволюция рекомендательных систем»: rating -&amp;gt; ranking -&amp;gt; page optimization -&amp;gt; context-aware recommender. С первым и вторым более менее понятно (хотя тут он снова много рассказывал про методы, pairwise и pointwise, про то, что хорошо оптимизировать loss-function для ранжирования, но можно, например, делать это не напрямую, а косвенно. Хотя, конечно, работает хуже). Еще отдельно были упомянуты похожести как рекомендации. Их можно строить через графовые методы, например, sim-rank, через «похожести» в метаданных, в поведении пользователей и в рейтингах (это как раз CF-подходы). Все это очень хорошо работает в ансамбле. Но если трудно обучать ансамбль, то можно использовать бандитов.&lt;/p&gt;
&lt;p&gt;Еще говорил про deep learning, но сразу оговорюсь — тут все только зарождается (в основном благодаря тому, что научились эффективно учить сети, см. &lt;a href="http://techblog.netflix.com/2014/02/distributed-neural-networks-with-gpus.html"&gt;http://techblog.netflix.com/2014/02/distributed-neural-networks-with-gpus.html&lt;/a&gt;). Упоминались методы из Spotify (RNN и обучение латентных векторов). Из spotify, кстати, всего один человек, Бернхардсона не было.
Немного упомянул про social RS (но дальше был отдельный туториал по ним). Кстати, мелькнула идея регуляризации близких пользователей.&lt;/p&gt;
&lt;p&gt;Про page optimization (самое интересное) Аматриан говорил мало, не хватало времени. В кратце: основная идея состоит в том, что у нас 10000 item-ов, которые можно показать и дофига блоков. Но показывать это все надо не просто так, а оптимизируя страницу целиком для конкретного пользователя (и конкретного девайса тоже). Работ тут пока мало, упоминалась вот эта: &lt;a href="http://www.cs.cmu.edu/~amahmed/papers/SVCM_WSDM12.pdf"&gt;http://www.cs.cmu.edu/~amahmed/papers/SVCM_WSDM12.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Еще говорил про context-aware RS: тензорные разложения и factorization machines.&lt;/p&gt;
&lt;p&gt;Интересная часть — о многоруких бандитах. Их активно используют для exploration/exploitation. Можно так подбирать параметры в online, можно выбирать алгоритмы (тогда это работает как гибридная RS). &lt;/p&gt;
&lt;p&gt;Про implicit feedback был вопрос о том, как бороться с bias-ом от того, что пользователь смотрит то, что мы ему показываем. Тут решение либо сэмплить, либо исопользовать бандитов.&lt;/p&gt;
&lt;h2&gt;T2&lt;/h2&gt;
&lt;p&gt;Какие-то невнятные китайцы с отвратительным английским пытались рассказывать про location based recommender на основе соцсетей. Но никто ничего не понял, большая часть людей свалила. Мне так сделать не удалось, но туториал был бесполезный.&lt;/p&gt;
&lt;h2&gt;T3&lt;/h2&gt;
&lt;p&gt;Паоло Кремонези рассказывал про Cross-Domain Recommender Systems. Это был неплохой обзор того, кто чего делает в области.
Очень много всякой разной классификации по типу чего-нибудь. В целом выводы примерно такие: 1) есть разные цели: cold-start, cross-selling, improving quality и разные свойства доменов (например, разное пересечение пользователей, item-ов, аттрибутов). Исходя из этого применяются разные методы от самых тупых (аггрегация профилей, моделей, рейтингов) до сложных (тензорные факторизации, три-матричная кофакторизация, codebook transfer). Про последний забавно — они только что показали, что cross-domain тут непричем — это просто хороший matrix factorization метод. Методы оценки также зависят от того, в каком домене и кому мы хотим рекомендовать.&lt;/p&gt;
&lt;h2&gt;T4&lt;/h2&gt;
&lt;p&gt;Social Recommender Systems. Рассказывали чуваки из Yahoo и IBM (Ido Guy). Идея в том, что web2.0 — интернет людей. Отсюда появились соцсетки и социальные медиа. Очень много новой информации вроде тэгов, голосовалок (like) и комментариев. &lt;/p&gt;
&lt;p&gt;Про рекомендации контента: есть два типа связей — знакомство (люди связаны в сети) и похожесть (люди состоят в одних группах и комментируют одни материалы). Первые дают более точные, но более скучные рекомендации (еще они помогают в explanation), вторые сильно увеличивают diversity и serendipity (имхо, это уже CF). Упоминал статью про google reader: &lt;a href="http://dl.acm.org/citation.cfm?id=1719976&amp;amp;dl=ACM&amp;amp;coll=DL&amp;amp;CFID=438180616&amp;amp;CFTOKEN=35684830"&gt;http://dl.acm.org/citation.cfm?id=1719976&amp;amp;dl=ACM&amp;amp;coll=DL&amp;amp;CFID=438180616&amp;amp;CFTOKEN=35684830&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Еще интересный факт: «входящие» данные (то, что про пользователя думает окружение) работает лучше, чем исходящие данные (лайки, тэги) самого пользователя.&lt;/p&gt;
&lt;p&gt;Рекомендации тэгов еще одна тема. Используются CF-методы, гибридные (Rendle’2010, видимо вот это имелось в виду: &lt;a href="http://www.informatik.uni-konstanz.de/rendle/software/tag-recommender/"&gt;http://www.informatik.uni-konstanz.de/rendle/software/tag-recommender/&lt;/a&gt;). Хорошо работают графовые методы: &lt;a href="http://www.kde.cs.uni-kassel.de/stumme/papers/2006/hotho2006folkrank.pdf"&gt;http://www.kde.cs.uni-kassel.de/stumme/papers/2006/hotho2006folkrank.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Про рекомендации сообществ говорил про комбинацию arules и lda на контенте (странно что не упомянул одноклассников).&lt;/p&gt;
&lt;p&gt;Рекомендация людей (друзей, кого фолловить): есть методы на контенте, FoF и SONAR. В опросах побеждают последние, но по факту они быстро исчерпывают себя — человек и так знаком с рекомендуемыми людьми. Тут было довольно спорно все. Кстати, для предсказания кого фолловить внезапно follower-ы человека более информативны, чем те, кого он сам фолловит.&lt;/p&gt;
&lt;p&gt;Много говорили про создание контента. Так как активно генерят контент всего 1% пользователей, то нужно их мотивировать. В частности, рекомендация тэгов — это мотивация. Приводилось две теории генерации контента: самоопределение и теория Foggs behaviour model (для действия нужны мотивация (нужно хотеть), доступность (это не должно быть слишком сложно) и trigger — событие, которое станет «последней каплей», например, это может быть письмо от соцсети).&lt;/p&gt;
&lt;p&gt;Говорили про интересное исследование: пользователи, которым в самом начале порекомендовали «активных» в друзья, с гораздо большей вероятностью сами становятся активными. Еще была долгая история про то, как рекомендовали темы блогов. С одной стороны, не было значимого увеличения в количестве постов. Но зато посты по рекомендациям собирали гораздо больше посещений и лайков.
Тут отдельный момент — как такие рекомендации меняют структуру сети. Например, FoF создает хабы. А Content matching создает связи к странным людям всего с несколькими друзьями…&lt;/p&gt;
&lt;p&gt;Кратко о trust and reputation: есть семейство графовых методов, которые с помощью «trust» и его распространения в сети могут повысить качество коллаборативки. Пример: повышаем рекомендации от доверенных пользователей, понижаем от недоверенных.
Reputation — это общее доверие, которым пользователь обладает в сети. Аналог page rank.&lt;/p&gt;
&lt;p&gt;Немного говорили про рекомендации группе людей, тут работ мало, в основном работает аггрегация профилей. Еще упоминали интересную работу &lt;a href="http://www.research.ibm.com/haifa/dept/imt/papers/sigir191-ronen.pdf"&gt;http://www.research.ibm.com/haifa/dept/imt/papers/sigir191-ronen.pdf&lt;/a&gt; (свою) про рекомендации контента для владельцев групп.
Снова интересно, как это меняет сеть.&lt;/p&gt;
&lt;h1&gt;Вторник (7 октября)&lt;/h1&gt;
&lt;p&gt;Вторник — первый день основной конференции, программа тоже более интересная.&lt;/p&gt;
&lt;h2&gt;Keynote&lt;/h2&gt;
&lt;p&gt;Вначале был &lt;em&gt;keynote&lt;/em&gt; от Нейл Ханта (технический директор Netflix). Он внезапно начал с того, что доверие пользователей с нами не навсегда и (опираясь на кучу историй с гуглом) призвал всех быть предельно аккуратными, чтобы не потерять свою аудиторию.
Дальше он рассказал краткую историю рекомендаций в компании — в основном раньше брали в прокат только новые релизы, а потом они оставались у них на складе навсегда. После внедрения рекомендаций стало сильно лучше, сейчас новые релизы — это примерно 10%
Были интересные параллели с Linear TV и on-demand TV, Netflix видимо мощно двигается в эту сторону (например, через приложения для телеков) и они говорят об изменении классического формата (бродкаст, 21 час в неделю prime-time и больше ничего). Они не продают рекламу, не продают данные пользователей, но могут делать только качественные рекомендации (примерно 150M «решений»(событий?) в день, 50M пользователей). 1% увеличения к количеству просмотров — это более $500M.
Им очень хочется измерять retention, но это невозможно. Хороший прокси — часы просмотра (так же и у нас в радио). Но не все изменения полезны — даже увеличивая эту метрику они могут потерять пользователей с низким числом просмотров, поэтому смотрят на всю кривую.
Еще интересная мысль — они могут технически (и видимо уже собираются это делать) говорить продюссерам, как будет принят фильм. И могут предсказывать хорошие ниши даже для очень маленьких аудиторий. Вообще «there are no bad shows, just shows with small audience».
И да, еще интересный момент. Они пробовали просить пользователей самим поранжировать вручную. Но их алгоритм по метрике лучше =)&lt;/p&gt;
&lt;p&gt;Во время перерыва говорил с чуваками из Pandora (с Оскаром Сельма тоже, кстати, он там теперь большой начальник). Они рассказали, что используют только разметку, но разметка фичей не бинарная, а обычно в пятибальной шкале. Дальше из этого уже майнят эфир. Новые фичи не добавляются, но зато можно добавить новый домен (например, комедии) со своим набором фич.&lt;/p&gt;
&lt;p&gt;У Гугла спрашивал, используют ли они единую систему рекомендаций. Сказали, что нет, обычно продукт пишет что-то свое. Вообще они очен мало рассказывали по делу, девочка даже ноут от меня прикрыла (хотя я не мог видеть что там, да и не пытался даже) =)&lt;/p&gt;
&lt;p&gt;Поговорил с Рикардо Диасом, который делал доклад &lt;a href="http://ceur-ws.org/Vol-1245/cbrecsys2014-paper05.pdf"&gt;http://ceur-ws.org/Vol-1245/cbrecsys2014-paper05.pdf&lt;/a&gt; на вчерашнем воркшопе. Он пересказал мне вкратце свой метод — они просто берут фичи у эхонеста и пытаются играть треки, которые хорошо подходят к активности конкретного пользователя. Но масштабы там маленькие.&lt;/p&gt;
&lt;h2&gt;Novel applications&lt;/h2&gt;
&lt;p&gt;Заговорившись в холле пропустил первый доклад, как и многие другие =(
Доклад &lt;em&gt;Automating Readers’ Advisory to Make Book Recommendations for K-12 Readers&lt;/em&gt; — это рекомендации детских книжек. Они строят рекомендации на темах и анализе контента, выделяя факторы (например, storyline: fun). Выделение с помощью правил-шаблонов из ревью.
По их замерам лучше Novelist, но хуже амазона (что странно при том, что они очень нишевые).&lt;/p&gt;
&lt;p&gt;Еще был доклад про &lt;em&gt;Robust Model for Paper-Reviewer Assignment&lt;/em&gt;, в целом про то, как выделять экспертов. У них графовая модель, случайные блуждания с рестартом. В вершинах все объекты (авторы, статьи, темы), на ребрах отношения (автор-автор, статья-автор, статья-тема). Темы выделяют через LDA. Разнообразия ревьюеров они добиваются используя кластеризацию и l1 нормой убивая лишних.
Судя по их графикам выигрывает RWR, но они не сравнивали с существующими системами — типа другие данные&lt;/p&gt;
&lt;p&gt;Следующий доклад: &lt;em&gt;Exploiting Sentiment Homophily for Link Prediction&lt;/em&gt; — используя окраску твитов опрелеляют друзей. Строят граф связей различным образом (самый жгущий — это @mentions &amp;gt; N). По тэгам твитов определяют темы и смотрят как разные пользователи к ним относятся. Дальше строят скор кандидатам. Вроде неплохо получается по F1.&lt;/p&gt;
&lt;h2&gt;Novel setups&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Factored MDPs for Detecting Topics of User Sessions&lt;/em&gt;. Обычно нужно по предыдущему item-у определить следующий, но почему бы не делать это по сессии? Собственно, чуваки так и делают: строится MDP — состояния — аттрибуты (всего четыре), действия — выбор следующего, вознаграждение — клики, и матрица переходов.
В предположении независимости атрибутов получают существенное ускорение. 
Дальше имея Q-функцию они определяют тему сессии как распределение вероятностей атрибутов (плюс обрезание по общему порогу). Для длинных сессий хорошо работает точный MDP, для коротких — приближенный.
Дальше применяют свою модель тем для построения рекомендаций и оказываются лучше матричного разложения по AvgPos.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Context Adaptation in Interactive Recommender Systems&lt;/em&gt;. Многорукие бандиты с определением смены контекста. Собственно, exploitation — если контекст одинаковый (item выбирается с вероятностью быть лучшим), exploration — если смена. Смену контекста определяют так: берут два окна (рядом, но не пересекая) и считают модели. Дальше смотрят на разницу. 
Сравнивались с user-based kNN на Y!Music, смену контекста симулировали рандомной сменой пользователя в тест сете. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Question Recommendation with Constraints for Massive Open Online Courses&lt;/em&gt;. Рекомендуют темы форума на курсере, стараются увеличить overall community benefit. Сначала строят скор релевантности (через этакий супер-SVD со статистиками внутри как в %%SVD++%%), потом max concave cost flow, используют три фактора для фильтрации тем и юзеров: capability (expertise), capacity (number of question to work on), Hardness (how difficult question).
Данные, 3 курса с coursera, в питоне (самый большой) 3 тыс пользователей и 3 тыс itemов. Меряют MAP@1 @3 @5, сравнились с простым MF по ним.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Attacking Item-Based Recommender Systems with Power Items&lt;/em&gt;. Чувак очень здорово напугал всех тем, как легко и эффективно можно проводить атаки на user-based, item-based и SVD RS. Типы атак: push (поднимаем item), nuke (опускаем item) и disrupt (выводим систему из строя).
Как это делается: назначается target item, остальные рейтинги симулируются (разными способами) так, чтобы было похоже на обычного userа. Они находят «power users» и power items такие, которые больше всего влияют на систему. Дальше они могут быть похожи на такого user-а или оценивать такие item-ы. В случае item-based систем хорошо работает multitarget attack, у одного пользователя несколько target-итемов.
Атаки весьма эффективны по hit rate и по rating shift. Говорит, что есть хорошие защиты (работы 2002 и 2010 года), основная идея — смотреть на большое количество аномальных новых пользователей.&lt;/p&gt;
&lt;h2&gt;Cold start&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Ensemble Contextual Bandits for Personalized Recommendation&lt;/em&gt;. Идея в том, чтобы использовать многоруких бандитов как ансамбль когда мало данных для разделения моделей. Два шага: начала используется вес алгоритма в ансамбле, потом для каждого item-а алгоритмы говорят его вероятность. Все это совмещается и получается не сильно хуже, чем лучший алгоритм. Зато можно жить не выбирая модель.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Cold-start News Recommendation with Domain-dependent Browse Graph&lt;/em&gt;. Очень хорошая работа из Yahoo! Labs. Они исследовали user cold start для новостей. Идея: поведение пользователей отличается в зависимости от referer-а с которого они пришли. Чуваки выделили несколько больших рефереров (соцсети и поисковые системы) и построили для них browse-graph (с вершинами — статьями и ребрами — переходами). Кстати, графы поисковиков и соцсетей очень отличаются, а в группах большое пересечение. Дальше исследуют влияние разных рекомендаций в таких графах. Получается, что можно сделать лучше! Да, графы пересчитывают каждый час. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Item Cold-Start Recommendations: Learning Local Collective Embeddings&lt;/em&gt;. Еще работа из Yahoo! Labs. Идея в том, что они раскладывают две матрицы content matrix и collaborative matrix вместе, одна формирует темы, другая — группы пользователей. Но матрица фичей одна! То есть можно зная темы документа предсказать рейтинг для каждого пользователя. Используют два датасета: новости и предсказание адресата в почте. По почте почти так же как bpr+knn, где-то лучше, где-то хуже по разным метрикам. По новостям становится сильно лучше.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Improving The Discriminative Power Of Inferred Content Information Using Segmented Virtual Profile&lt;/em&gt;. Чувакки из linkedin рассказывают, как они улучшили  свои рекомендации работ. Выделяют из профилей фичи, по которым аппликанты сильно отличаются от остальных, это помогает дополнить профиль вакансии и лучше рекомендовать. Стало сильно лучше и хорошо масштабируется. Больше я ничего не понял=(&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ratings Meet Reviews, a Combined Approach to Recommend&lt;/em&gt;. Какой-то невнятный китаец рассказывал, как соединить lda и mf в одну вероятностную generative model. Модель вроде интересная, но они меряют rmse и упирают на explanation, который весьма сомнителен. Аматриан заметил, что ровно то же самое опубликовали на последнем KDD. &lt;/p&gt;
&lt;h1&gt;Среда (8 октября)&lt;/h1&gt;
&lt;p&gt;Очень интересный день — самые интересные доклады, самые интересные встречи, постеры. Попытаюсь описать как можно больше из того, что я запомнил.&lt;/p&gt;
&lt;h2&gt;Metrics and Evaluation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; Первая статья — &lt;em&gt;Beyond Clicks: Dwell Time for Personalization&lt;/em&gt; — best paper award.
Идея простая, есть yahoo stream, лайков мало, а клики шумные. Давайте же использовать dwell-time!
Собственно, они собирают события (зашли на статью, в фокусе, потеряли фокус, ушли) и строят сессии.
Дальше они делают большой анализ dwell time в разных категориях и контекстах, в итоге пришли к z-score нормализации внутри контекста.
Рекомендации строят через GBDT, время хорошо использовать для взвешивания событий (тут лучше почитать статью), но можно и для собственно формирования событий.&lt;br /&gt;
Супер-пупер результаты, все хорошо работает, всем dwell-time.&lt;/p&gt;
&lt;p&gt;Дальше Даниэль Клувер делал доклад &lt;em&gt;Evaluating Recommender Behavior For New Users&lt;/em&gt;. Идея простая: они взяли movielens и у некоторых пользователей из test set-а оставили в train-е маленькое количество рейтингов (симулировали cold-start). А дальше они изучили как разные методы ведут себя в разных ситуациях. Вывод доклада — если меньше 4-х рейтингов, то baseline model лучше svd почти по всем метрикам.&lt;/p&gt;
&lt;p&gt;Следом выступил Алан Саид &lt;em&gt;Comparative Recommender System Evaluation: Benchmarking Recommendation Frameworks&lt;/em&gt;. Они рассказывали про rival — фреймворк для оценки и проведения исследований. Получилось очень интересно, они построили хороший протокол, где единственным черным ящиком остается алгоритм. Можно использовать модульно, поэтому и тестить что угодно. Его, кстати, использовали в recsys challenge в этом году.&lt;br /&gt;
Смотреть можно и нужно на &lt;a href="http://rival.recommenders.net"&gt;http://rival.recommenders.net&lt;/a&gt;, код у них открытый.&lt;/p&gt;
&lt;p&gt;Дальше был рассказ про &lt;em&gt;Social Influence Bias in Recommender Systems: A Methodology for Learning, Analyzing, and Mitigating Bias in Ratings&lt;/em&gt;. Суть в том, что решения пользователей подвержены влиянию большинства (например, если все в комнате говорят, что черный кубик белый человек склонен тоже сказать, что он белый, хотя и зная, что это не так). Вопрос в том, можно ли измерить social bias и можно ли его устранить из существующего датасета? Используют California Report Card, люди сначала ставят рейтинг, потом им показывают медиану и они могут поменять решение. Так вот оказывается, что изменившие решение и не изменившие его отличаются (по Вилкоксону). Дальше они строят метод предсказания того, что пользователь поменял рейтинг и очищают данные.&lt;br /&gt;
Но к случаю, когда рейтинг встроен в дизайн, это плохо применимо.&lt;/p&gt;
&lt;h2&gt;Novelty and Serendipity&lt;/h2&gt;
&lt;p&gt;Первая статья весьма оригинальна: &lt;em&gt;Improving-Sales-Diversity-by-Recommending-Users-to-Items&lt;/em&gt;. Идея в том, чтобы развернуть проблему и рекомендовать пользователей к item-ам. Чуваки переписывают kNN в такой формулировке и получают более качественный neighbour selection, в итоге выигрывают по качеству.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;On Over-Specialization and Concentration Biases of Recommendations: Probabilistic Neighborhood Selection in Collaborative Filtering Systems&lt;/em&gt;. Чуваки делают probabilistic neighbor selection, это простое взвешенное семплирование с возващение. Больше ничего не понял =(&lt;/p&gt;
&lt;p&gt;В следующей работе &lt;em&gt;User Perception of Differences in Recommender Algorithms&lt;/em&gt; чуваки на user study смотрят как пользователи оценивают выдачи разных алгоритмов. Они строят модель качества алгоритма, которая учитывает сочетания accuracy, diversity и novelty, от которых зависит satisfaction и first impression, которые в свою очередь ведут к выбору того или иного алгоритма как лучшего. Интересно, что:
  * satisfaction affects 1 imp and choice
  * satisfaction mediates diversity
  * novelty has complex largely negative effect
  * diversity and accuracy trade off
Короче, осторожно с novelty, а diversity в меру хорошо. Но это все махания руками, так как народ резонно заметил, что пользователи не пользовались этими рекомендациями и поэтому скорее всего выбрали более очевидные. Но они якобы делали это больше для новых пользователей и бла-бла-бла...&lt;/p&gt;
&lt;p&gt;Дальше рассказывал Флоран Гарсин (проф из EPFL): &lt;em&gt;Offline and Online Evaluation of News Recommender Systems at swissinfo.ch&lt;/em&gt;
они сделали систему рекомендаций новостей, см. предыдущую работу: &lt;a href="http://arxiv.org/pdf/1303.0665.pdf"&gt;http://arxiv.org/pdf/1303.0665.pdf&lt;/a&gt;&lt;br /&gt;
Собирают клики и обучают модель, в offline и online ситуация отличается диаметрально! Этот тот самый extremely good random recommender. Очень странная статья практически без выводов...&lt;/p&gt;
&lt;p&gt;В перерыве подошел к Клуверу, спрашивал не знает ли он про исследования в области таксономии в cold start. Он не знает =(
Потом обсуждали с Флораном почему его метод не работает, обсуждение плавно перетекло в ланч (всех выгнали из зала). И в результете (один я бы так не сделал), мы подсели за столик к каким-то чувакам. Которые при ближайшем рассмотрении оказались цветом Гугла. Так я пообедал с Джеффом Дином =)&lt;br /&gt;
Они мало что рассказывали и вообще были напряженные. Я пытался спрашивать, как они строят рекомендации — единой платформы таки нет. Часто они совпадают по API, но не всегда, им нравится, что рекомендации делают эксперты в конкретной предметной области. Идеального рекоомендера Джефф не видит, скорее это что-то в духе ансамбля (или нейросети, как можно подумать из его доклада?), куда легко можно вставить разные фичи про пользователя, item и т.д.&lt;/p&gt;
&lt;h2&gt;Keynote&lt;/h2&gt;
&lt;p&gt;Дальше был &lt;em&gt;keynote&lt;/em&gt; от Джеффа, про который мнения разошлись. Он говорил про нейросети (что очень внезапно) и очень impressive. Соответственно, половина людей была скептична (например, Аматриан), другая наоборот воодушевилась. 
В целом главная мысль — нам нужно научиться лучше понимать объекты (тексты, изображения, музыку, действия пользователя и т.д.) и очень хочется избавиться от ручного кодирования тысяч фичей. Выход — deep learning. Это реинкарнация нейронных сетей из 80-х, но at scale. Причем, с одной стороны все упростилось (например, просто max(0,x) вместо сигмоиды для активации), но зато появились способы обучать supervised, unsupervised и RL. Очень много работы сделано, чтобы уменьшить время обучения: это удается сделать с помощью двух вещей:
  * параллелизм модели — разные части модели можно обучать параллельно
  * параллелизм данных - можно поднять много копий моделей и parameter server, каждая модель будет считать дельты к параметрам и отправлять/получать обновления параметров&lt;br /&gt;
В результате — asynchronous distributed SGD. &lt;br /&gt;
См. &lt;a href="http://static.googleusercontent.com/media/research.google.com/ru/us/archive/unsupervised_icml2012.pdf"&gt;http://static.googleusercontent.com/media/research.google.com/ru/us/archive/unsupervised_icml2012.pdf&lt;/a&gt; и &lt;a href="http://static.googleusercontent.com/media/research.google.com/ru/us/archive/large_deep_networks_nips2012.pdf."&gt;http://static.googleusercontent.com/media/research.google.com/ru/us/archive/large_deep_networks_nips2012.pdf.&lt;/a&gt;&lt;br /&gt;
Дальше он приводил множество примеров того, что нейронки всемогущие. Ну вы понимаете о чем я.&lt;br /&gt;
Затем внезапно рассказал word2vec-модели (включая перевод текстов и paragraph-model). и о том, что это можно применять для эмбеддинга целых фраз: &lt;a href="http://arxiv.org/pdf/1409.3215.pdf"&gt;http://arxiv.org/pdf/1409.3215.pdf&lt;/a&gt;&lt;br /&gt;
Дальше с такими представлениями можно работать как с обычными плотными данными, например, кормить большой нейронке, вроде тех, что используются в image recognition или acoustic recognition &lt;a href="http://static.googleusercontent.com/media/research.google.com/ru/us/pubs/archive/38131.pdf."&gt;http://static.googleusercontent.com/media/research.google.com/ru/us/pubs/archive/38131.pdf.&lt;/a&gt; Или просто использовать получившееся латентное пространство.&lt;br /&gt;
Архитектуру сетей очень хочется получать автоматически, но пока они не научились.  &lt;/p&gt;
&lt;h2&gt;Mainstream&lt;/h2&gt;
&lt;p&gt;Дальше тетушка из Linkedin рассказывала про &lt;em&gt;A/B Testing: Innovation @ Internet Scale&lt;/em&gt;. В целом говорила достаточно очевидные вещи: тестировать надо. Но не просто надо, а тестировать надо все (буквально каждый рефакторинг). Они построили систему, которая одновременно гоняет 200+ экспериментов и считает 800+ метрик (кроме всего прочего, замеряет значимость). Плюс, разные метрики по разному связаны с p-value (тут мало кто понял о чем она), поэтому они умеют для разных метрик задавать разные пороги значимости. Плюс, они умеют выделять конкретную экспериментальную группу (тоолько те, у кого было 1 или 2 работы). Плюс, они разделяют владельца эксперимента и владельца метрики и можно удобно смотреть, какие эксперименты зааффектит изменение метрики.&lt;/p&gt;
&lt;p&gt;Дальше ребята из facebook делали два доклада:&lt;/p&gt;
&lt;p&gt;первый — &lt;em&gt;Page recommendations at Facebook&lt;/em&gt;. Идея в том, что они максимизируют не лайки, а user engagement. Система сначала выделяет структурированный запрос, потом выбирает кандидатов, потом ранжирует их по p(engagement). Разные события весят по-разному (лайки, клики), но взвешивание подбирается чуть ли не руками. Для выбора кандидатов используют:
1. location based CF
2. social user2user
3. CF (SVD on user-page matrix)
4. session-based CF: predict p(next page eng|current page eng.)
5. topic based ContentFiltering + RBM для сжатия
6. DNN to match page topic topic models to peoples interest models&lt;/p&gt;
&lt;p&gt;второй — &lt;em&gt;News feed ranking&lt;/em&gt;. У большинства пользователей очень большая лента, которую просто нереально читать. Поэтому они ее ранжируют. Глобальные метрики:daily active people, overall time spent. Но они очень не чувствительные, к тому же не на уровне постов. Метрики фида — на кликах, лайках, поделяшках, комментах и т.д. Пытаются предсказать (с разным весом в зависимости от типа события), понравится ли пользовалелю пост (в смысле лайк ли). We predict p(like) with many features… which are statistics on everything grouped in different ways. Счетчики, счетчики и еще раз счетчики. По пользовательским событиям, по постам и т.д. Дальше они извлекают фичи из счетчиков (как?) и обучают простую логистическую регрессию.&lt;br /&gt;
Еще интересно, что фид не фиксирован — каждый update фида они переранжируют все, причем то, что пользователь видел, сильно понижается. Таким образом они значительно увеличивают долю прочитанного.&lt;/p&gt;
&lt;p&gt;Дальше был докад &lt;em&gt;Making Advertising Personal: Large Scale Product Recommendation at Criteo&lt;/em&gt; чувака из Criteo про то, какие они крутые. Но мне так не кажется — мало что рассказал, только общие идеи, про то, что они тестируют ранжирование вместо регрессии и очень хорошо масштабируются. И все.  &lt;/p&gt;
&lt;p&gt;После снова был перерыв, мне попались ребята из Spotify (собственно, тот самый Эрик Бернардсон). Я много спрашивал про алгоритмы:
1. vector_exp — очень простая штука, которая внезапно хороша
2. они только экспериментируют с ее online-версией
3. да, они используют word2vec в ансамбле (но не очень распространяются как обучать их)
4. они пробовали писать статьи, но их отреджектили и пропала мотивация
5. еще много чего, в основном они спрашивали про то, насколько мы большие, так же ли у нас все устроено как у них и т.д.&lt;/p&gt;
&lt;h2&gt;Recommendation methods and theory&lt;/h2&gt;
&lt;p&gt;Первый доклад: &lt;em&gt;Recommending User Generated Item Lists&lt;/em&gt; про то, как рекомендовать не только item-ы, а целые списки item-ов (мне задача очень напомнила next basket recommendation). Чуваки обучают ранжирование списков с помощью семплирования в два шага: на первом семплят пары item-ов, на втором — пары списков (что бы это ни значило). Сравнивают с кучей методов, в т.ч. BPR и LME, они лучше, конечно. Но там очень маленький датасет — 34k списков и всего 3k item-ов, плюс они еще фильтруют это. Так что скорее всего история как с LME, который не работает на данных реальных размеров.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; Второй доклад: &lt;em&gt;Question Recommendation for Collaborative Question Answering Systems with RankSLDA&lt;/em&gt;. Ребята решают задачу collaborative question answering, рекомендуют вопросы на crossvalidated (из stackexchange) тем, кто может ответить (как я понял). Они придумали расширение sLDA (supervised), которое умеет ранжировать — rankSLDA. Основные отличия — multiple outcome per document и learning to rank. Очень интересная работа, рекомендую прочитать статью.&lt;/p&gt;
&lt;p&gt;Дальше какой-то китаец рассказывал про &lt;em&gt;Bayesian Binomial Mixture Model for Collaborative Prediction with Non-Random Missing Data&lt;/em&gt;. Ничего не понял кроме классификации пропущенных данных (уже давно показали, что рейтинги — это missing not at random).&lt;/p&gt;
&lt;h2&gt;Poster session&lt;/h2&gt;
&lt;p&gt;Через некоторое время был poster session.
Посмотрел несколько работ, организовано было плохо (как и вся конференция целиком), поэтому не со всеми удалось поговорить.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Recommending Learning materials to students…&lt;/em&gt;
Работа Кости Баумана, все очень просто — есть студенты, им предлагают quizz-ы посередине курса и по результатам формируют картину пробелов в знаниях. Рекомендации — это просто материалы к этим пробелам. На мой взгляд там есть проблемы с evaluation, Костя вроде согласился с этим. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Recommending Thumblr blogs to follow with inductive matrix completion&lt;/em&gt;
Работа из yahoo, суть в том, что вместо стандартного матричного разложения они используют разложение на четыре матрицы: U x W x H x V, где U и V — фичи пользователей и блогов соответственно, они просто считают их без обучения. А вот W и H матрицы уже обучают.
Интересно, хотя и неизвестно, насколько это сравнимо с чистым implicit и с инициализацией через SimFactor.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Empathize, don’t filter&lt;/em&gt;
Работа про UI, чуваки просто по разному показывают разные по важности твиты и на user study оказывается, что это типа лучше.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hybrid explanations framework for CF RS&lt;/em&gt;
Работа Кенингстайна про объяснение рекомендаций. Суть в том, чтобы построить три матрицы весов item-а в событиях пользователя, матрицу item-tag корелляций (?) и матрицу весов тэгов (мне так и не удалось понять, что это за веса). Потом простым произведением они выводят user-item-tag и дальше делают на этом explanation. Ноам говорит, что это просто эвристики, они сейчас ничего не обучают.
Кстати, спрашивал его про таксономию, он говорит, что у них есть та-самая-статья, но изданная в журнале, они там в частности показывают на примере жанров, что их таксономические вектора интерпретируемы и отлично сравнимы между собой. Cold start они не смотрели.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Switching Hybrid for cold-start CARS&lt;/em&gt;
Чувак почти ничего толком не объяснил. Суть в том, что есть разные контексты и разные модели. Контексты сочетаются, но мы знаем не про все сочетания. И они вроде придумали, что нужно показывать общее предсказание в таких случаях… он не смог нормально объяснить.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Free-lunch Enhancement for Collaborative Filtering with factorization machines&lt;/em&gt;
Интересная работа про libFM. Идея проста — давайте посмотрим на паттерны оценок пользователей (n1 единиц, n2 двоек, n3 трокек и т.д.), дальше построим по этим паттернам кластера. Номер кластера запихиваем в AUX information в libFM и вуаля.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;WrapRec...&lt;/em&gt;
Фреймворк на C# про то, как можно просто и удобно скрывать внешние рекоммендеры от клиентского кода. На стенде никого не было =(&lt;/p&gt;
&lt;p&gt;&lt;em&gt;An extended data model format for composite recommendation&lt;/em&gt;
Очередной протокол от Саида, на этот раз про то, как передавать данные. Сущности — tsv, атрибуты в json-колонке. Ничего примечательного.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Long term recommendation benchmarking … using Markov chains&lt;/em&gt;
Чувак делает приложение- список покупок. И выдвигает идею, что можно обучать вероятность элемента прожить (не быть удаленным, но может быть быть купленным) в списке больше времени t. Ничего кроме идеи.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Task-based user modelling for personalization via PMF&lt;/em&gt;
Интересная работа, суть в том, чтобы научится выделять из пользовательских запросов задачи через кластеризацию (тут очень спорно, что они получатся интерпретируемы), дальше мы можем соотнести пользователя и его новые запросы с определенными тасками. Может быть, будет интересно кому-нибудь в поиске.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Using graded implicit feedback for BPR&lt;/em&gt;
Чувак предложил как обучать BPR не на {0,1} фидбеке, а в случае, если мы знаем степень предпочтения. Правда, он не умеет сильнее учитывать более сильную разницу предпочтений, учитывается только факт разницы.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Inferring user interests in twitter soc. network&lt;/em&gt;
Простое извлечение интересов по связям и ключевым словам в твиттере.&lt;/p&gt;
&lt;p&gt;Фотки постеров, которые мне удалось посмотреть, можно найти в папке posters в диске: &lt;a href="https://yadi.sk/d/ueMsOUE4buSUx"&gt;https://yadi.sk/d/ueMsOUE4buSUx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;После этого поговорил с Яннахом Дитмаром (автор одной из книжек), они много занимаются музыкой. Но ничего конкретного он не рассказал, скорее больше спрашивал кто мы, сколько у нас данных, какие методы используем и т.д.&lt;/p&gt;
&lt;h1&gt;Четверг (9 октября)&lt;/h1&gt;
&lt;p&gt;В четверг был последний день основной программы, тоже было много чего интересного.
Но обо все по порядку:&lt;/p&gt;
&lt;h2&gt;Ranking and Top-N Recommendations&lt;/h2&gt;
&lt;p&gt;Первый доклад — &lt;em&gt;Coverage, Redundancy and Size-Awareness in Genre Diversity for Recommender Systems&lt;/em&gt;. Чуваки из telefonica делают разнообразие киношных рекомендаций через жанры. Они рассматривают несколько существующих подходов к тому, как это делать и в результате предлагают свой. Суть в построениии метрики binomialDiversity(R), где R — список рекомендаций. Строят так:
  * binomialCoverage(R), — штафуем за невыбор жанра
  * nonRedundancy(R) — штафуем за вероятности найти это или большее количество фильмов жанра в рекомендациях
  * binDiv(R) = coverage(R) * NonRed(R)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Towards a Dynamic Top-N Recommendation Framework&lt;/em&gt;. Автора статьи не было, докладывал его коллега. Строят online+offline модель рекомендаций, но кроме того, еще инициализируют некоторые компоненты латентных векторов через topic modelling. Сравнение у них странное, они делают online, но сравниваются с offline-методами. Короче, неясно, насколько topic modelling помогает.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Explore-Exploit in Top-N Recommender Systems via Gaussian Processes&lt;/em&gt;. Обычно в RL очень маленькое количество действий, но тут #action &amp;gt;&amp;gt; #trials. Поэтому можно выиграть в скорости, плюс идея разделять данные между позициями списка, между пользователями и item-ами. Для разделения между позициями считают простую вероятность вознаграждения на этой позиции, а для разделения user2user и item2item используют Гауссовские процессы. Интересно, что чем длиннее список, тем быстрее сходится.&lt;br /&gt;
Их спрашивали про производительность (вроде Гауссовские процессы медленные) — они говорят, что параллелят вычисления, но у них пока нет online.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A Parameter-free Algorithm for an Optimized Tag Recommendation List Size&lt;/em&gt;. Чувак из Сенегала рассказывал про то, как он строит рекомендации тэгов. Он вводит релевантность тэга, а из нее формулирует релевантность списка (которая не монотонна). В результате рекомендует список, оптимальный по релевантности  (но может быть более короткий).&lt;/p&gt;
&lt;h2&gt;Industry session&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Virtual personal shopping assistant&lt;/em&gt; — чувак из Shopkick (крупнейшего приложения для ритейлеров) рассказывал о rocket future для традиционных магазинов (не online!). Основная идея — нужно привести человека в магазин, а дальше высокая конверсия (от  35% до 90% в разных областях) сделают свое (тут я бы поспорил с ним). Они очень активно используют геопозицию — знают (с помощью ультразвуковых датчиков), когда, где и в какой магазин вошел пользователь. Через iBeacon знают, где он внутри магазина (иногда с точностью до манекена, который он смотрит, чаще просто отдел). В результате их идея — формировать персональные скидки для человека. Например, "хей! ты вчера интересовался этой курткой, специально для тебя скидка 30%"&lt;br /&gt;
Еще персонализируют фид в приложении, персонализируют нотификации (как способ так и время). Стараются выдать нотификацию в тот момент, когда человек реально может зайти в магазин, а не посреди хайвея.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Recommendations and Decision Support in Agriculture&lt;/em&gt;. Чуваки занимаются рекомендациями и анализом данных в сельском хозяйстве. Пишут о том, что средний фермер за год принимает примерно 40 бизнес-решений, которые очень сильно влияют на дальнейшую судьбу бизнеса. Хотят это оптимизировать и помогать в принятии решений. Очень много данных (реально много), но проблема — они не собраны вместе и часто в разных форматах. Но они двигаются вперед.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Blending Human Computing and Recommender Systems for Personalized Style Recommendations&lt;/em&gt;. Доклад прямо противоположный вчерашнему keynote Джеффа. Компьютеры хороши в том, чтобы быстро что-нибудь посчитать, человек — в распознавании сложных образов и вообще в прекрасном. Они соединяют компьютеры и людей для того, чтобы рекомендовать одежду. Модель такая: человек заходит на сайт, заполняет много-много данных про себя (в том числе неструктурированных, плюс указывает примеры стиля, который ей нравится — они только для девушек). Дальше алгоритм отбирает "кандадатов", потом эксперт в области делает окончательный выбор. И товары отправляются пользователю. Сразу. То есть пользователь посмотрит их уже дома. Рекомендации — это 100% их бизнеса, плюс очень высокие ставки (хотя мне интересно, на что они потратили бы больше — на доставку false positive или на зарплату экспертам).&lt;br /&gt;
Идея интересная, хотя и очень спорная.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Prototyping Trust: Modeling the Virtuous Cycle&lt;/em&gt;. Тетушка из microsoft рассказывала про то, как они дизайнят новый интерфейс взамодействия рекомендаций и человека. Она привела резонный пример, что в человеческих отношениях существует social protocol — мы не сразу рассказываем первому встречному все про себя, но нам нужно какое-то время, чтобы обрести доверие друг друга. Собственно тут идея та же самая — они хотят научить машины уважать этот social protocol. Она говорит, что не нужно доставлять максимально точные рекомендации в первый день. По этому вопросу много споров, например, Аматриан с ней категорически не согласен. Но это их идея в том, чтобы сделать "вежливого" интеллектуального помощника.&lt;/p&gt;
&lt;h2&gt;Keynote&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Thoughts on the Future of Recommender Systems&lt;/em&gt; by Hector Garcia Molina, Standford University
Impressive профессор из Стэнфорда пытался научить всех делать рекомендательные системы. Несколько основных мыслей:
1. нужно объединить (хотя бы по базе знаний и технологиям) поиск, рекомендации и рекламу
2. нужно дать пользователю возможность настройки и влияния на алгоритм
3. нужно дать возможность людям помочь в рекомендации (очень созвучно с blending human computing...)
Дальше долго рассказывал какую они замечательную систему рекомендаций построили в Стэнфорде. Вобщем, совершенно не по делу.&lt;/p&gt;
&lt;h2&gt;Panel&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Controversial Questions About Personalization&lt;/em&gt;. В дискуссии принимали участие Pankaj Gupta (ex-Twitter), Tim Jones (CTO at Upworthy — ecommerce), Eric Bieschke (Chief Scientist and VP at Pandora), Joaquin A Delgado (Director of Engineering of Advertising and Personalization at OnCue – Verizon).&lt;br /&gt;
Много говорили про мораль, по то, какая ответственность лежит на системах рекомендаций, не будет ли так, что пользователь окажется в пузыре. "Все люди в пузыре. Но наше счастье, что он достаточно большой" — Эрик. Они в Pandora, кстати, оптимизируют diversity рекомендаций, это одна из их основных метрик. Еще говорили про то, хорошо ли аб-тестироваться на пользователях и о том, как сделать так, чтобы они поняли почему их рекомендации хуже.&lt;/p&gt;
&lt;h2&gt;Matrix factorization&lt;/h2&gt;
&lt;p&gt;Последняя сессия была довольно интересной.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;GASGD: Stochastic Gradient Descent for Distributed Asynchronous Matrix Completion via Graph Partitioning&lt;/em&gt;. Чуваки делают раcпределенный SGD за счет разбиения графа рейтингов (?). Основные улучшения — метод партиционирования, уменьшение количества разделяемых данных между нодами и введение синхро-параметра (отвечает за то, как часто ноды синхронизируются, конролирует tradeoff между качеством и скоростью). Реально на распределенной системе они еще не тестили, только в симуляторе.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A Framework for Matrix Factorization based on General Distributions&lt;/em&gt;. О том, как обобщить probabilistic matrix factorization на любые распределения. GD (или SGD), для вычисления производной делают численное дифференцирование.
&lt;a href="https://github.com/josefbauer/DMF"&gt;https://github.com/josefbauer/DMF&lt;/a&gt; (will be soon available?)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Speeding Up the Xbox Recommender System Using a Euclidean Transformation for Inner-Product Spaces&lt;/em&gt;. Отличная работа Кенингстайна про то, как ускорить выбор кандидатов. Суть в том, что они перевели пространство, где оптимизируется скалярное произведение в пространство, где нужно оптимизировать евклидово расстояние. Дальше применяют PCA-деревья (как kd, только раскладывают по главным компонентам всего множества). Для ускорения поиска они применяют эвристику — пронумеровав все листья они ищут соседей по листам с расстоянием Хэмминга 1 до данного.&lt;br /&gt;
Результаты очень классные.&lt;br /&gt;
P.S. прочитал их статью — там очень простые преобразования, правда. Это должно очень хорошо работать. Но эвристика с расстоянием Хэмминга — все же эвристика, то есть стоит понимать, что результат будет не точный.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно&lt;/strong&gt;: &lt;em&gt;Gradient Boosting Factorization Machines&lt;/em&gt;. Очень простая идея — метод Context Aware FM считает все попарные сочетания факторов. Но не все из них реально полезны! Собственно, чуваки придумали, каким образом ввести коэффициенты для фичей и жадно оптимизировать слой за слоем (у них только слой 2). Плюс еще превзошли сами себя и придумали, как оптимизировать все это используя shared latent vectors. Рекомендую статью к прочтению.&lt;br /&gt;
На эксперименте рвут всех (само собой).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Exploiting Temporal Influence in Online Recommendation&lt;/em&gt;. Парень исследует влияние совместных скробблингов исполнителей в last.fm. Вводит красивую вероятностную модель, сводит это к нескольким матричным разложениям и много махает руками. Тут основная проблема в том, как он измеряет, у него DCG@1. То есть фактически, это не ранжирование, а предсказание.&lt;/p&gt;
&lt;p&gt;В перерывах несколько раз разговаривал с Эриком. Он рассказал, что у них почти все в проде написано java, а исследования на scala. Они пользуются хадупом, пробовали spark, но он очень нестабилен, да и прирост в производительности маленький. Параметры (Миша, тебе лучше присесть) они подбирают на глазок! То есть выбирают то, что описано в статье и неплохо работает и все. Никаких оптимизаций у них нет! Очень внезапно.&lt;br /&gt;
Рассказывал, что они используют word2vec (своя реализация в проде и gensim для исследований), но в основном для похожестей. Я так понял, что у них даже в этом блоке работает ансамбль. Про контент-майнинг — они предсказывают латентные вектора item-ов, но это тоже только для похожестей и не в проде пока. vector_exp действительно у них хорошо работает, там очень простая идея, пока даже онлайна нет.&lt;br /&gt;
Примерно так.  &lt;/p&gt;
&lt;p&gt;Следующий RecSys будет в Вене 16-20 сентября 2015. Огласили программу RecSys Challenge — нужно будет по данным eCommerce системы научиться предсказывать а) была ли в сессии покупка б) и что купили. Данные и условия скоро выложат.&lt;/p&gt;
&lt;h1&gt;Пятница (10 октября)&lt;/h1&gt;
&lt;p&gt;Сегодня был последний день конференции — только воркшопы. Первоначально я планировал идти только на large scale recommender systems, но потом скипнул несколько докладов и послушал вместо них recsysTV. Так что если вдруг статья будет про тв — не удивляйтесь.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Recommendation Architecture: Going Beyond the Collaborative Filter&lt;/em&gt;.  Доклад чуваков из OpenTable — рекомендательная система ресторанов. У них 32k ресторанов,  $25B (в год?) тратят их клиенты в offline-ресторанах. Говорили достаточно много очевидных вещей. В целом идея — real goal: minimize engineering time to improve metric that matters. Такой подход легче измерить, итерации короче и проще. Дальше говорили, что стоит смотреть на то, как люди используют продукт, смотреть и на AB-тесты и «глазами аналитика». Дальше говорили про то, как стартовать рекомендательную систему, что хорошо начинать с простых эвристик и простых метрик типа RMSE. А уже потом переходить на learning2rank. Еще хорошо бы смотреть на variability of predictions, чтобы быть уверенным в своих рекомендациях и не порекомендовать что-то потенциально плохое.&lt;br /&gt;
Еще немного рассказывали о том, что они майнят темы из ревью через non-negative MF + TF-IDF (такой вариант топик-моделлинга). Кстати, у них темы визуализируются клевыми облаками тэгов.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Latent Feature Based FM Model For Rating Prediction&lt;/em&gt;. Задача: добавить контент в Factorization Machines. Один способ — сделать topic modelling и добавить тему как aux information. Второй — выделить вектора слов через word2vec и добавить как aux info в FMs. Результатов не дождался — сбежал на доклад Netflix.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Personalized Page Generation for Browsing Recommendations&lt;/em&gt;. Парень из Netflix рассказывал, как они строят персональную страницу пользователя.&lt;br /&gt;
Начало пересекалось с туториалом Аматриана, скип. Идея персонализации — смотреть как люди скроллят и взаимодействуют со страницей. Простой подход — просто строки на фиксированных местах (со своим ранкингом внутри). Выбирать можно rule-based, жадно и жадно с разнообразием. Второй подход — намайнить кучу фичей про блок (например, его размеры, CTR, quality, evidence, recency, how big, etc.), дальше строить page-level метрики: easy to discovery, diversity, novelty, recall@box (recall по области из нескольких блоков). Дальше добавляются блоки (разных размеров!).&lt;br /&gt;
Все это происходит в три этапа (offline, near RT, RT). То есть что-то они делают прямо налету, да. Но сильно не все.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Large-scale Recommendation in E-commerce&lt;/em&gt;. Чуваки из taobao.com (alibaba group) рассказывали, какие классные рекомендации они делают. Рекомендации разделены на retrieval и ranking + reranking. Плюс они в своем рекоммендере используют asynchronous distributed OnlineGD для обучения MF (?) на implicit-данных (например, dwell-time, click vs long click etc.). Поверх всего этого работает простая логистическая регрессия. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Personalized Content Recommendation in Practice: The StumbleUpon model&lt;/em&gt;. Тетушка рассказывала про StumbleUpon. Это фактически рекомендации страниц как у surfingbird: 180M indexed pages, +75k per day, примерно 500 интересов. 35 страниц пользователь смотрит в сессию, 3,5 часа на пользователя в месяц.&lt;br /&gt;
Основной упор на diversity (когда показать лучшую рекомендацию? сейчас или когда пользователь уже «почти» будет готов уйти?). Из интересного — они майнят экспертов, чтобы а) уменьшить шум данных б) увеличить точность и интересность материала.&lt;br /&gt;
Исползуют все модели – и CB и CF, но diversity is most important factor. Рекомендации генерятся налету. Еще по их опыту рейтинги не помогают почти никак — очень шумные (вы залайкаете котика, но он вам не интересен. А интересный мателиал про какую-нибудь проблему вы не будете лайкать — это слишком серьезная вещь). Ну и да, большинство лайков происходит еще до того, как пользователь прочитал материал. А вот негативные отзывы требуют больше времени, чтобы сформировать эмоции. Этот эффект можно использовать — они предсказывают, где пересекутся кривые ожидания времени лайка и дислайка для предсказания рейтинга. Да, ранжированием они начали заниматься, но там все трудно, так как выигрыш в MF не значит лучший продукт. Они много занимаются сегментацией рейтингов и пользователей и очень много майнят из контента. 
Full stack:
  * ingestion — feature analysis of content
  * sampling — how well this content will do?
  * rec pipelines — compute user-url metches, refresh data sources
  * rec engine — runtime (depends on device)
  * online computation — collecting events and online features and updating models
а еще реклама, дубликаты, классификаторы страниц, и т.д.&lt;br /&gt;
Короче, крутые чуваки. Я делал много фотографий ее слайдов. Если слайды не выложат, то обработаю эти фотки — интересный доклад.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Graphlab tutorial&lt;/em&gt;. Основатель(?) graphlab сел и за двадцать минут показал, как просто это использовать.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Building Large-Scale Recommender Systems for TV&lt;/em&gt;. Скучный доклад тетушки из Samsung о том, как они строят рекомендации. hadoop, yarn, spark, обзор, бла-бла-бла… Интересно следующее: они используют automatic content recognition, то есть телек сам понимает, какое шоу показывают. Они что-то сделали в направлении объединения контентного пространства и коллаборативного пространства. Но что конкретно?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Large Scale Purchase Prediction with Historical User Actions on B2C Online Retail Platform&lt;/em&gt;. Доклад победителей (?) Tmall price (китайское соревнование по ecommerce). Суть в том, что выдали 500M ratings, 10M users, 30k brands и нужно было предсказать по сессии купит ли пользователь данный бренд. Интересный момент — всем дали кластер!&lt;br /&gt;
Чуваки делают много-много-много фичей, некоторые как у нас, некоторые нам надо бы попробовать. Подробности в статье. Feature selection у них наивный, просто по significance в модели.&lt;br /&gt;
Рекомендательная система двухслойная: на первом слое куча сложных моделей (MF, Random forest, GBDT etc), на втором — логистическая регрессия (чтобы не переобучаться, как они говорят).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Distributed framework for ALS&lt;/em&gt;. Очень простая идея — если считать ALS распределенно, то нужно передавать по сети матрицу (P^T * P + lambdaI)^-1. Так вот если ноды объединить в блоки и передавать один раз на блок (а еще мультикастом), то будет хорошо. Но это лишь идея, проработки почти никакой.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно:&lt;/strong&gt; &lt;em&gt;Machine Listening at Pandora&lt;/em&gt;. Чуваки из Пандоры намекнули, почему в совсем недалеком будущем останутся только они. Общеизвестно, что у них есть разметка экспертами полутора млн треков. Так вот, inside: они активно майнят свои фичи из контента для неразмеченных треков используя эту гигантскую базу. Дальше он приводил пример того, как выделять сильные доли по контенту (это вроде стандартно и очевидно, Женя, можем поговорить, если надо). Они много чего научились майнить автоматически подобным образом, им очень просто настраивать алгоритмы. На датасетах MIREX-а показывают 0.999, в то время как текущие лучшие результаты в районе 0,6 — 0,9 в разных задачах. Это просто power of data.&lt;br /&gt;
Но предсказание жанра и фичей еще не все — важный момент — это построение плейлиста. У них используется metric learning. Но не только — они очень много чего делают и пробуют.&lt;br /&gt;
q1: deep learning? representation learning?&lt;br /&gt;
пробовали, но не скажут.&lt;br /&gt;
q2: popularity?&lt;br /&gt;
вроде не учитывают ее совсем&lt;br /&gt;
q3: discogs will improve?&lt;br /&gt;
в основном свои данные&lt;br /&gt;
q4: how compares with itunes?&lt;br /&gt;
никак, у них нет данных для объективного сравнения&lt;br /&gt;
q5: а тексты?&lt;br /&gt;
нет, это wide open problem. А вот эмоции майнят.&lt;br /&gt;
q6: do users use cultural vs musicological reason for declaring songs? cultural и musical не так далеки — на самом деле некий tradeoff.  &lt;/p&gt;
&lt;p&gt;С таким размеченным датасетом они могут почти все, что угодно…  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Интересно&lt;/strong&gt;: &lt;em&gt;Introducing the Metric Optimization Engine (MOE)&lt;/em&gt;. Optimal learning — most effective way to collect information. Ребята в Yelp сделали фреймворк, который позволяет это делать. Оптимально обучаться, оптимально тюнить параметры, оптимально тестировать. Все это на explore-exploit.&lt;br /&gt;
Как это работает:
  * builds Gaussian Process from sampled points
  * optimize covariance hyperparams of Gp
  * choose point with hight expected improvement
  * return next optimal point
Быстро сходится, отлично параллелится (можно делать мультисемплинг), можно исопльзовать GPU, можно как угодно задавать objective function… И все это уже работает в их production. И open source.&lt;br /&gt;
Короче, надо брать: &lt;a href="https://github.com/Yelp/MOE"&gt;https://github.com/Yelp/MOE&lt;/a&gt;&lt;/p&gt;</summary></entry></feed>