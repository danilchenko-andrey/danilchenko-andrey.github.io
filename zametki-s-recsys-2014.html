<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8">
  <!-- Site Meta Data -->
  <title>Заметки с RecSys 2014</title>
  <meta name="description" content="">
  <meta name="author" content="Andrey Danilchenko">

  <!-- Style Meta Data -->
  <link rel="stylesheet" href="/theme/css/notebook.css" type="text/css" />
  <link rel="icon" type="image/png" href="/images/favicon.32.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/favicon.57.png"> <!-- iPhone -->
  <link rel="apple-touch-icon" type="image/png" sizes="72x72" href="/images/favicon.72.png"> <!-- iPad -->
  <link rel="apple-touch-icon" type="image/png" sizes="114x114" href="/images/favicon.114.png"> <!-- iPhone4 -->

  <!-- Feed Meta Data -->
  <link href="/" type="application/atom+xml" rel="alternate" title="4ducks ATOM Feed" />

  <!-- Twitter Feed -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="mir_nomer_nol">
  <meta name="twitter:image" content="/images/avatar.png">

<meta name="twitter:creator" content="mir_nomer_nol">
<meta name="twitter:url" content="/zametki-s-recsys-2014.html">
<meta name="twitter:title" content="4ducks ~ Заметки с RecSys 2014">
<meta name="twitter:description" content="<p>Заметки с только что прошедней конференции RecSys 2014.</p>">

<!-- Facebook Meta Data -->
<meta property="og:title" content="4ducks ~ Заметки с RecSys 2014" />
<meta property="og:description" content="<p>Заметки с только что прошедней конференции RecSys 2014.</p>" />
<meta property="og:image" content="images/avatar.png" />
</head>

<body>
  <!-- Sidebar -->
  <aside>
    <p><a href="/"><img id="avatar" src="/images/avatar.png"></a></p>
    <h1>4ducks</h1>
    <h2>Andrey Danilchenko dev page</h2>
    <p></p>
    <hr>
    <h2>Social</h2>
    <ul class="social">
      <li style="list-style-image : url(/theme/images/icons/github.png);"><a href="https://github.com/danilchenko-andrey">github</a></li>
      <li style="list-style-image : url(/theme/images/icons/linkedin.png);"><a href="https://ru.linkedin.com/in/danilchenko/">linkedin</a></li>
      <li style="list-style-image : url(/theme/images/icons/twitter.png);"><a href="https://twitter.com/mir_nomer_nol">twitter</a></li>
      <li style="list-style-image : url(/theme/images/icons/gplus.png);"><a href="https://plus.google.com/+АндрейДанильченко">Gplus</a></li>
      <li style="list-style-image : url(/theme/images/icons/instagram.png);"><a href="http://instagram.com/mir_nomer_nol">instagram</a></li>
      <li style="list-style-image : url(/theme/images/icons/vk.png);"><a href="http://vk.com/andrey.danilchenko">vk</a></li>
      <!--li style="list-style-image : url(/theme/images/icons/rss.png);"><a href="/" rel="alternate"><i class="icon-bookmark icon-large"></i>Atom feed</a></li-->
    </ul>
    <h2>Pages</h2>
    <ul class="navbar">
      <li><a href="/pages/itmo-rs-2014.html">ITMO RS 2014</a></li>
    </ul>
    <h2>Categories</h2>
    <ul class="navbar">
      <li><a href="/category/itmo.html">itmo</a></li>
      <li class="active"><a href="/category/recsys.html">recsys</a></li>
    </ul> 
    <div class="modification">Last updated: 2014-10-20 12:13</div>
  </aside>

  <!-- Content -->
  <article>
<section id="content">
    <article>
        <header class="post_list">
            <h2 class="post_title"><a href="/zametki-s-recsys-2014.html" rel="bookmark" title="Permalink to Заметки с RecSys 2014">Заметки с RecSys 2014</a></h2>
        </header>
        <div class="entry-content">
            <p>На прошлой неделе в Foster City, CA прошла конференция RecSys'14.</p>
<p>Содержимое флешки с оглавлением: <a href="https://yadi.sk/d/-DVv6cBwbqyM8">https://yadi.sk/d/-DVv6cBwbqyM8</a><br />
Видео всех докладов и постеров: <a href="https://www.youtube.com/playlist?list=PLaZufLfJumb9A95nS5AmY6G5mqYnwIfZX">https://www.youtube.com/playlist?list=PLaZufLfJumb9A95nS5AmY6G5mqYnwIfZX</a></p>
<h1>Понедельник (6 октября)</h1>
<p>День туториалов, поэтому нового мало.</p>
<h2>T1</h2>
<p>Вначале рассказывал Аматриан, это была часть его «стандартного» туториала с MLSS, только в два раза короче. Он пробежался по основным методам (memory-based, svd, rbm, arules, clustering, classification, content-based), а во второй части акцентировал внимание на том, чему они научились во время (и после) Netflix Prize. Это «эволюция рекомендательных систем»: rating -&gt; ranking -&gt; page optimization -&gt; context-aware recommender. С первым и вторым более менее понятно (хотя тут он снова много рассказывал про методы, pairwise и pointwise, про то, что хорошо оптимизировать loss-function для ранжирования, но можно, например, делать это не напрямую, а косвенно. Хотя, конечно, работает хуже). Еще отдельно были упомянуты похожести как рекомендации. Их можно строить через графовые методы, например, sim-rank, через «похожести» в метаданных, в поведении пользователей и в рейтингах (это как раз CF-подходы). Все это очень хорошо работает в ансамбле. Но если трудно обучать ансамбль, то можно использовать бандитов.</p>
<p>Еще говорил про deep learning, но сразу оговорюсь — тут все только зарождается (в основном благодаря тому, что научились эффективно учить сети, см. <a href="http://techblog.netflix.com/2014/02/distributed-neural-networks-with-gpus.html">http://techblog.netflix.com/2014/02/distributed-neural-networks-with-gpus.html</a>). Упоминались методы из Spotify (RNN и обучение латентных векторов). Из spotify, кстати, всего один человек, Бернхардсона не было.
Немного упомянул про social RS (но дальше был отдельный туториал по ним). Кстати, мелькнула идея регуляризации близких пользователей.</p>
<p>Про page optimization (самое интересное) Аматриан говорил мало, не хватало времени. В кратце: основная идея состоит в том, что у нас 10000 item-ов, которые можно показать и дофига блоков. Но показывать это все надо не просто так, а оптимизируя страницу целиком для конкретного пользователя (и конкретного девайса тоже). Работ тут пока мало, упоминалась вот эта: <a href="http://www.cs.cmu.edu/~amahmed/papers/SVCM_WSDM12.pdf">http://www.cs.cmu.edu/~amahmed/papers/SVCM_WSDM12.pdf</a></p>
<p>Еще говорил про context-aware RS: тензорные разложения и factorization machines.</p>
<p>Интересная часть — о многоруких бандитах. Их активно используют для exploration/exploitation. Можно так подбирать параметры в online, можно выбирать алгоритмы (тогда это работает как гибридная RS). </p>
<p>Про implicit feedback был вопрос о том, как бороться с bias-ом от того, что пользователь смотрит то, что мы ему показываем. Тут решение либо сэмплить, либо исопользовать бандитов.</p>
<h2>T2</h2>
<p>Какие-то невнятные китайцы с отвратительным английским пытались рассказывать про location based recommender на основе соцсетей. Но никто ничего не понял, большая часть людей свалила. Мне так сделать не удалось, но туториал был бесполезный.</p>
<h2>T3</h2>
<p>Паоло Кремонези рассказывал про Cross-Domain Recommender Systems. Это был неплохой обзор того, кто чего делает в области.
Очень много всякой разной классификации по типу чего-нибудь. В целом выводы примерно такие: 1) есть разные цели: cold-start, cross-selling, improving quality и разные свойства доменов (например, разное пересечение пользователей, item-ов, аттрибутов). Исходя из этого применяются разные методы от самых тупых (аггрегация профилей, моделей, рейтингов) до сложных (тензорные факторизации, три-матричная кофакторизация, codebook transfer). Про последний забавно — они только что показали, что cross-domain тут непричем — это просто хороший matrix factorization метод. Методы оценки также зависят от того, в каком домене и кому мы хотим рекомендовать.</p>
<h2>T4</h2>
<p>Social Recommender Systems. Рассказывали чуваки из Yahoo и IBM (Ido Guy). Идея в том, что web2.0 — интернет людей. Отсюда появились соцсетки и социальные медиа. Очень много новой информации вроде тэгов, голосовалок (like) и комментариев. </p>
<p>Про рекомендации контента: есть два типа связей — знакомство (люди связаны в сети) и похожесть (люди состоят в одних группах и комментируют одни материалы). Первые дают более точные, но более скучные рекомендации (еще они помогают в explanation), вторые сильно увеличивают diversity и serendipity (имхо, это уже CF). Упоминал статью про google reader: <a href="http://dl.acm.org/citation.cfm?id=1719976&amp;dl=ACM&amp;coll=DL&amp;CFID=438180616&amp;CFTOKEN=35684830">http://dl.acm.org/citation.cfm?id=1719976&amp;dl=ACM&amp;coll=DL&amp;CFID=438180616&amp;CFTOKEN=35684830</a></p>
<p>Еще интересный факт: «входящие» данные (то, что про пользователя думает окружение) работает лучше, чем исходящие данные (лайки, тэги) самого пользователя.</p>
<p>Рекомендации тэгов еще одна тема. Используются CF-методы, гибридные (Rendle’2010, видимо вот это имелось в виду: <a href="http://www.informatik.uni-konstanz.de/rendle/software/tag-recommender/">http://www.informatik.uni-konstanz.de/rendle/software/tag-recommender/</a>). Хорошо работают графовые методы: <a href="http://www.kde.cs.uni-kassel.de/stumme/papers/2006/hotho2006folkrank.pdf">http://www.kde.cs.uni-kassel.de/stumme/papers/2006/hotho2006folkrank.pdf</a></p>
<p>Про рекомендации сообществ говорил про комбинацию arules и lda на контенте (странно что не упомянул одноклассников).</p>
<p>Рекомендация людей (друзей, кого фолловить): есть методы на контенте, FoF и SONAR. В опросах побеждают последние, но по факту они быстро исчерпывают себя — человек и так знаком с рекомендуемыми людьми. Тут было довольно спорно все. Кстати, для предсказания кого фолловить внезапно follower-ы человека более информативны, чем те, кого он сам фолловит.</p>
<p>Много говорили про создание контента. Так как активно генерят контент всего 1% пользователей, то нужно их мотивировать. В частности, рекомендация тэгов — это мотивация. Приводилось две теории генерации контента: самоопределение и теория Foggs behaviour model (для действия нужны мотивация (нужно хотеть), доступность (это не должно быть слишком сложно) и trigger — событие, которое станет «последней каплей», например, это может быть письмо от соцсети).</p>
<p>Говорили про интересное исследование: пользователи, которым в самом начале порекомендовали «активных» в друзья, с гораздо большей вероятностью сами становятся активными. Еще была долгая история про то, как рекомендовали темы блогов. С одной стороны, не было значимого увеличения в количестве постов. Но зато посты по рекомендациям собирали гораздо больше посещений и лайков.
Тут отдельный момент — как такие рекомендации меняют структуру сети. Например, FoF создает хабы. А Content matching создает связи к странным людям всего с несколькими друзьями…</p>
<p>Кратко о trust and reputation: есть семейство графовых методов, которые с помощью «trust» и его распространения в сети могут повысить качество коллаборативки. Пример: повышаем рекомендации от доверенных пользователей, понижаем от недоверенных.
Reputation — это общее доверие, которым пользователь обладает в сети. Аналог page rank.</p>
<p>Немного говорили про рекомендации группе людей, тут работ мало, в основном работает аггрегация профилей. Еще упоминали интересную работу <a href="http://www.research.ibm.com/haifa/dept/imt/papers/sigir191-ronen.pdf">http://www.research.ibm.com/haifa/dept/imt/papers/sigir191-ronen.pdf</a> (свою) про рекомендации контента для владельцев групп.
Снова интересно, как это меняет сеть.</p>
<h1>Вторник (7 октября)</h1>
<p>Вторник — первый день основной конференции, программа тоже более интересная.</p>
<h2>Keynote</h2>
<p>Вначале был <em>keynote</em> от Нейл Ханта (технический директор Netflix). Он внезапно начал с того, что доверие пользователей с нами не навсегда и (опираясь на кучу историй с гуглом) призвал всех быть предельно аккуратными, чтобы не потерять свою аудиторию.
Дальше он рассказал краткую историю рекомендаций в компании — в основном раньше брали в прокат только новые релизы, а потом они оставались у них на складе навсегда. После внедрения рекомендаций стало сильно лучше, сейчас новые релизы — это примерно 10%
Были интересные параллели с Linear TV и on-demand TV, Netflix видимо мощно двигается в эту сторону (например, через приложения для телеков) и они говорят об изменении классического формата (бродкаст, 21 час в неделю prime-time и больше ничего). Они не продают рекламу, не продают данные пользователей, но могут делать только качественные рекомендации (примерно 150M «решений»(событий?) в день, 50M пользователей). 1% увеличения к количеству просмотров — это более $500M.
Им очень хочется измерять retention, но это невозможно. Хороший прокси — часы просмотра (так же и у нас в радио). Но не все изменения полезны — даже увеличивая эту метрику они могут потерять пользователей с низким числом просмотров, поэтому смотрят на всю кривую.
Еще интересная мысль — они могут технически (и видимо уже собираются это делать) говорить продюссерам, как будет принят фильм. И могут предсказывать хорошие ниши даже для очень маленьких аудиторий. Вообще «there are no bad shows, just shows with small audience».
И да, еще интересный момент. Они пробовали просить пользователей самим поранжировать вручную. Но их алгоритм по метрике лучше =)</p>
<p>Во время перерыва говорил с чуваками из Pandora (с Оскаром Сельма тоже, кстати, он там теперь большой начальник). Они рассказали, что используют только разметку, но разметка фичей не бинарная, а обычно в пятибальной шкале. Дальше из этого уже майнят эфир. Новые фичи не добавляются, но зато можно добавить новый домен (например, комедии) со своим набором фич.</p>
<p>У Гугла спрашивал, используют ли они единую систему рекомендаций. Сказали, что нет, обычно продукт пишет что-то свое. Вообще они очен мало рассказывали по делу, девочка даже ноут от меня прикрыла (хотя я не мог видеть что там, да и не пытался даже) =)</p>
<p>Поговорил с Рикардо Диасом, который делал доклад <a href="http://ceur-ws.org/Vol-1245/cbrecsys2014-paper05.pdf">http://ceur-ws.org/Vol-1245/cbrecsys2014-paper05.pdf</a> на вчерашнем воркшопе. Он пересказал мне вкратце свой метод — они просто берут фичи у эхонеста и пытаются играть треки, которые хорошо подходят к активности конкретного пользователя. Но масштабы там маленькие.</p>
<h2>Novel applications</h2>
<p>Заговорившись в холле пропустил первый доклад, как и многие другие =(
Доклад <em>Automating Readers’ Advisory to Make Book Recommendations for K-12 Readers</em> — это рекомендации детских книжек. Они строят рекомендации на темах и анализе контента, выделяя факторы (например, storyline: fun). Выделение с помощью правил-шаблонов из ревью.
По их замерам лучше Novelist, но хуже амазона (что странно при том, что они очень нишевые).</p>
<p>Еще был доклад про <em>Robust Model for Paper-Reviewer Assignment</em>, в целом про то, как выделять экспертов. У них графовая модель, случайные блуждания с рестартом. В вершинах все объекты (авторы, статьи, темы), на ребрах отношения (автор-автор, статья-автор, статья-тема). Темы выделяют через LDA. Разнообразия ревьюеров они добиваются используя кластеризацию и l1 нормой убивая лишних.
Судя по их графикам выигрывает RWR, но они не сравнивали с существующими системами — типа другие данные</p>
<p>Следующий доклад: <em>Exploiting Sentiment Homophily for Link Prediction</em> — используя окраску твитов опрелеляют друзей. Строят граф связей различным образом (самый жгущий — это @mentions &gt; N). По тэгам твитов определяют темы и смотрят как разные пользователи к ним относятся. Дальше строят скор кандидатам. Вроде неплохо получается по F1.</p>
<h2>Novel setups</h2>
<p><em>Factored MDPs for Detecting Topics of User Sessions</em>. Обычно нужно по предыдущему item-у определить следующий, но почему бы не делать это по сессии? Собственно, чуваки так и делают: строится MDP — состояния — аттрибуты (всего четыре), действия — выбор следующего, вознаграждение — клики, и матрица переходов.
В предположении независимости атрибутов получают существенное ускорение. 
Дальше имея Q-функцию они определяют тему сессии как распределение вероятностей атрибутов (плюс обрезание по общему порогу). Для длинных сессий хорошо работает точный MDP, для коротких — приближенный.
Дальше применяют свою модель тем для построения рекомендаций и оказываются лучше матричного разложения по AvgPos.</p>
<p><em>Context Adaptation in Interactive Recommender Systems</em>. Многорукие бандиты с определением смены контекста. Собственно, exploitation — если контекст одинаковый (item выбирается с вероятностью быть лучшим), exploration — если смена. Смену контекста определяют так: берут два окна (рядом, но не пересекая) и считают модели. Дальше смотрят на разницу. 
Сравнивались с user-based kNN на Y!Music, смену контекста симулировали рандомной сменой пользователя в тест сете. </p>
<p><em>Question Recommendation with Constraints for Massive Open Online Courses</em>. Рекомендуют темы форума на курсере, стараются увеличить overall community benefit. Сначала строят скор релевантности (через этакий супер-SVD со статистиками внутри как в %%SVD++%%), потом max concave cost flow, используют три фактора для фильтрации тем и юзеров: capability (expertise), capacity (number of question to work on), Hardness (how difficult question).
Данные, 3 курса с coursera, в питоне (самый большой) 3 тыс пользователей и 3 тыс itemов. Меряют MAP@1 @3 @5, сравнились с простым MF по ним.</p>
<p><strong>Интересно:</strong> <em>Attacking Item-Based Recommender Systems with Power Items</em>. Чувак очень здорово напугал всех тем, как легко и эффективно можно проводить атаки на user-based, item-based и SVD RS. Типы атак: push (поднимаем item), nuke (опускаем item) и disrupt (выводим систему из строя).
Как это делается: назначается target item, остальные рейтинги симулируются (разными способами) так, чтобы было похоже на обычного userа. Они находят «power users» и power items такие, которые больше всего влияют на систему. Дальше они могут быть похожи на такого user-а или оценивать такие item-ы. В случае item-based систем хорошо работает multitarget attack, у одного пользователя несколько target-итемов.
Атаки весьма эффективны по hit rate и по rating shift. Говорит, что есть хорошие защиты (работы 2002 и 2010 года), основная идея — смотреть на большое количество аномальных новых пользователей.</p>
<h2>Cold start</h2>
<p><em>Ensemble Contextual Bandits for Personalized Recommendation</em>. Идея в том, чтобы использовать многоруких бандитов как ансамбль когда мало данных для разделения моделей. Два шага: начала используется вес алгоритма в ансамбле, потом для каждого item-а алгоритмы говорят его вероятность. Все это совмещается и получается не сильно хуже, чем лучший алгоритм. Зато можно жить не выбирая модель.</p>
<p><strong>Интересно:</strong> <em>Cold-start News Recommendation with Domain-dependent Browse Graph</em>. Очень хорошая работа из Yahoo! Labs. Они исследовали user cold start для новостей. Идея: поведение пользователей отличается в зависимости от referer-а с которого они пришли. Чуваки выделили несколько больших рефереров (соцсети и поисковые системы) и построили для них browse-graph (с вершинами — статьями и ребрами — переходами). Кстати, графы поисковиков и соцсетей очень отличаются, а в группах большое пересечение. Дальше исследуют влияние разных рекомендаций в таких графах. Получается, что можно сделать лучше! Да, графы пересчитывают каждый час. </p>
<p><em>Item Cold-Start Recommendations: Learning Local Collective Embeddings</em>. Еще работа из Yahoo! Labs. Идея в том, что они раскладывают две матрицы content matrix и collaborative matrix вместе, одна формирует темы, другая — группы пользователей. Но матрица фичей одна! То есть можно зная темы документа предсказать рейтинг для каждого пользователя. Используют два датасета: новости и предсказание адресата в почте. По почте почти так же как bpr+knn, где-то лучше, где-то хуже по разным метрикам. По новостям становится сильно лучше.</p>
<p><em>Improving The Discriminative Power Of Inferred Content Information Using Segmented Virtual Profile</em>. Чувакки из linkedin рассказывают, как они улучшили  свои рекомендации работ. Выделяют из профилей фичи, по которым аппликанты сильно отличаются от остальных, это помогает дополнить профиль вакансии и лучше рекомендовать. Стало сильно лучше и хорошо масштабируется. Больше я ничего не понял=(</p>
<p><em>Ratings Meet Reviews, a Combined Approach to Recommend</em>. Какой-то невнятный китаец рассказывал, как соединить lda и mf в одну вероятностную generative model. Модель вроде интересная, но они меряют rmse и упирают на explanation, который весьма сомнителен. Аматриан заметил, что ровно то же самое опубликовали на последнем KDD. </p>
<h1>Среда (8 октября)</h1>
<p>Очень интересный день — самые интересные доклады, самые интересные встречи, постеры. Попытаюсь описать как можно больше из того, что я запомнил.</p>
<h2>Metrics and Evaluation</h2>
<p><strong>Интересно:</strong> Первая статья — <em>Beyond Clicks: Dwell Time for Personalization</em> — best paper award.
Идея простая, есть yahoo stream, лайков мало, а клики шумные. Давайте же использовать dwell-time!
Собственно, они собирают события (зашли на статью, в фокусе, потеряли фокус, ушли) и строят сессии.
Дальше они делают большой анализ dwell time в разных категориях и контекстах, в итоге пришли к z-score нормализации внутри контекста.
Рекомендации строят через GBDT, время хорошо использовать для взвешивания событий (тут лучше почитать статью), но можно и для собственно формирования событий.<br />
Супер-пупер результаты, все хорошо работает, всем dwell-time.</p>
<p>Дальше Даниэль Клувер делал доклад <em>Evaluating Recommender Behavior For New Users</em>. Идея простая: они взяли movielens и у некоторых пользователей из test set-а оставили в train-е маленькое количество рейтингов (симулировали cold-start). А дальше они изучили как разные методы ведут себя в разных ситуациях. Вывод доклада — если меньше 4-х рейтингов, то baseline model лучше svd почти по всем метрикам.</p>
<p>Следом выступил Алан Саид <em>Comparative Recommender System Evaluation: Benchmarking Recommendation Frameworks</em>. Они рассказывали про rival — фреймворк для оценки и проведения исследований. Получилось очень интересно, они построили хороший протокол, где единственным черным ящиком остается алгоритм. Можно использовать модульно, поэтому и тестить что угодно. Его, кстати, использовали в recsys challenge в этом году.<br />
Смотреть можно и нужно на <a href="http://rival.recommenders.net">http://rival.recommenders.net</a>, код у них открытый.</p>
<p>Дальше был рассказ про <em>Social Influence Bias in Recommender Systems: A Methodology for Learning, Analyzing, and Mitigating Bias in Ratings</em>. Суть в том, что решения пользователей подвержены влиянию большинства (например, если все в комнате говорят, что черный кубик белый человек склонен тоже сказать, что он белый, хотя и зная, что это не так). Вопрос в том, можно ли измерить social bias и можно ли его устранить из существующего датасета? Используют California Report Card, люди сначала ставят рейтинг, потом им показывают медиану и они могут поменять решение. Так вот оказывается, что изменившие решение и не изменившие его отличаются (по Вилкоксону). Дальше они строят метод предсказания того, что пользователь поменял рейтинг и очищают данные.<br />
Но к случаю, когда рейтинг встроен в дизайн, это плохо применимо.</p>
<h2>Novelty and Serendipity</h2>
<p>Первая статья весьма оригинальна: <em>Improving-Sales-Diversity-by-Recommending-Users-to-Items</em>. Идея в том, чтобы развернуть проблему и рекомендовать пользователей к item-ам. Чуваки переписывают kNN в такой формулировке и получают более качественный neighbour selection, в итоге выигрывают по качеству.</p>
<p><em>On Over-Specialization and Concentration Biases of Recommendations: Probabilistic Neighborhood Selection in Collaborative Filtering Systems</em>. Чуваки делают probabilistic neighbor selection, это простое взвешенное семплирование с возващение. Больше ничего не понял =(</p>
<p>В следующей работе <em>User Perception of Differences in Recommender Algorithms</em> чуваки на user study смотрят как пользователи оценивают выдачи разных алгоритмов. Они строят модель качества алгоритма, которая учитывает сочетания accuracy, diversity и novelty, от которых зависит satisfaction и first impression, которые в свою очередь ведут к выбору того или иного алгоритма как лучшего. Интересно, что:
  * satisfaction affects 1 imp and choice
  * satisfaction mediates diversity
  * novelty has complex largely negative effect
  * diversity and accuracy trade off
Короче, осторожно с novelty, а diversity в меру хорошо. Но это все махания руками, так как народ резонно заметил, что пользователи не пользовались этими рекомендациями и поэтому скорее всего выбрали более очевидные. Но они якобы делали это больше для новых пользователей и бла-бла-бла...</p>
<p>Дальше рассказывал Флоран Гарсин (проф из EPFL): <em>Offline and Online Evaluation of News Recommender Systems at swissinfo.ch</em>
они сделали систему рекомендаций новостей, см. предыдущую работу: <a href="http://arxiv.org/pdf/1303.0665.pdf">http://arxiv.org/pdf/1303.0665.pdf</a><br />
Собирают клики и обучают модель, в offline и online ситуация отличается диаметрально! Этот тот самый extremely good random recommender. Очень странная статья практически без выводов...</p>
<p>В перерыве подошел к Клуверу, спрашивал не знает ли он про исследования в области таксономии в cold start. Он не знает =(
Потом обсуждали с Флораном почему его метод не работает, обсуждение плавно перетекло в ланч (всех выгнали из зала). И в результете (один я бы так не сделал), мы подсели за столик к каким-то чувакам. Которые при ближайшем рассмотрении оказались цветом Гугла. Так я пообедал с Джеффом Дином =)<br />
Они мало что рассказывали и вообще были напряженные. Я пытался спрашивать, как они строят рекомендации — единой платформы таки нет. Часто они совпадают по API, но не всегда, им нравится, что рекомендации делают эксперты в конкретной предметной области. Идеального рекоомендера Джефф не видит, скорее это что-то в духе ансамбля (или нейросети, как можно подумать из его доклада?), куда легко можно вставить разные фичи про пользователя, item и т.д.</p>
<h2>Keynote</h2>
<p>Дальше был <em>keynote</em> от Джеффа, про который мнения разошлись. Он говорил про нейросети (что очень внезапно) и очень impressive. Соответственно, половина людей была скептична (например, Аматриан), другая наоборот воодушевилась. 
В целом главная мысль — нам нужно научиться лучше понимать объекты (тексты, изображения, музыку, действия пользователя и т.д.) и очень хочется избавиться от ручного кодирования тысяч фичей. Выход — deep learning. Это реинкарнация нейронных сетей из 80-х, но at scale. Причем, с одной стороны все упростилось (например, просто max(0,x) вместо сигмоиды для активации), но зато появились способы обучать supervised, unsupervised и RL. Очень много работы сделано, чтобы уменьшить время обучения: это удается сделать с помощью двух вещей:
  * параллелизм модели — разные части модели можно обучать параллельно
  * параллелизм данных - можно поднять много копий моделей и parameter server, каждая модель будет считать дельты к параметрам и отправлять/получать обновления параметров<br />
В результате — asynchronous distributed SGD. <br />
См. <a href="http://static.googleusercontent.com/media/research.google.com/ru/us/archive/unsupervised_icml2012.pdf">http://static.googleusercontent.com/media/research.google.com/ru/us/archive/unsupervised_icml2012.pdf</a> и <a href="http://static.googleusercontent.com/media/research.google.com/ru/us/archive/large_deep_networks_nips2012.pdf.">http://static.googleusercontent.com/media/research.google.com/ru/us/archive/large_deep_networks_nips2012.pdf.</a><br />
Дальше он приводил множество примеров того, что нейронки всемогущие. Ну вы понимаете о чем я.<br />
Затем внезапно рассказал word2vec-модели (включая перевод текстов и paragraph-model). и о том, что это можно применять для эмбеддинга целых фраз: <a href="http://arxiv.org/pdf/1409.3215.pdf">http://arxiv.org/pdf/1409.3215.pdf</a><br />
Дальше с такими представлениями можно работать как с обычными плотными данными, например, кормить большой нейронке, вроде тех, что используются в image recognition или acoustic recognition <a href="http://static.googleusercontent.com/media/research.google.com/ru/us/pubs/archive/38131.pdf.">http://static.googleusercontent.com/media/research.google.com/ru/us/pubs/archive/38131.pdf.</a> Или просто использовать получившееся латентное пространство.<br />
Архитектуру сетей очень хочется получать автоматически, но пока они не научились.  </p>
<h2>Mainstream</h2>
<p>Дальше тетушка из Linkedin рассказывала про <em>A/B Testing: Innovation @ Internet Scale</em>. В целом говорила достаточно очевидные вещи: тестировать надо. Но не просто надо, а тестировать надо все (буквально каждый рефакторинг). Они построили систему, которая одновременно гоняет 200+ экспериментов и считает 800+ метрик (кроме всего прочего, замеряет значимость). Плюс, разные метрики по разному связаны с p-value (тут мало кто понял о чем она), поэтому они умеют для разных метрик задавать разные пороги значимости. Плюс, они умеют выделять конкретную экспериментальную группу (тоолько те, у кого было 1 или 2 работы). Плюс, они разделяют владельца эксперимента и владельца метрики и можно удобно смотреть, какие эксперименты зааффектит изменение метрики.</p>
<p>Дальше ребята из facebook делали два доклада:</p>
<p>первый — <em>Page recommendations at Facebook</em>. Идея в том, что они максимизируют не лайки, а user engagement. Система сначала выделяет структурированный запрос, потом выбирает кандидатов, потом ранжирует их по p(engagement). Разные события весят по-разному (лайки, клики), но взвешивание подбирается чуть ли не руками. Для выбора кандидатов используют:
1. location based CF
2. social user2user
3. CF (SVD on user-page matrix)
4. session-based CF: predict p(next page eng|current page eng.)
5. topic based ContentFiltering + RBM для сжатия
6. DNN to match page topic topic models to peoples interest models</p>
<p>второй — <em>News feed ranking</em>. У большинства пользователей очень большая лента, которую просто нереально читать. Поэтому они ее ранжируют. Глобальные метрики:daily active people, overall time spent. Но они очень не чувствительные, к тому же не на уровне постов. Метрики фида — на кликах, лайках, поделяшках, комментах и т.д. Пытаются предсказать (с разным весом в зависимости от типа события), понравится ли пользовалелю пост (в смысле лайк ли). We predict p(like) with many features… which are statistics on everything grouped in different ways. Счетчики, счетчики и еще раз счетчики. По пользовательским событиям, по постам и т.д. Дальше они извлекают фичи из счетчиков (как?) и обучают простую логистическую регрессию.<br />
Еще интересно, что фид не фиксирован — каждый update фида они переранжируют все, причем то, что пользователь видел, сильно понижается. Таким образом они значительно увеличивают долю прочитанного.</p>
<p>Дальше был докад <em>Making Advertising Personal: Large Scale Product Recommendation at Criteo</em> чувака из Criteo про то, какие они крутые. Но мне так не кажется — мало что рассказал, только общие идеи, про то, что они тестируют ранжирование вместо регрессии и очень хорошо масштабируются. И все.  </p>
<p>После снова был перерыв, мне попались ребята из Spotify (собственно, тот самый Эрик Бернардсон). Я много спрашивал про алгоритмы:
1. vector_exp — очень простая штука, которая внезапно хороша
2. они только экспериментируют с ее online-версией
3. да, они используют word2vec в ансамбле (но не очень распространяются как обучать их)
4. они пробовали писать статьи, но их отреджектили и пропала мотивация
5. еще много чего, в основном они спрашивали про то, насколько мы большие, так же ли у нас все устроено как у них и т.д.</p>
<h2>Recommendation methods and theory</h2>
<p>Первый доклад: <em>Recommending User Generated Item Lists</em> про то, как рекомендовать не только item-ы, а целые списки item-ов (мне задача очень напомнила next basket recommendation). Чуваки обучают ранжирование списков с помощью семплирования в два шага: на первом семплят пары item-ов, на втором — пары списков (что бы это ни значило). Сравнивают с кучей методов, в т.ч. BPR и LME, они лучше, конечно. Но там очень маленький датасет — 34k списков и всего 3k item-ов, плюс они еще фильтруют это. Так что скорее всего история как с LME, который не работает на данных реальных размеров.</p>
<p><strong>Интересно:</strong> Второй доклад: <em>Question Recommendation for Collaborative Question Answering Systems with RankSLDA</em>. Ребята решают задачу collaborative question answering, рекомендуют вопросы на crossvalidated (из stackexchange) тем, кто может ответить (как я понял). Они придумали расширение sLDA (supervised), которое умеет ранжировать — rankSLDA. Основные отличия — multiple outcome per document и learning to rank. Очень интересная работа, рекомендую прочитать статью.</p>
<p>Дальше какой-то китаец рассказывал про <em>Bayesian Binomial Mixture Model for Collaborative Prediction with Non-Random Missing Data</em>. Ничего не понял кроме классификации пропущенных данных (уже давно показали, что рейтинги — это missing not at random).</p>
<h2>Poster session</h2>
<p>Через некоторое время был poster session.
Посмотрел несколько работ, организовано было плохо (как и вся конференция целиком), поэтому не со всеми удалось поговорить.</p>
<p><em>Recommending Learning materials to students…</em>
Работа Кости Баумана, все очень просто — есть студенты, им предлагают quizz-ы посередине курса и по результатам формируют картину пробелов в знаниях. Рекомендации — это просто материалы к этим пробелам. На мой взгляд там есть проблемы с evaluation, Костя вроде согласился с этим. </p>
<p><em>Recommending Thumblr blogs to follow with inductive matrix completion</em>
Работа из yahoo, суть в том, что вместо стандартного матричного разложения они используют разложение на четыре матрицы: U x W x H x V, где U и V — фичи пользователей и блогов соответственно, они просто считают их без обучения. А вот W и H матрицы уже обучают.
Интересно, хотя и неизвестно, насколько это сравнимо с чистым implicit и с инициализацией через SimFactor.</p>
<p><em>Empathize, don’t filter</em>
Работа про UI, чуваки просто по разному показывают разные по важности твиты и на user study оказывается, что это типа лучше.</p>
<p><em>Hybrid explanations framework for CF RS</em>
Работа Кенингстайна про объяснение рекомендаций. Суть в том, чтобы построить три матрицы весов item-а в событиях пользователя, матрицу item-tag корелляций (?) и матрицу весов тэгов (мне так и не удалось понять, что это за веса). Потом простым произведением они выводят user-item-tag и дальше делают на этом explanation. Ноам говорит, что это просто эвристики, они сейчас ничего не обучают.
Кстати, спрашивал его про таксономию, он говорит, что у них есть та-самая-статья, но изданная в журнале, они там в частности показывают на примере жанров, что их таксономические вектора интерпретируемы и отлично сравнимы между собой. Cold start они не смотрели.</p>
<p><em>Switching Hybrid for cold-start CARS</em>
Чувак почти ничего толком не объяснил. Суть в том, что есть разные контексты и разные модели. Контексты сочетаются, но мы знаем не про все сочетания. И они вроде придумали, что нужно показывать общее предсказание в таких случаях… он не смог нормально объяснить.</p>
<p><em>Free-lunch Enhancement for Collaborative Filtering with factorization machines</em>
Интересная работа про libFM. Идея проста — давайте посмотрим на паттерны оценок пользователей (n1 единиц, n2 двоек, n3 трокек и т.д.), дальше построим по этим паттернам кластера. Номер кластера запихиваем в AUX information в libFM и вуаля.</p>
<p><em>WrapRec...</em>
Фреймворк на C# про то, как можно просто и удобно скрывать внешние рекоммендеры от клиентского кода. На стенде никого не было =(</p>
<p><em>An extended data model format for composite recommendation</em>
Очередной протокол от Саида, на этот раз про то, как передавать данные. Сущности — tsv, атрибуты в json-колонке. Ничего примечательного.</p>
<p><em>Long term recommendation benchmarking … using Markov chains</em>
Чувак делает приложение- список покупок. И выдвигает идею, что можно обучать вероятность элемента прожить (не быть удаленным, но может быть быть купленным) в списке больше времени t. Ничего кроме идеи.</p>
<p><em>Task-based user modelling for personalization via PMF</em>
Интересная работа, суть в том, чтобы научится выделять из пользовательских запросов задачи через кластеризацию (тут очень спорно, что они получатся интерпретируемы), дальше мы можем соотнести пользователя и его новые запросы с определенными тасками. Может быть, будет интересно кому-нибудь в поиске.</p>
<p><strong>Интересно:</strong> <em>Using graded implicit feedback for BPR</em>
Чувак предложил как обучать BPR не на {0,1} фидбеке, а в случае, если мы знаем степень предпочтения. Правда, он не умеет сильнее учитывать более сильную разницу предпочтений, учитывается только факт разницы.</p>
<p><em>Inferring user interests in twitter soc. network</em>
Простое извлечение интересов по связям и ключевым словам в твиттере.</p>
<p>Фотки постеров, которые мне удалось посмотреть, можно найти в папке posters в диске: <a href="https://yadi.sk/d/ueMsOUE4buSUx">https://yadi.sk/d/ueMsOUE4buSUx</a></p>
<p>После этого поговорил с Яннахом Дитмаром (автор одной из книжек), они много занимаются музыкой. Но ничего конкретного он не рассказал, скорее больше спрашивал кто мы, сколько у нас данных, какие методы используем и т.д.</p>
<h1>Четверг (9 октября)</h1>
<p>В четверг был последний день основной программы, тоже было много чего интересного.
Но обо все по порядку:</p>
<h2>Ranking and Top-N Recommendations</h2>
<p>Первый доклад — <em>Coverage, Redundancy and Size-Awareness in Genre Diversity for Recommender Systems</em>. Чуваки из telefonica делают разнообразие киношных рекомендаций через жанры. Они рассматривают несколько существующих подходов к тому, как это делать и в результате предлагают свой. Суть в построениии метрики binomialDiversity(R), где R — список рекомендаций. Строят так:
  * binomialCoverage(R), — штафуем за невыбор жанра
  * nonRedundancy(R) — штафуем за вероятности найти это или большее количество фильмов жанра в рекомендациях
  * binDiv(R) = coverage(R) * NonRed(R)</p>
<p><em>Towards a Dynamic Top-N Recommendation Framework</em>. Автора статьи не было, докладывал его коллега. Строят online+offline модель рекомендаций, но кроме того, еще инициализируют некоторые компоненты латентных векторов через topic modelling. Сравнение у них странное, они делают online, но сравниваются с offline-методами. Короче, неясно, насколько topic modelling помогает.</p>
<p><em>Explore-Exploit in Top-N Recommender Systems via Gaussian Processes</em>. Обычно в RL очень маленькое количество действий, но тут #action &gt;&gt; #trials. Поэтому можно выиграть в скорости, плюс идея разделять данные между позициями списка, между пользователями и item-ами. Для разделения между позициями считают простую вероятность вознаграждения на этой позиции, а для разделения user2user и item2item используют Гауссовские процессы. Интересно, что чем длиннее список, тем быстрее сходится.<br />
Их спрашивали про производительность (вроде Гауссовские процессы медленные) — они говорят, что параллелят вычисления, но у них пока нет online.</p>
<p><em>A Parameter-free Algorithm for an Optimized Tag Recommendation List Size</em>. Чувак из Сенегала рассказывал про то, как он строит рекомендации тэгов. Он вводит релевантность тэга, а из нее формулирует релевантность списка (которая не монотонна). В результате рекомендует список, оптимальный по релевантности  (но может быть более короткий).</p>
<h2>Industry session</h2>
<p><em>Virtual personal shopping assistant</em> — чувак из Shopkick (крупнейшего приложения для ритейлеров) рассказывал о rocket future для традиционных магазинов (не online!). Основная идея — нужно привести человека в магазин, а дальше высокая конверсия (от  35% до 90% в разных областях) сделают свое (тут я бы поспорил с ним). Они очень активно используют геопозицию — знают (с помощью ультразвуковых датчиков), когда, где и в какой магазин вошел пользователь. Через iBeacon знают, где он внутри магазина (иногда с точностью до манекена, который он смотрит, чаще просто отдел). В результате их идея — формировать персональные скидки для человека. Например, "хей! ты вчера интересовался этой курткой, специально для тебя скидка 30%"<br />
Еще персонализируют фид в приложении, персонализируют нотификации (как способ так и время). Стараются выдать нотификацию в тот момент, когда человек реально может зайти в магазин, а не посреди хайвея.</p>
<p><em>Recommendations and Decision Support in Agriculture</em>. Чуваки занимаются рекомендациями и анализом данных в сельском хозяйстве. Пишут о том, что средний фермер за год принимает примерно 40 бизнес-решений, которые очень сильно влияют на дальнейшую судьбу бизнеса. Хотят это оптимизировать и помогать в принятии решений. Очень много данных (реально много), но проблема — они не собраны вместе и часто в разных форматах. Но они двигаются вперед.</p>
<p><em>Blending Human Computing and Recommender Systems for Personalized Style Recommendations</em>. Доклад прямо противоположный вчерашнему keynote Джеффа. Компьютеры хороши в том, чтобы быстро что-нибудь посчитать, человек — в распознавании сложных образов и вообще в прекрасном. Они соединяют компьютеры и людей для того, чтобы рекомендовать одежду. Модель такая: человек заходит на сайт, заполняет много-много данных про себя (в том числе неструктурированных, плюс указывает примеры стиля, который ей нравится — они только для девушек). Дальше алгоритм отбирает "кандадатов", потом эксперт в области делает окончательный выбор. И товары отправляются пользователю. Сразу. То есть пользователь посмотрит их уже дома. Рекомендации — это 100% их бизнеса, плюс очень высокие ставки (хотя мне интересно, на что они потратили бы больше — на доставку false positive или на зарплату экспертам).<br />
Идея интересная, хотя и очень спорная.</p>
<p><em>Prototyping Trust: Modeling the Virtuous Cycle</em>. Тетушка из microsoft рассказывала про то, как они дизайнят новый интерфейс взамодействия рекомендаций и человека. Она привела резонный пример, что в человеческих отношениях существует social protocol — мы не сразу рассказываем первому встречному все про себя, но нам нужно какое-то время, чтобы обрести доверие друг друга. Собственно тут идея та же самая — они хотят научить машины уважать этот social protocol. Она говорит, что не нужно доставлять максимально точные рекомендации в первый день. По этому вопросу много споров, например, Аматриан с ней категорически не согласен. Но это их идея в том, чтобы сделать "вежливого" интеллектуального помощника.</p>
<h2>Keynote</h2>
<p><em>Thoughts on the Future of Recommender Systems</em> by Hector Garcia Molina, Standford University
Impressive профессор из Стэнфорда пытался научить всех делать рекомендательные системы. Несколько основных мыслей:
1. нужно объединить (хотя бы по базе знаний и технологиям) поиск, рекомендации и рекламу
2. нужно дать пользователю возможность настройки и влияния на алгоритм
3. нужно дать возможность людям помочь в рекомендации (очень созвучно с blending human computing...)
Дальше долго рассказывал какую они замечательную систему рекомендаций построили в Стэнфорде. Вобщем, совершенно не по делу.</p>
<h2>Panel</h2>
<p><em>Controversial Questions About Personalization</em>. В дискуссии принимали участие Pankaj Gupta (ex-Twitter), Tim Jones (CTO at Upworthy — ecommerce), Eric Bieschke (Chief Scientist and VP at Pandora), Joaquin A Delgado (Director of Engineering of Advertising and Personalization at OnCue – Verizon).<br />
Много говорили про мораль, по то, какая ответственность лежит на системах рекомендаций, не будет ли так, что пользователь окажется в пузыре. "Все люди в пузыре. Но наше счастье, что он достаточно большой" — Эрик. Они в Pandora, кстати, оптимизируют diversity рекомендаций, это одна из их основных метрик. Еще говорили про то, хорошо ли аб-тестироваться на пользователях и о том, как сделать так, чтобы они поняли почему их рекомендации хуже.</p>
<h2>Matrix factorization</h2>
<p>Последняя сессия была довольно интересной.</p>
<p><em>GASGD: Stochastic Gradient Descent for Distributed Asynchronous Matrix Completion via Graph Partitioning</em>. Чуваки делают раcпределенный SGD за счет разбиения графа рейтингов (?). Основные улучшения — метод партиционирования, уменьшение количества разделяемых данных между нодами и введение синхро-параметра (отвечает за то, как часто ноды синхронизируются, конролирует tradeoff между качеством и скоростью). Реально на распределенной системе они еще не тестили, только в симуляторе.</p>
<p><em>A Framework for Matrix Factorization based on General Distributions</em>. О том, как обобщить probabilistic matrix factorization на любые распределения. GD (или SGD), для вычисления производной делают численное дифференцирование.
<a href="https://github.com/josefbauer/DMF">https://github.com/josefbauer/DMF</a> (will be soon available?)</p>
<p><strong>Интересно:</strong> <em>Speeding Up the Xbox Recommender System Using a Euclidean Transformation for Inner-Product Spaces</em>. Отличная работа Кенингстайна про то, как ускорить выбор кандидатов. Суть в том, что они перевели пространство, где оптимизируется скалярное произведение в пространство, где нужно оптимизировать евклидово расстояние. Дальше применяют PCA-деревья (как kd, только раскладывают по главным компонентам всего множества). Для ускорения поиска они применяют эвристику — пронумеровав все листья они ищут соседей по листам с расстоянием Хэмминга 1 до данного.<br />
Результаты очень классные.<br />
P.S. прочитал их статью — там очень простые преобразования, правда. Это должно очень хорошо работать. Но эвристика с расстоянием Хэмминга — все же эвристика, то есть стоит понимать, что результат будет не точный.</p>
<p><strong>Интересно</strong>: <em>Gradient Boosting Factorization Machines</em>. Очень простая идея — метод Context Aware FM считает все попарные сочетания факторов. Но не все из них реально полезны! Собственно, чуваки придумали, каким образом ввести коэффициенты для фичей и жадно оптимизировать слой за слоем (у них только слой 2). Плюс еще превзошли сами себя и придумали, как оптимизировать все это используя shared latent vectors. Рекомендую статью к прочтению.<br />
На эксперименте рвут всех (само собой).</p>
<p><em>Exploiting Temporal Influence in Online Recommendation</em>. Парень исследует влияние совместных скробблингов исполнителей в last.fm. Вводит красивую вероятностную модель, сводит это к нескольким матричным разложениям и много махает руками. Тут основная проблема в том, как он измеряет, у него DCG@1. То есть фактически, это не ранжирование, а предсказание.</p>
<p>В перерывах несколько раз разговаривал с Эриком. Он рассказал, что у них почти все в проде написано java, а исследования на scala. Они пользуются хадупом, пробовали spark, но он очень нестабилен, да и прирост в производительности маленький. Параметры (Миша, тебе лучше присесть) они подбирают на глазок! То есть выбирают то, что описано в статье и неплохо работает и все. Никаких оптимизаций у них нет! Очень внезапно.<br />
Рассказывал, что они используют word2vec (своя реализация в проде и gensim для исследований), но в основном для похожестей. Я так понял, что у них даже в этом блоке работает ансамбль. Про контент-майнинг — они предсказывают латентные вектора item-ов, но это тоже только для похожестей и не в проде пока. vector_exp действительно у них хорошо работает, там очень простая идея, пока даже онлайна нет.<br />
Примерно так.  </p>
<p>Следующий RecSys будет в Вене 16-20 сентября 2015. Огласили программу RecSys Challenge — нужно будет по данным eCommerce системы научиться предсказывать а) была ли в сессии покупка б) и что купили. Данные и условия скоро выложат.</p>
<h1>Пятница (10 октября)</h1>
<p>Сегодня был последний день конференции — только воркшопы. Первоначально я планировал идти только на large scale recommender systems, но потом скипнул несколько докладов и послушал вместо них recsysTV. Так что если вдруг статья будет про тв — не удивляйтесь.</p>
<p><em>Recommendation Architecture: Going Beyond the Collaborative Filter</em>.  Доклад чуваков из OpenTable — рекомендательная система ресторанов. У них 32k ресторанов,  $25B (в год?) тратят их клиенты в offline-ресторанах. Говорили достаточно много очевидных вещей. В целом идея — real goal: minimize engineering time to improve metric that matters. Такой подход легче измерить, итерации короче и проще. Дальше говорили, что стоит смотреть на то, как люди используют продукт, смотреть и на AB-тесты и «глазами аналитика». Дальше говорили про то, как стартовать рекомендательную систему, что хорошо начинать с простых эвристик и простых метрик типа RMSE. А уже потом переходить на learning2rank. Еще хорошо бы смотреть на variability of predictions, чтобы быть уверенным в своих рекомендациях и не порекомендовать что-то потенциально плохое.<br />
Еще немного рассказывали о том, что они майнят темы из ревью через non-negative MF + TF-IDF (такой вариант топик-моделлинга). Кстати, у них темы визуализируются клевыми облаками тэгов.</p>
<p><em>Latent Feature Based FM Model For Rating Prediction</em>. Задача: добавить контент в Factorization Machines. Один способ — сделать topic modelling и добавить тему как aux information. Второй — выделить вектора слов через word2vec и добавить как aux info в FMs. Результатов не дождался — сбежал на доклад Netflix.</p>
<p><strong>Интересно:</strong> <em>Personalized Page Generation for Browsing Recommendations</em>. Парень из Netflix рассказывал, как они строят персональную страницу пользователя.<br />
Начало пересекалось с туториалом Аматриана, скип. Идея персонализации — смотреть как люди скроллят и взаимодействуют со страницей. Простой подход — просто строки на фиксированных местах (со своим ранкингом внутри). Выбирать можно rule-based, жадно и жадно с разнообразием. Второй подход — намайнить кучу фичей про блок (например, его размеры, CTR, quality, evidence, recency, how big, etc.), дальше строить page-level метрики: easy to discovery, diversity, novelty, recall@box (recall по области из нескольких блоков). Дальше добавляются блоки (разных размеров!).<br />
Все это происходит в три этапа (offline, near RT, RT). То есть что-то они делают прямо налету, да. Но сильно не все.</p>
<p><em>Large-scale Recommendation in E-commerce</em>. Чуваки из taobao.com (alibaba group) рассказывали, какие классные рекомендации они делают. Рекомендации разделены на retrieval и ranking + reranking. Плюс они в своем рекоммендере используют asynchronous distributed OnlineGD для обучения MF (?) на implicit-данных (например, dwell-time, click vs long click etc.). Поверх всего этого работает простая логистическая регрессия. </p>
<p><strong>Интересно:</strong> <em>Personalized Content Recommendation in Practice: The StumbleUpon model</em>. Тетушка рассказывала про StumbleUpon. Это фактически рекомендации страниц как у surfingbird: 180M indexed pages, +75k per day, примерно 500 интересов. 35 страниц пользователь смотрит в сессию, 3,5 часа на пользователя в месяц.<br />
Основной упор на diversity (когда показать лучшую рекомендацию? сейчас или когда пользователь уже «почти» будет готов уйти?). Из интересного — они майнят экспертов, чтобы а) уменьшить шум данных б) увеличить точность и интересность материала.<br />
Исползуют все модели – и CB и CF, но diversity is most important factor. Рекомендации генерятся налету. Еще по их опыту рейтинги не помогают почти никак — очень шумные (вы залайкаете котика, но он вам не интересен. А интересный мателиал про какую-нибудь проблему вы не будете лайкать — это слишком серьезная вещь). Ну и да, большинство лайков происходит еще до того, как пользователь прочитал материал. А вот негативные отзывы требуют больше времени, чтобы сформировать эмоции. Этот эффект можно использовать — они предсказывают, где пересекутся кривые ожидания времени лайка и дислайка для предсказания рейтинга. Да, ранжированием они начали заниматься, но там все трудно, так как выигрыш в MF не значит лучший продукт. Они много занимаются сегментацией рейтингов и пользователей и очень много майнят из контента. 
Full stack:
  * ingestion — feature analysis of content
  * sampling — how well this content will do?
  * rec pipelines — compute user-url metches, refresh data sources
  * rec engine — runtime (depends on device)
  * online computation — collecting events and online features and updating models
а еще реклама, дубликаты, классификаторы страниц, и т.д.<br />
Короче, крутые чуваки. Я делал много фотографий ее слайдов. Если слайды не выложат, то обработаю эти фотки — интересный доклад.</p>
<p><em>Graphlab tutorial</em>. Основатель(?) graphlab сел и за двадцать минут показал, как просто это использовать.</p>
<p><em>Building Large-Scale Recommender Systems for TV</em>. Скучный доклад тетушки из Samsung о том, как они строят рекомендации. hadoop, yarn, spark, обзор, бла-бла-бла… Интересно следующее: они используют automatic content recognition, то есть телек сам понимает, какое шоу показывают. Они что-то сделали в направлении объединения контентного пространства и коллаборативного пространства. Но что конкретно?</p>
<p><em>Large Scale Purchase Prediction with Historical User Actions on B2C Online Retail Platform</em>. Доклад победителей (?) Tmall price (китайское соревнование по ecommerce). Суть в том, что выдали 500M ratings, 10M users, 30k brands и нужно было предсказать по сессии купит ли пользователь данный бренд. Интересный момент — всем дали кластер!<br />
Чуваки делают много-много-много фичей, некоторые как у нас, некоторые нам надо бы попробовать. Подробности в статье. Feature selection у них наивный, просто по significance в модели.<br />
Рекомендательная система двухслойная: на первом слое куча сложных моделей (MF, Random forest, GBDT etc), на втором — логистическая регрессия (чтобы не переобучаться, как они говорят).</p>
<p><em>Distributed framework for ALS</em>. Очень простая идея — если считать ALS распределенно, то нужно передавать по сети матрицу (P^T * P + lambdaI)^-1. Так вот если ноды объединить в блоки и передавать один раз на блок (а еще мультикастом), то будет хорошо. Но это лишь идея, проработки почти никакой.</p>
<p><strong>Интересно:</strong> <em>Machine Listening at Pandora</em>. Чуваки из Пандоры намекнули, почему в совсем недалеком будущем останутся только они. Общеизвестно, что у них есть разметка экспертами полутора млн треков. Так вот, inside: они активно майнят свои фичи из контента для неразмеченных треков используя эту гигантскую базу. Дальше он приводил пример того, как выделять сильные доли по контенту (это вроде стандартно и очевидно, Женя, можем поговорить, если надо). Они много чего научились майнить автоматически подобным образом, им очень просто настраивать алгоритмы. На датасетах MIREX-а показывают 0.999, в то время как текущие лучшие результаты в районе 0,6 — 0,9 в разных задачах. Это просто power of data.<br />
Но предсказание жанра и фичей еще не все — важный момент — это построение плейлиста. У них используется metric learning. Но не только — они очень много чего делают и пробуют.<br />
q1: deep learning? representation learning?<br />
пробовали, но не скажут.<br />
q2: popularity?<br />
вроде не учитывают ее совсем<br />
q3: discogs will improve?<br />
в основном свои данные<br />
q4: how compares with itunes?<br />
никак, у них нет данных для объективного сравнения<br />
q5: а тексты?<br />
нет, это wide open problem. А вот эмоции майнят.<br />
q6: do users use cultural vs musicological reason for declaring songs? cultural и musical не так далеки — на самом деле некий tradeoff.  </p>
<p>С таким размеченным датасетом они могут почти все, что угодно…  </p>
<p><strong>Интересно</strong>: <em>Introducing the Metric Optimization Engine (MOE)</em>. Optimal learning — most effective way to collect information. Ребята в Yelp сделали фреймворк, который позволяет это делать. Оптимально обучаться, оптимально тюнить параметры, оптимально тестировать. Все это на explore-exploit.<br />
Как это работает:
  * builds Gaussian Process from sampled points
  * optimize covariance hyperparams of Gp
  * choose point with hight expected improvement
  * return next optimal point
Быстро сходится, отлично параллелится (можно делать мультисемплинг), можно исопльзовать GPU, можно как угодно задавать objective function… И все это уже работает в их production. И open source.<br />
Короче, надо брать: <a href="https://github.com/Yelp/MOE">https://github.com/Yelp/MOE</a></p>
        </div>
        <footer>
            <a href="/author/andrey-danilchenko.html">Andrey Danilchenko</a>
            <br />
            <span class="post_category label label-primary" ><a href="/category/recsys.html" rel="bookmark" title="Permalink to recsys"> recsys </a></span>
            <br />
            <span class="post_date">среда 15 октября 2014</span>
        </footer>
    </article>
</section>
  </article>

  <!-- Footer -->
  <footer>
    <address id="about" class="vcard body">
      <a href="/">4ducks</a>. Powered by <a href="http://getpelican.com/">Pelican</a>. Hosted by <a href="https://help.github.com/categories/github-pages-basics/">GitHub</a>.
    </address>
  </footer>


  <!-- Yandex.Metrika informer -->
    <a href="https://metrika.yandex.ru/stat/?id=26693874&amp;from=informer"
    target="_blank" rel="nofollow"><img src="//bs.yandex.ru/informer/26693874/3_1_FFFFFFFF_EFEFEFFF_0_pageviews"
    style="width:88px; height:31px; border:0;" alt="Яндекс.Метрика" title="Яндекс.Метрика: данные за сегодня (просмотры, визиты и уникальные посетители)" onclick="try{Ya.Metrika.informer({i:this,id:26693874,lang:'ru'});return false}catch(e){}"/></a>
    <!-- /Yandex.Metrika informer -->

    <!-- Yandex.Metrika counter -->
    <script type="text/javascript">
    (function (d, w, c) {
        (w[c] = w[c] || []).push(function() {
            try {
                w.yaCounter26693874 = new Ya.Metrika({id:26693874,
                        clickmap:true,
                        trackLinks:true,
                        accurateTrackBounce:true});
            } catch(e) { }
        });

        var n = d.getElementsByTagName("script")[0],
            s = d.createElement("script"),
            f = function () { n.parentNode.insertBefore(s, n); };
        s.type = "text/javascript";
        s.async = true;
        s.src = (d.location.protocol == "https:" ? "https:" : "http:") + "//mc.yandex.ru/metrika/watch.js";

        if (w.opera == "[object Opera]") {
            d.addEventListener("DOMContentLoaded", f, false);
        } else { f(); }
    })(document, window, "yandex_metrika_callbacks");
    </script>
    <noscript><div><img src="//mc.yandex.ru/watch/26693874" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
  <!-- /Yandex.Metrika counter -->

</body>
</html>